{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"ML_CFDv2.ipynb","version":"0.3.2","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"code","metadata":{"id":"LdtrDN_FljrF","colab_type":"code","outputId":"4c7034a2-76b7-4050-bd21-b44a76a99875","executionInfo":{"status":"ok","timestamp":1559448247054,"user_tz":240,"elapsed":1074,"user":{"displayName":"Gautham Bekal","photoUrl":"","userId":"01650273333839084339"}},"colab":{"base_uri":"https://localhost:8080/","height":55}},"source":["from google.colab import drive\n","drive.mount('/content/grdive')"],"execution_count":2,"outputs":[{"output_type":"stream","text":["Drive already mounted at /content/grdive; to attempt to forcibly remount, call drive.mount(\"/content/grdive\", force_remount=True).\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"q9J81bkslrzu","colab_type":"code","colab":{}},"source":["import pandas as pd\n","import numpy as np\n","import math \n","from collections import deque\n","from numpy import array\n","import random"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"X6Pr8g_Mlvj8","colab_type":"code","colab":{}},"source":["df =pd.read_excel('/content/grdive/My Drive/CFD Machine Learning/CFD.xlsx')"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"n20rbNHzn8RB","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":1949},"outputId":"0c0b81ae-2807-4a8c-ca7c-b1c433d08808","executionInfo":{"status":"ok","timestamp":1559458710092,"user_tz":240,"elapsed":666,"user":{"displayName":"Gautham Bekal","photoUrl":"","userId":"01650273333839084339"}}},"source":["df[:]"],"execution_count":71,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>ccx</th>\n","      <th>ccy</th>\n","      <th>ccz</th>\n","      <th>U1</th>\n","      <th>U2</th>\n","      <th>U3</th>\n","      <th>distance</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>276101</th>\n","      <td>-3.549367</td>\n","      <td>0.873805</td>\n","      <td>0.165214</td>\n","      <td>0.157078</td>\n","      <td>0.312564</td>\n","      <td>0.086993</td>\n","      <td>3.659076</td>\n","    </tr>\n","    <tr>\n","      <th>276075</th>\n","      <td>-3.549369</td>\n","      <td>-0.873805</td>\n","      <td>0.165215</td>\n","      <td>0.186573</td>\n","      <td>0.425258</td>\n","      <td>0.081138</td>\n","      <td>3.659077</td>\n","    </tr>\n","    <tr>\n","      <th>276008</th>\n","      <td>-0.873900</td>\n","      <td>-3.549809</td>\n","      <td>0.165215</td>\n","      <td>1.250538</td>\n","      <td>0.322960</td>\n","      <td>0.072068</td>\n","      <td>3.659527</td>\n","    </tr>\n","    <tr>\n","      <th>276166</th>\n","      <td>-0.873901</td>\n","      <td>3.549815</td>\n","      <td>0.165213</td>\n","      <td>1.157566</td>\n","      <td>0.301015</td>\n","      <td>0.068508</td>\n","      <td>3.659534</td>\n","    </tr>\n","    <tr>\n","      <th>2717</th>\n","      <td>0.873998</td>\n","      <td>3.550097</td>\n","      <td>0.165215</td>\n","      <td>0.683874</td>\n","      <td>0.066385</td>\n","      <td>0.019641</td>\n","      <td>3.659830</td>\n","    </tr>\n","    <tr>\n","      <th>276020</th>\n","      <td>0.873998</td>\n","      <td>-3.550097</td>\n","      <td>0.165215</td>\n","      <td>0.750596</td>\n","      <td>0.084345</td>\n","      <td>0.033828</td>\n","      <td>3.659830</td>\n","    </tr>\n","    <tr>\n","      <th>2365</th>\n","      <td>3.550562</td>\n","      <td>0.874096</td>\n","      <td>0.165215</td>\n","      <td>-0.017168</td>\n","      <td>0.067213</td>\n","      <td>-0.004526</td>\n","      <td>3.660305</td>\n","    </tr>\n","    <tr>\n","      <th>276081</th>\n","      <td>3.550562</td>\n","      <td>-0.874096</td>\n","      <td>0.165215</td>\n","      <td>-0.134878</td>\n","      <td>0.469799</td>\n","      <td>-0.036332</td>\n","      <td>3.660305</td>\n","    </tr>\n","    <tr>\n","      <th>2022</th>\n","      <td>-3.171205</td>\n","      <td>-1.838501</td>\n","      <td>0.165493</td>\n","      <td>0.481896</td>\n","      <td>0.711182</td>\n","      <td>0.071588</td>\n","      <td>3.669334</td>\n","    </tr>\n","    <tr>\n","      <th>276122</th>\n","      <td>-3.171205</td>\n","      <td>1.838503</td>\n","      <td>0.165493</td>\n","      <td>0.447528</td>\n","      <td>0.585344</td>\n","      <td>0.076908</td>\n","      <td>3.669335</td>\n","    </tr>\n","    <tr>\n","      <th>1845</th>\n","      <td>-1.838588</td>\n","      <td>-3.171412</td>\n","      <td>0.165492</td>\n","      <td>1.115045</td>\n","      <td>0.638383</td>\n","      <td>0.068604</td>\n","      <td>3.669557</td>\n","    </tr>\n","    <tr>\n","      <th>276149</th>\n","      <td>-1.838586</td>\n","      <td>3.171413</td>\n","      <td>0.165491</td>\n","      <td>1.023918</td>\n","      <td>0.574993</td>\n","      <td>0.067115</td>\n","      <td>3.669557</td>\n","    </tr>\n","    <tr>\n","      <th>276039</th>\n","      <td>1.838924</td>\n","      <td>-3.171949</td>\n","      <td>0.165492</td>\n","      <td>0.229515</td>\n","      <td>0.046744</td>\n","      <td>-0.038786</td>\n","      <td>3.670189</td>\n","    </tr>\n","    <tr>\n","      <th>276151</th>\n","      <td>1.838926</td>\n","      <td>3.171952</td>\n","      <td>0.165493</td>\n","      <td>0.215866</td>\n","      <td>0.039359</td>\n","      <td>-0.056248</td>\n","      <td>3.670193</td>\n","    </tr>\n","    <tr>\n","      <th>276124</th>\n","      <td>3.172170</td>\n","      <td>1.839009</td>\n","      <td>0.165492</td>\n","      <td>-0.061589</td>\n","      <td>0.154011</td>\n","      <td>-0.027047</td>\n","      <td>3.670423</td>\n","    </tr>\n","    <tr>\n","      <th>276064</th>\n","      <td>3.172170</td>\n","      <td>-1.839011</td>\n","      <td>0.165492</td>\n","      <td>-0.225966</td>\n","      <td>0.430632</td>\n","      <td>0.008234</td>\n","      <td>3.670424</td>\n","    </tr>\n","    <tr>\n","      <th>276105</th>\n","      <td>-3.547741</td>\n","      <td>0.874263</td>\n","      <td>0.499513</td>\n","      <td>0.124777</td>\n","      <td>0.335237</td>\n","      <td>0.121523</td>\n","      <td>3.687861</td>\n","    </tr>\n","    <tr>\n","      <th>276079</th>\n","      <td>-3.547743</td>\n","      <td>-0.874263</td>\n","      <td>0.499512</td>\n","      <td>0.158837</td>\n","      <td>0.454766</td>\n","      <td>0.116399</td>\n","      <td>3.687862</td>\n","    </tr>\n","    <tr>\n","      <th>276012</th>\n","      <td>-0.874355</td>\n","      <td>-3.548183</td>\n","      <td>0.499510</td>\n","      <td>1.309245</td>\n","      <td>0.366379</td>\n","      <td>0.126965</td>\n","      <td>3.688307</td>\n","    </tr>\n","    <tr>\n","      <th>276170</th>\n","      <td>-0.874358</td>\n","      <td>3.548190</td>\n","      <td>0.499513</td>\n","      <td>1.196482</td>\n","      <td>0.334115</td>\n","      <td>0.117156</td>\n","      <td>3.688315</td>\n","    </tr>\n","    <tr>\n","      <th>276184</th>\n","      <td>0.874456</td>\n","      <td>3.548471</td>\n","      <td>0.499510</td>\n","      <td>0.661981</td>\n","      <td>0.051430</td>\n","      <td>0.045055</td>\n","      <td>3.688608</td>\n","    </tr>\n","    <tr>\n","      <th>276024</th>\n","      <td>0.874456</td>\n","      <td>-3.548471</td>\n","      <td>0.499510</td>\n","      <td>0.755136</td>\n","      <td>0.075397</td>\n","      <td>0.076303</td>\n","      <td>3.688608</td>\n","    </tr>\n","    <tr>\n","      <th>276085</th>\n","      <td>3.548938</td>\n","      <td>-0.874551</td>\n","      <td>0.499510</td>\n","      <td>-0.138464</td>\n","      <td>0.474620</td>\n","      <td>-0.001005</td>\n","      <td>3.689080</td>\n","    </tr>\n","    <tr>\n","      <th>276111</th>\n","      <td>3.548938</td>\n","      <td>0.874551</td>\n","      <td>0.499510</td>\n","      <td>-0.028645</td>\n","      <td>0.070300</td>\n","      <td>0.040818</td>\n","      <td>3.689080</td>\n","    </tr>\n","    <tr>\n","      <th>276046</th>\n","      <td>-2.768935</td>\n","      <td>-2.441561</td>\n","      <td>0.166028</td>\n","      <td>0.747418</td>\n","      <td>0.782648</td>\n","      <td>0.063859</td>\n","      <td>3.695374</td>\n","    </tr>\n","    <tr>\n","      <th>276134</th>\n","      <td>-2.768933</td>\n","      <td>2.441566</td>\n","      <td>0.166029</td>\n","      <td>0.677541</td>\n","      <td>0.690687</td>\n","      <td>0.060777</td>\n","      <td>3.695376</td>\n","    </tr>\n","    <tr>\n","      <th>276034</th>\n","      <td>-2.441578</td>\n","      <td>-2.768997</td>\n","      <td>0.166029</td>\n","      <td>0.909903</td>\n","      <td>0.733185</td>\n","      <td>0.061510</td>\n","      <td>3.695431</td>\n","    </tr>\n","    <tr>\n","      <th>2625</th>\n","      <td>-2.441578</td>\n","      <td>2.769000</td>\n","      <td>0.166029</td>\n","      <td>0.832003</td>\n","      <td>0.667888</td>\n","      <td>0.060604</td>\n","      <td>3.695434</td>\n","    </tr>\n","    <tr>\n","      <th>276042</th>\n","      <td>2.442150</td>\n","      <td>-2.769597</td>\n","      <td>0.166028</td>\n","      <td>0.013873</td>\n","      <td>0.021274</td>\n","      <td>-0.000362</td>\n","      <td>3.696258</td>\n","    </tr>\n","    <tr>\n","      <th>276153</th>\n","      <td>2.442150</td>\n","      <td>2.769598</td>\n","      <td>0.166029</td>\n","      <td>0.027405</td>\n","      <td>0.085434</td>\n","      <td>0.000548</td>\n","      <td>3.696260</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>266909</th>\n","      <td>47.666650</td>\n","      <td>-13.666650</td>\n","      <td>39.000000</td>\n","      <td>0.111677</td>\n","      <td>0.009181</td>\n","      <td>0.125522</td>\n","      <td>63.086344</td>\n","    </tr>\n","    <tr>\n","      <th>270845</th>\n","      <td>47.666650</td>\n","      <td>13.666650</td>\n","      <td>39.000000</td>\n","      <td>0.151359</td>\n","      <td>0.025423</td>\n","      <td>0.122113</td>\n","      <td>63.086344</td>\n","    </tr>\n","    <tr>\n","      <th>271805</th>\n","      <td>47.666650</td>\n","      <td>-11.666650</td>\n","      <td>39.666650</td>\n","      <td>0.088905</td>\n","      <td>0.000472</td>\n","      <td>0.121237</td>\n","      <td>63.100423</td>\n","    </tr>\n","    <tr>\n","      <th>275165</th>\n","      <td>47.666650</td>\n","      <td>11.666650</td>\n","      <td>39.666650</td>\n","      <td>0.164925</td>\n","      <td>0.038231</td>\n","      <td>0.131068</td>\n","      <td>63.100423</td>\n","    </tr>\n","    <tr>\n","      <th>266525</th>\n","      <td>47.666650</td>\n","      <td>15.666650</td>\n","      <td>38.333350</td>\n","      <td>0.441022</td>\n","      <td>0.014984</td>\n","      <td>0.126803</td>\n","      <td>63.142689</td>\n","    </tr>\n","    <tr>\n","      <th>262013</th>\n","      <td>47.666650</td>\n","      <td>-15.666650</td>\n","      <td>38.333350</td>\n","      <td>0.463450</td>\n","      <td>0.014148</td>\n","      <td>0.138098</td>\n","      <td>63.142689</td>\n","    </tr>\n","    <tr>\n","      <th>271420</th>\n","      <td>47.000000</td>\n","      <td>-14.333350</td>\n","      <td>39.666650</td>\n","      <td>0.140162</td>\n","      <td>0.010970</td>\n","      <td>0.129720</td>\n","      <td>63.149727</td>\n","    </tr>\n","    <tr>\n","      <th>275548</th>\n","      <td>47.000000</td>\n","      <td>14.333350</td>\n","      <td>39.666650</td>\n","      <td>0.147391</td>\n","      <td>0.024766</td>\n","      <td>0.118924</td>\n","      <td>63.149727</td>\n","    </tr>\n","    <tr>\n","      <th>271709</th>\n","      <td>47.666650</td>\n","      <td>-12.333350</td>\n","      <td>39.666650</td>\n","      <td>0.095288</td>\n","      <td>0.003098</td>\n","      <td>0.122770</td>\n","      <td>63.227084</td>\n","    </tr>\n","    <tr>\n","      <th>275261</th>\n","      <td>47.666650</td>\n","      <td>12.333350</td>\n","      <td>39.666650</td>\n","      <td>0.161908</td>\n","      <td>0.034536</td>\n","      <td>0.128563</td>\n","      <td>63.227084</td>\n","    </tr>\n","    <tr>\n","      <th>266813</th>\n","      <td>47.666650</td>\n","      <td>-14.333350</td>\n","      <td>39.000000</td>\n","      <td>0.131187</td>\n","      <td>0.013236</td>\n","      <td>0.128506</td>\n","      <td>63.234124</td>\n","    </tr>\n","    <tr>\n","      <th>270941</th>\n","      <td>47.666650</td>\n","      <td>14.333350</td>\n","      <td>39.000000</td>\n","      <td>0.150691</td>\n","      <td>0.022857</td>\n","      <td>0.120139</td>\n","      <td>63.234124</td>\n","    </tr>\n","    <tr>\n","      <th>271324</th>\n","      <td>47.000000</td>\n","      <td>-15.000000</td>\n","      <td>39.666650</td>\n","      <td>0.208119</td>\n","      <td>0.016012</td>\n","      <td>0.139533</td>\n","      <td>63.304369</td>\n","    </tr>\n","    <tr>\n","      <th>275644</th>\n","      <td>47.000000</td>\n","      <td>15.000000</td>\n","      <td>39.666650</td>\n","      <td>0.178076</td>\n","      <td>0.025251</td>\n","      <td>0.120226</td>\n","      <td>63.304369</td>\n","    </tr>\n","    <tr>\n","      <th>275357</th>\n","      <td>47.666650</td>\n","      <td>13.000000</td>\n","      <td>39.666650</td>\n","      <td>0.157168</td>\n","      <td>0.030391</td>\n","      <td>0.125559</td>\n","      <td>63.360498</td>\n","    </tr>\n","    <tr>\n","      <th>271613</th>\n","      <td>47.666650</td>\n","      <td>-13.000000</td>\n","      <td>39.666650</td>\n","      <td>0.102985</td>\n","      <td>0.005819</td>\n","      <td>0.124484</td>\n","      <td>63.360498</td>\n","    </tr>\n","    <tr>\n","      <th>271037</th>\n","      <td>47.666650</td>\n","      <td>15.000000</td>\n","      <td>39.000000</td>\n","      <td>0.177339</td>\n","      <td>0.021635</td>\n","      <td>0.122510</td>\n","      <td>63.388560</td>\n","    </tr>\n","    <tr>\n","      <th>266717</th>\n","      <td>47.666650</td>\n","      <td>-15.000000</td>\n","      <td>39.000000</td>\n","      <td>0.198465</td>\n","      <td>0.020162</td>\n","      <td>0.137273</td>\n","      <td>63.388560</td>\n","    </tr>\n","    <tr>\n","      <th>271228</th>\n","      <td>47.000000</td>\n","      <td>-15.666650</td>\n","      <td>39.666650</td>\n","      <td>0.473723</td>\n","      <td>0.010697</td>\n","      <td>0.145299</td>\n","      <td>63.465637</td>\n","    </tr>\n","    <tr>\n","      <th>275740</th>\n","      <td>47.000000</td>\n","      <td>15.666650</td>\n","      <td>39.666650</td>\n","      <td>0.417702</td>\n","      <td>0.018457</td>\n","      <td>0.129334</td>\n","      <td>63.465637</td>\n","    </tr>\n","    <tr>\n","      <th>271517</th>\n","      <td>47.666650</td>\n","      <td>-13.666650</td>\n","      <td>39.666650</td>\n","      <td>0.113699</td>\n","      <td>0.008532</td>\n","      <td>0.126595</td>\n","      <td>63.500630</td>\n","    </tr>\n","    <tr>\n","      <th>275453</th>\n","      <td>47.666650</td>\n","      <td>13.666650</td>\n","      <td>39.666650</td>\n","      <td>0.152188</td>\n","      <td>0.026036</td>\n","      <td>0.122583</td>\n","      <td>63.500630</td>\n","    </tr>\n","    <tr>\n","      <th>266621</th>\n","      <td>47.666650</td>\n","      <td>-15.666650</td>\n","      <td>39.000000</td>\n","      <td>0.464908</td>\n","      <td>0.013687</td>\n","      <td>0.139690</td>\n","      <td>63.549614</td>\n","    </tr>\n","    <tr>\n","      <th>271133</th>\n","      <td>47.666650</td>\n","      <td>15.666650</td>\n","      <td>39.000000</td>\n","      <td>0.427363</td>\n","      <td>0.016491</td>\n","      <td>0.127746</td>\n","      <td>63.549614</td>\n","    </tr>\n","    <tr>\n","      <th>275549</th>\n","      <td>47.666650</td>\n","      <td>14.333350</td>\n","      <td>39.666650</td>\n","      <td>0.151514</td>\n","      <td>0.023623</td>\n","      <td>0.120431</td>\n","      <td>63.647447</td>\n","    </tr>\n","    <tr>\n","      <th>271421</th>\n","      <td>47.666650</td>\n","      <td>-14.333350</td>\n","      <td>39.666650</td>\n","      <td>0.134311</td>\n","      <td>0.011838</td>\n","      <td>0.130038</td>\n","      <td>63.647447</td>\n","    </tr>\n","    <tr>\n","      <th>271325</th>\n","      <td>47.666650</td>\n","      <td>-15.000000</td>\n","      <td>39.666650</td>\n","      <td>0.202112</td>\n","      <td>0.017728</td>\n","      <td>0.139705</td>\n","      <td>63.800883</td>\n","    </tr>\n","    <tr>\n","      <th>275645</th>\n","      <td>47.666650</td>\n","      <td>15.000000</td>\n","      <td>39.666650</td>\n","      <td>0.176976</td>\n","      <td>0.022689</td>\n","      <td>0.122407</td>\n","      <td>63.800883</td>\n","    </tr>\n","    <tr>\n","      <th>275741</th>\n","      <td>47.666650</td>\n","      <td>15.666650</td>\n","      <td>39.666650</td>\n","      <td>0.417286</td>\n","      <td>0.016842</td>\n","      <td>0.130620</td>\n","      <td>63.960899</td>\n","    </tr>\n","    <tr>\n","      <th>271229</th>\n","      <td>47.666650</td>\n","      <td>-15.666650</td>\n","      <td>39.666650</td>\n","      <td>0.468579</td>\n","      <td>0.012161</td>\n","      <td>0.143829</td>\n","      <td>63.960899</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>346167 rows Ã— 7 columns</p>\n","</div>"],"text/plain":["              ccx        ccy        ccz  ...        U2        U3   distance\n","276101  -3.549367   0.873805   0.165214  ...  0.312564  0.086993   3.659076\n","276075  -3.549369  -0.873805   0.165215  ...  0.425258  0.081138   3.659077\n","276008  -0.873900  -3.549809   0.165215  ...  0.322960  0.072068   3.659527\n","276166  -0.873901   3.549815   0.165213  ...  0.301015  0.068508   3.659534\n","2717     0.873998   3.550097   0.165215  ...  0.066385  0.019641   3.659830\n","276020   0.873998  -3.550097   0.165215  ...  0.084345  0.033828   3.659830\n","2365     3.550562   0.874096   0.165215  ...  0.067213 -0.004526   3.660305\n","276081   3.550562  -0.874096   0.165215  ...  0.469799 -0.036332   3.660305\n","2022    -3.171205  -1.838501   0.165493  ...  0.711182  0.071588   3.669334\n","276122  -3.171205   1.838503   0.165493  ...  0.585344  0.076908   3.669335\n","1845    -1.838588  -3.171412   0.165492  ...  0.638383  0.068604   3.669557\n","276149  -1.838586   3.171413   0.165491  ...  0.574993  0.067115   3.669557\n","276039   1.838924  -3.171949   0.165492  ...  0.046744 -0.038786   3.670189\n","276151   1.838926   3.171952   0.165493  ...  0.039359 -0.056248   3.670193\n","276124   3.172170   1.839009   0.165492  ...  0.154011 -0.027047   3.670423\n","276064   3.172170  -1.839011   0.165492  ...  0.430632  0.008234   3.670424\n","276105  -3.547741   0.874263   0.499513  ...  0.335237  0.121523   3.687861\n","276079  -3.547743  -0.874263   0.499512  ...  0.454766  0.116399   3.687862\n","276012  -0.874355  -3.548183   0.499510  ...  0.366379  0.126965   3.688307\n","276170  -0.874358   3.548190   0.499513  ...  0.334115  0.117156   3.688315\n","276184   0.874456   3.548471   0.499510  ...  0.051430  0.045055   3.688608\n","276024   0.874456  -3.548471   0.499510  ...  0.075397  0.076303   3.688608\n","276085   3.548938  -0.874551   0.499510  ...  0.474620 -0.001005   3.689080\n","276111   3.548938   0.874551   0.499510  ...  0.070300  0.040818   3.689080\n","276046  -2.768935  -2.441561   0.166028  ...  0.782648  0.063859   3.695374\n","276134  -2.768933   2.441566   0.166029  ...  0.690687  0.060777   3.695376\n","276034  -2.441578  -2.768997   0.166029  ...  0.733185  0.061510   3.695431\n","2625    -2.441578   2.769000   0.166029  ...  0.667888  0.060604   3.695434\n","276042   2.442150  -2.769597   0.166028  ...  0.021274 -0.000362   3.696258\n","276153   2.442150   2.769598   0.166029  ...  0.085434  0.000548   3.696260\n","...           ...        ...        ...  ...       ...       ...        ...\n","266909  47.666650 -13.666650  39.000000  ...  0.009181  0.125522  63.086344\n","270845  47.666650  13.666650  39.000000  ...  0.025423  0.122113  63.086344\n","271805  47.666650 -11.666650  39.666650  ...  0.000472  0.121237  63.100423\n","275165  47.666650  11.666650  39.666650  ...  0.038231  0.131068  63.100423\n","266525  47.666650  15.666650  38.333350  ...  0.014984  0.126803  63.142689\n","262013  47.666650 -15.666650  38.333350  ...  0.014148  0.138098  63.142689\n","271420  47.000000 -14.333350  39.666650  ...  0.010970  0.129720  63.149727\n","275548  47.000000  14.333350  39.666650  ...  0.024766  0.118924  63.149727\n","271709  47.666650 -12.333350  39.666650  ...  0.003098  0.122770  63.227084\n","275261  47.666650  12.333350  39.666650  ...  0.034536  0.128563  63.227084\n","266813  47.666650 -14.333350  39.000000  ...  0.013236  0.128506  63.234124\n","270941  47.666650  14.333350  39.000000  ...  0.022857  0.120139  63.234124\n","271324  47.000000 -15.000000  39.666650  ...  0.016012  0.139533  63.304369\n","275644  47.000000  15.000000  39.666650  ...  0.025251  0.120226  63.304369\n","275357  47.666650  13.000000  39.666650  ...  0.030391  0.125559  63.360498\n","271613  47.666650 -13.000000  39.666650  ...  0.005819  0.124484  63.360498\n","271037  47.666650  15.000000  39.000000  ...  0.021635  0.122510  63.388560\n","266717  47.666650 -15.000000  39.000000  ...  0.020162  0.137273  63.388560\n","271228  47.000000 -15.666650  39.666650  ...  0.010697  0.145299  63.465637\n","275740  47.000000  15.666650  39.666650  ...  0.018457  0.129334  63.465637\n","271517  47.666650 -13.666650  39.666650  ...  0.008532  0.126595  63.500630\n","275453  47.666650  13.666650  39.666650  ...  0.026036  0.122583  63.500630\n","266621  47.666650 -15.666650  39.000000  ...  0.013687  0.139690  63.549614\n","271133  47.666650  15.666650  39.000000  ...  0.016491  0.127746  63.549614\n","275549  47.666650  14.333350  39.666650  ...  0.023623  0.120431  63.647447\n","271421  47.666650 -14.333350  39.666650  ...  0.011838  0.130038  63.647447\n","271325  47.666650 -15.000000  39.666650  ...  0.017728  0.139705  63.800883\n","275645  47.666650  15.000000  39.666650  ...  0.022689  0.122407  63.800883\n","275741  47.666650  15.666650  39.666650  ...  0.016842  0.130620  63.960899\n","271229  47.666650 -15.666650  39.666650  ...  0.012161  0.143829  63.960899\n","\n","[346167 rows x 7 columns]"]},"metadata":{"tags":[]},"execution_count":71}]},{"cell_type":"code","metadata":{"id":"dwcmem0ur5C0","colab_type":"code","colab":{}},"source":["df=df.iloc[:,3:9]"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"R0YKB_aksLKq","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":202},"outputId":"86af8946-b476-4ee9-c2d6-38e023c38ca8","executionInfo":{"status":"ok","timestamp":1559448281092,"user_tz":240,"elapsed":35038,"user":{"displayName":"Gautham Bekal","photoUrl":"","userId":"01650273333839084339"}}},"source":["df.head()"],"execution_count":7,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>ccx</th>\n","      <th>ccy</th>\n","      <th>ccz</th>\n","      <th>U1</th>\n","      <th>U2</th>\n","      <th>U3</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>-15.66665</td>\n","      <td>-15.66665</td>\n","      <td>0.333333</td>\n","      <td>1.000053</td>\n","      <td>0.000269</td>\n","      <td>0.000074</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>-15.00000</td>\n","      <td>-15.66665</td>\n","      <td>0.333333</td>\n","      <td>1.000582</td>\n","      <td>0.000954</td>\n","      <td>0.000260</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>-14.33335</td>\n","      <td>-15.66665</td>\n","      <td>0.333333</td>\n","      <td>1.001449</td>\n","      <td>0.001724</td>\n","      <td>0.000427</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>-13.66665</td>\n","      <td>-15.66665</td>\n","      <td>0.333333</td>\n","      <td>1.002579</td>\n","      <td>0.002579</td>\n","      <td>0.000593</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>-13.00000</td>\n","      <td>-15.66665</td>\n","      <td>0.333333</td>\n","      <td>1.003905</td>\n","      <td>0.003499</td>\n","      <td>0.000760</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["        ccx       ccy       ccz        U1        U2        U3\n","0 -15.66665 -15.66665  0.333333  1.000053  0.000269  0.000074\n","1 -15.00000 -15.66665  0.333333  1.000582  0.000954  0.000260\n","2 -14.33335 -15.66665  0.333333  1.001449  0.001724  0.000427\n","3 -13.66665 -15.66665  0.333333  1.002579  0.002579  0.000593\n","4 -13.00000 -15.66665  0.333333  1.003905  0.003499  0.000760"]},"metadata":{"tags":[]},"execution_count":7}]},{"cell_type":"code","metadata":{"id":"6Bkee-Zcs8mu","colab_type":"code","colab":{}},"source":["df['distance']=np.sqrt((df['ccx']**2)+(df['ccy']**2)+(df['ccz']**2))"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"50Cl3EOMv16q","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":202},"outputId":"ac420166-bb64-425b-b748-c867905f1075","executionInfo":{"status":"ok","timestamp":1559448282033,"user_tz":240,"elapsed":35947,"user":{"displayName":"Gautham Bekal","photoUrl":"","userId":"01650273333839084339"}}},"source":["df.head()"],"execution_count":9,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>ccx</th>\n","      <th>ccy</th>\n","      <th>ccz</th>\n","      <th>U1</th>\n","      <th>U2</th>\n","      <th>U3</th>\n","      <th>distance</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>-15.66665</td>\n","      <td>-15.66665</td>\n","      <td>0.333333</td>\n","      <td>1.000053</td>\n","      <td>0.000269</td>\n","      <td>0.000074</td>\n","      <td>22.158496</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>-15.00000</td>\n","      <td>-15.66665</td>\n","      <td>0.333333</td>\n","      <td>1.000582</td>\n","      <td>0.000954</td>\n","      <td>0.000260</td>\n","      <td>21.692281</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>-14.33335</td>\n","      <td>-15.66665</td>\n","      <td>0.333333</td>\n","      <td>1.001449</td>\n","      <td>0.001724</td>\n","      <td>0.000427</td>\n","      <td>21.236760</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>-13.66665</td>\n","      <td>-15.66665</td>\n","      <td>0.333333</td>\n","      <td>1.002579</td>\n","      <td>0.002579</td>\n","      <td>0.000593</td>\n","      <td>20.792603</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>-13.00000</td>\n","      <td>-15.66665</td>\n","      <td>0.333333</td>\n","      <td>1.003905</td>\n","      <td>0.003499</td>\n","      <td>0.000760</td>\n","      <td>20.360625</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["        ccx       ccy       ccz        U1        U2        U3   distance\n","0 -15.66665 -15.66665  0.333333  1.000053  0.000269  0.000074  22.158496\n","1 -15.00000 -15.66665  0.333333  1.000582  0.000954  0.000260  21.692281\n","2 -14.33335 -15.66665  0.333333  1.001449  0.001724  0.000427  21.236760\n","3 -13.66665 -15.66665  0.333333  1.002579  0.002579  0.000593  20.792603\n","4 -13.00000 -15.66665  0.333333  1.003905  0.003499  0.000760  20.360625"]},"metadata":{"tags":[]},"execution_count":9}]},{"cell_type":"code","metadata":{"id":"tobqogY2wK7F","colab_type":"code","colab":{}},"source":["df=df.sort_values('distance')"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"ehV5tjtywUxL","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":202},"outputId":"64518758-a7be-4052-963f-d24d0c64ed15","executionInfo":{"status":"ok","timestamp":1559448282038,"user_tz":240,"elapsed":35927,"user":{"displayName":"Gautham Bekal","photoUrl":"","userId":"01650273333839084339"}}},"source":["df.head()"],"execution_count":11,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>ccx</th>\n","      <th>ccy</th>\n","      <th>ccz</th>\n","      <th>U1</th>\n","      <th>U2</th>\n","      <th>U3</th>\n","      <th>distance</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>276101</th>\n","      <td>-3.549367</td>\n","      <td>0.873805</td>\n","      <td>0.165214</td>\n","      <td>0.157078</td>\n","      <td>0.312564</td>\n","      <td>0.086993</td>\n","      <td>3.659076</td>\n","    </tr>\n","    <tr>\n","      <th>276075</th>\n","      <td>-3.549369</td>\n","      <td>-0.873805</td>\n","      <td>0.165215</td>\n","      <td>0.186573</td>\n","      <td>0.425258</td>\n","      <td>0.081138</td>\n","      <td>3.659077</td>\n","    </tr>\n","    <tr>\n","      <th>276008</th>\n","      <td>-0.873900</td>\n","      <td>-3.549809</td>\n","      <td>0.165215</td>\n","      <td>1.250538</td>\n","      <td>0.322960</td>\n","      <td>0.072068</td>\n","      <td>3.659527</td>\n","    </tr>\n","    <tr>\n","      <th>276166</th>\n","      <td>-0.873901</td>\n","      <td>3.549815</td>\n","      <td>0.165213</td>\n","      <td>1.157566</td>\n","      <td>0.301015</td>\n","      <td>0.068508</td>\n","      <td>3.659534</td>\n","    </tr>\n","    <tr>\n","      <th>2717</th>\n","      <td>0.873998</td>\n","      <td>3.550097</td>\n","      <td>0.165215</td>\n","      <td>0.683874</td>\n","      <td>0.066385</td>\n","      <td>0.019641</td>\n","      <td>3.659830</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["             ccx       ccy       ccz        U1        U2        U3  distance\n","276101 -3.549367  0.873805  0.165214  0.157078  0.312564  0.086993  3.659076\n","276075 -3.549369 -0.873805  0.165215  0.186573  0.425258  0.081138  3.659077\n","276008 -0.873900 -3.549809  0.165215  1.250538  0.322960  0.072068  3.659527\n","276166 -0.873901  3.549815  0.165213  1.157566  0.301015  0.068508  3.659534\n","2717    0.873998  3.550097  0.165215  0.683874  0.066385  0.019641  3.659830"]},"metadata":{"tags":[]},"execution_count":11}]},{"cell_type":"code","metadata":{"id":"wq8qEEV0n9sv","colab_type":"code","colab":{}},"source":["X=df.iloc[:,3:7].values"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"E5l3IjlJrlwy","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":35},"outputId":"b83de614-fc8c-437c-e305-144a0a188bea","executionInfo":{"status":"ok","timestamp":1559448282042,"user_tz":240,"elapsed":35892,"user":{"displayName":"Gautham Bekal","photoUrl":"","userId":"01650273333839084339"}}},"source":["X.shape"],"execution_count":13,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(346167, 4)"]},"metadata":{"tags":[]},"execution_count":13}]},{"cell_type":"code","metadata":{"id":"7RvCiovix57R","colab_type":"code","colab":{}},"source":["#X=X[0:22000]"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"Avo2cF-ByIpN","colab_type":"code","colab":{}},"source":["X=X[:,0:3]"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"ndcWtrHAzGZ-","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":35},"outputId":"4d23535e-4ac2-4c5e-ac5e-320e7c71f685","executionInfo":{"status":"ok","timestamp":1559448282054,"user_tz":240,"elapsed":35864,"user":{"displayName":"Gautham Bekal","photoUrl":"","userId":"01650273333839084339"}}},"source":["X[0]"],"execution_count":16,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([0.15707782, 0.31256394, 0.08699269])"]},"metadata":{"tags":[]},"execution_count":16}]},{"cell_type":"code","metadata":{"id":"4tXn_4FuwmEO","colab_type":"code","colab":{}},"source":["sequential_data=[]\n","nearby_velocities =deque(maxlen=101)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"PMnfY1Uixsg9","colab_type":"code","colab":{}},"source":["#Creates the complete sequential data to be split into train and test sequences\n","for i in range(0,len(X)-1):\n","  nearby_velocities.append([n for n in X[i]])\n","  if len(nearby_velocities) ==101:\n","    sequential_data.append([np.array(nearby_velocities),np.array(nearby_velocities[50])])\n","\n","    "],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"cFOJz8yh4Hb3","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":35},"outputId":"a6f05519-aa2d-446d-bdcf-b336f8de837a","executionInfo":{"status":"ok","timestamp":1559448303068,"user_tz":240,"elapsed":56846,"user":{"displayName":"Gautham Bekal","photoUrl":"","userId":"01650273333839084339"}}},"source":["len(sequential_data)"],"execution_count":19,"outputs":[{"output_type":"execute_result","data":{"text/plain":["346066"]},"metadata":{"tags":[]},"execution_count":19}]},{"cell_type":"code","metadata":{"id":"TJBBtZ_H1VAZ","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":1768035,"output_embedded_package_id":"15Hz-1MGsvvRtCFycHTmhVjNOm90NIrgw"},"outputId":"a0f15f73-55a8-4e51-b897-267e79367d60","executionInfo":{"status":"ok","timestamp":1559448308075,"user_tz":240,"elapsed":61843,"user":{"displayName":"Gautham Bekal","photoUrl":"","userId":"01650273333839084339"}}},"source":["sequential_data"],"execution_count":20,"outputs":[{"output_type":"display_data","data":{"text/plain":"Output hidden; open in https://colab.research.google.com to view."},"metadata":{}}]},{"cell_type":"code","metadata":{"id":"gjKwNCfk3Eqg","colab_type":"code","colab":{}},"source":["random.shuffle(sequential_data)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"wRbtFTkBJI36","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":1768035,"output_embedded_package_id":"1JEe_rkvmPUsdUmvxkPqpv4NNKy9wraZ1"},"outputId":"ec3706fc-9b04-49e1-e437-85d5699bb2f0","executionInfo":{"status":"ok","timestamp":1559448314407,"user_tz":240,"elapsed":68150,"user":{"displayName":"Gautham Bekal","photoUrl":"","userId":"01650273333839084339"}}},"source":["#AFTER SHUFFLING\n","sequential_data"],"execution_count":22,"outputs":[{"output_type":"display_data","data":{"text/plain":"Output hidden; open in https://colab.research.google.com to view."},"metadata":{}}]},{"cell_type":"code","metadata":{"id":"SBkxAkEU1tuo","colab_type":"code","colab":{}},"source":["X_train=array([n[0] for n in sequential_data[0:20000]])\n","X_validate=array([n[0] for n in sequential_data[20000:22000]])"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"0NnMZb2W8MYM","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":52},"outputId":"917db2e5-d5bb-48b0-a767-d7ca32489bb5","executionInfo":{"status":"ok","timestamp":1559448314412,"user_tz":240,"elapsed":68134,"user":{"displayName":"Gautham Bekal","photoUrl":"","userId":"01650273333839084339"}}},"source":["print(X_train.shape)\n","print(X_validate.shape)"],"execution_count":24,"outputs":[{"output_type":"stream","text":["(20000, 101, 3)\n","(2000, 101, 3)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"w3O8AEGcp70n","colab_type":"code","colab":{}},"source":["#X_train=np.delete(X_train,50,1) #The first number 50 is index value and 1 means 2nd dimension\n","#X_validate=np.delete(X_validate,50,1)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"2Ft_NO51t5HE","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":52},"outputId":"2fd4c4c9-ce63-48dc-a0f3-bdd83f97db1d","executionInfo":{"status":"ok","timestamp":1559448314417,"user_tz":240,"elapsed":68113,"user":{"displayName":"Gautham Bekal","photoUrl":"","userId":"01650273333839084339"}}},"source":["print(X_train.shape)\n","print(X_validate.shape)"],"execution_count":26,"outputs":[{"output_type":"stream","text":["(20000, 100, 3)\n","(2000, 100, 3)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"TbZGzZpp9LrO","colab_type":"code","colab":{}},"source":["Y_train=array([n[1] for n in sequential_data[0:20000]])\n","Y_validate=array([n[1] for n in sequential_data[20000:22000]])  #Y_test will be used for validation"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"ns8t9IEt9Uow","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":52},"outputId":"db29fabd-4062-41a3-bb3d-54f30060f247","executionInfo":{"status":"ok","timestamp":1559448314430,"user_tz":240,"elapsed":68103,"user":{"displayName":"Gautham Bekal","photoUrl":"","userId":"01650273333839084339"}}},"source":["print(Y_train.shape)\n","print(Y_validate.shape)"],"execution_count":28,"outputs":[{"output_type":"stream","text":["(20000, 3)\n","(2000, 3)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"2YX6ghSr_OfR","colab_type":"code","colab":{}},"source":["from sklearn.preprocessing import StandardScaler"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"EYd7QGZC_QUw","colab_type":"code","colab":{}},"source":["sc_X=StandardScaler()\n","sc_Y=StandardScaler()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"O76eMwLT9htf","colab_type":"code","colab":{}},"source":["X_train[:,:,1]=sc_X.fit_transform(X_train[:,:,1])\n","X_train[:,:,0]=sc_X.fit_transform(X_train[:,:,0])\n","X_train[:,:,2]=sc_X.fit_transform(X_train[:,:,2])"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"xUd3lD3LBK_M","colab_type":"code","colab":{}},"source":["X_validate[:,:,1]=sc_X.fit_transform(X_validate[:,:,1])\n","X_validate[:,:,0]=sc_X.fit_transform(X_validate[:,:,0])\n","X_validate[:,:,2]=sc_X.fit_transform(X_validate[:,:,2])"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"U5JHE8yZBRRw","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":867},"outputId":"483a35f3-0a96-4f9c-c2fe-b1b156cabae1","executionInfo":{"status":"ok","timestamp":1559448314454,"user_tz":240,"elapsed":68077,"user":{"displayName":"Gautham Bekal","photoUrl":"","userId":"01650273333839084339"}}},"source":["X_train"],"execution_count":33,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([[[-1.76189576,  0.34568104, -0.38289055],\n","        [-1.75109863,  0.81202963, -0.38975975],\n","        [-0.21472856,  0.86945198, -0.25593407],\n","        ...,\n","        [ 0.59671256,  4.17212048, -0.21610954],\n","        [ 0.43249425,  3.63008846, -0.21648517],\n","        [ 1.09394425,  3.46369395, -0.20450057]],\n","\n","       [[-0.51887069, -0.70874268, -0.28325983],\n","        [-0.56197857, -0.76261839, -0.28966892],\n","        [-0.66350711, -0.7402436 , -0.31082816],\n","        ...,\n","        [-0.59794988, -0.6405061 , -0.30788328],\n","        [-0.67717353, -0.74711414, -0.30859011],\n","        [-0.682392  , -0.72980079, -0.30768277]],\n","\n","       [[-1.29334115, -0.77461058,  5.16655002],\n","        [-1.08860434, -0.35434071,  5.23776061],\n","        [-1.0997894 , -0.36277976,  5.17466579],\n","        ...,\n","        [-1.05258929,  0.09326407,  3.48086949],\n","        [ 1.40086839,  1.21391271, -0.21147668],\n","        [ 1.60637748,  1.47169633, -0.21225307]],\n","\n","       ...,\n","\n","       [[-1.45588126, -0.37603201,  0.28442579],\n","        [ 0.96532543, -0.05523167, -0.32730729],\n","        [-0.42263833, -0.59690605, -0.2893695 ],\n","        ...,\n","        [ 0.60683871,  4.29788602,  2.62248474],\n","        [-1.36394827,  0.36672043,  1.95961816],\n","        [-0.63136428, -0.30079461, -0.25850353]],\n","\n","       [[-0.8714624 , -0.40342919, -0.2296822 ],\n","        [-0.86427744, -0.45524654, -0.23635923],\n","        [-0.57858822, -0.7650785 , -0.20148661],\n","        ...,\n","        [-0.77198556, -0.5201218 , -0.26799897],\n","        [-0.50656731, -0.76062303, -0.29976186],\n","        [-0.65219825, -0.64576271, -0.29531096]],\n","\n","       [[ 1.08885789, -0.57301768, -0.31447776],\n","        [-0.41005388, -0.63431878, -0.28466457],\n","        [-0.42306321, -0.76892071, -0.24956296],\n","        ...,\n","        [ 0.92078096, -0.2206053 , -0.32925989],\n","        [-1.5802209 , -0.37310037,  0.29933289],\n","        [-0.45494132, -0.52700995, -0.28845376]]])"]},"metadata":{"tags":[]},"execution_count":33}]},{"cell_type":"code","metadata":{"id":"OAuoqDmEBao_","colab_type":"code","colab":{}},"source":["Y_train=sc_Y.fit_transform(Y_train)\n","Y_validate=sc_Y.fit_transform(Y_validate)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"N8sZ1Xa_BoHI","colab_type":"code","colab":{}},"source":["                                    #RECURSIVE DEEP NEURAL NETWORK\n","\n","import torch\n","import torch.nn as nn\n","import torchvision.datasets as datasets  #import the dataset\n","import torchvision.transforms as transforms  #\n","from torch.autograd import Variable  #autograd is a part of pytorch 0.3 but can also be used with pytorch 0.4\n","from torch.utils.data import Dataset\n","import sys"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"sYEYE8_jCy8d","colab_type":"code","colab":{}},"source":["                                    #CONVERT NUMPY TO PYTORCH \n","X_train=torch.tensor(X_train)\n","Y_train=torch.tensor(Y_train)\n","X_validate=torch.tensor(X_validate)\n","Y_validate=torch.tensor(Y_validate)\n","#CONVERT PYTORCH TENSOR TO VARIABLE FORMAT\n","X_validate=Variable(X_validate)\n","Y_validate=Variable(Y_validate)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"os3BkajYEpiH","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":52},"outputId":"0aaeeff5-acf8-434a-e7be-caea4555654f","executionInfo":{"status":"ok","timestamp":1559448316530,"user_tz":240,"elapsed":70106,"user":{"displayName":"Gautham Bekal","photoUrl":"","userId":"01650273333839084339"}}},"source":["print(X_train.shape)\n","print(X_validate.shape)"],"execution_count":37,"outputs":[{"output_type":"stream","text":["torch.Size([20000, 100, 3])\n","torch.Size([2000, 100, 3])\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"ezxGesoxKsvw","colab_type":"code","colab":{}},"source":["#WHEN WE ARE USING OUR OWN DATASET THEN WE NEED TO CREATE A DATASET CLASS WHICH INHERITS FROM PREDEFINED \n","#DATASET CLASS OF torch.utils.data library\n","class Dataset(Dataset):\n","  def __init__(self,x,y):\n","    self.x=x\n","    self.y=y\n","  \n","  def __getitem__(self,index):\n","    return self.x[index], self.y[index]\n","  \n","  def __len__(self):\n","    return len(self.x)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"enDFWDGcKi23","colab_type":"code","colab":{}},"source":["train_dataset=Dataset(X_train,Y_train)\n","validate_dataset=Dataset(X_validate,Y_validate)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"OvLXuTigL84f","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":87},"outputId":"23befe3f-9c7f-43dd-855c-dcd78a62dbda","executionInfo":{"status":"ok","timestamp":1559448316540,"user_tz":240,"elapsed":70085,"user":{"displayName":"Gautham Bekal","photoUrl":"","userId":"01650273333839084339"}}},"source":["print(train_dataset.x.shape)\n","print(train_dataset.y.shape)\n","print(validate_dataset.x.shape)\n","print(validate_dataset.y.shape)"],"execution_count":40,"outputs":[{"output_type":"stream","text":["torch.Size([20000, 100, 3])\n","torch.Size([20000, 3])\n","torch.Size([2000, 100, 3])\n","torch.Size([2000, 3])\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"Cr0RaOD9NpGQ","colab_type":"code","colab":{}},"source":["#MAKE DATA ITERABLE BY LOADING IT TO A LOADER. Shuffe the data to make it independent of order\n","#Batch size is the number of elements in a batch\n","train_loader=torch.utils.data.DataLoader(dataset=train_dataset,\n","                                        batch_size=200,\n","                                        shuffle=True)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"bUCMAU-EpCwa","colab_type":"code","colab":{}},"source":["#MAKE DATA ITERABLE BY LOADING IT TO A LOADER. Shuffe the data to make it independent of order\n","#Batch size is the number of elements in a batch\n","validation_loader=torch.utils.data.DataLoader(dataset=validate_dataset,\n","                                        batch_size=200,\n","                                        shuffle=False)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"iSx1CkuKNuM4","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":35},"outputId":"f2c6bcbb-82d5-4a4e-9ef2-6727bbc7821c","executionInfo":{"status":"ok","timestamp":1559448317030,"user_tz":240,"elapsed":70548,"user":{"displayName":"Gautham Bekal","photoUrl":"","userId":"01650273333839084339"}}},"source":["len(validation_loader)"],"execution_count":43,"outputs":[{"output_type":"execute_result","data":{"text/plain":["10"]},"metadata":{"tags":[]},"execution_count":43}]},{"cell_type":"code","metadata":{"id":"C7MGnbK_O71u","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":87},"outputId":"28843855-2cf4-4628-f955-1aa062f3db32","executionInfo":{"status":"ok","timestamp":1559448317032,"user_tz":240,"elapsed":70539,"user":{"displayName":"Gautham Bekal","photoUrl":"","userId":"01650273333839084339"}}},"source":["#THIS IS ONLY FOR DISPLAY PURPOSE TO UNDERSTAND THE DATA\n","print(\"There is {} batches in the dataset\".format(len(train_loader)))\n","shown=0\n","for (x,y) in train_loader:\n","  if shown==1:\n","    break\n","  print(\"For one batch there is:\")\n","  print(\"Data: {}, Type: {} \".format(x.shape,x.dtype))\n","  print(\"Data: {}, Type: {} \".format(y.shape,y.dtype))\n","  shown+=1\n","  "],"execution_count":44,"outputs":[{"output_type":"stream","text":["There is 100 batches in the dataset\n","For one batch there is:\n","Data: torch.Size([200, 100, 3]), Type: torch.float64 \n","Data: torch.Size([200, 3]), Type: torch.float64 \n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"-tL7XW3bPHe6","colab_type":"code","colab":{}},"source":["#Input of neural net 2 nodes and output of the neural net is 3 nodes\n","# Neural Net using 3 hidden layers each containing 3 nodes \n","\n","input_size=3\n","hidden_size=3\n","\n","class Model(nn.Module):\n","  def __init__(self):\n","    super(Model,self).__init__()\n","    self.bi_rcnn1=torch.nn.LSTM(input_size=3, hidden_size=3, num_layers=1, batch_first=False, bidirectional=True)   \n","    self.fc1=torch.nn.Linear(6,3)\n","              \n","    \n","    #Input hidden hidden output  =>layer format\n","  def forward(self,x):\n","      out,hidden=self.bi_rcnn1(x)  \n","      out=out[:,50]  #Middle value-1 6 input values to fully connected layer\n","      out=self.fc1(out)\n","      return out  \n","  \n","  def init_hidden(self):\n","      # Initialize hidden and cell states\n","      # (num_layers * num_directions, batch, hidden_size)\n","      return Variable(torch.zeros(1, 200, 3))\n","\n","    "],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"BRD4-ESbYtcv","colab_type":"code","colab":{}},"source":["# Instantiate RNN model\n","model = Model()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"IMM45imVY3Yx","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":87},"outputId":"a37e2602-ba1c-434b-d46b-8104d874316d","executionInfo":{"status":"ok","timestamp":1559448317043,"user_tz":240,"elapsed":70521,"user":{"displayName":"Gautham Bekal","photoUrl":"","userId":"01650273333839084339"}}},"source":["print(model.parameters)"],"execution_count":47,"outputs":[{"output_type":"stream","text":["<bound method Module.parameters of Model(\n","  (bi_rcnn1): LSTM(3, 3, bidirectional=True)\n","  (fc1): Linear(in_features=6, out_features=3, bias=True)\n",")>\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"zCfaMH-znL3B","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":72},"outputId":"ca04716a-c1d7-46dc-d9f7-8546fa69014f","executionInfo":{"status":"ok","timestamp":1559448317044,"user_tz":240,"elapsed":70508,"user":{"displayName":"Gautham Bekal","photoUrl":"","userId":"01650273333839084339"}}},"source":["criterion=torch.nn.MSELoss(size_average=True)   #Loss Criterion\n","optimizer=torch.optim.Adam(model.parameters(),lr=0.01)"],"execution_count":48,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='mean' instead.\n","  warnings.warn(warning.format(ret))\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"da35V3LtY6ni","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":17351},"outputId":"3ce20c5a-d18b-4ec3-c9ec-10ef961bd190","executionInfo":{"status":"ok","timestamp":1559454968169,"user_tz":240,"elapsed":2800333,"user":{"displayName":"Gautham Bekal","photoUrl":"","userId":"01650273333839084339"}}},"source":["epochs=100   #We have done it for 100 epochs \n","for epoch in range(epochs):\n","  for x, y in train_loader:\n","    x=Variable(x.float())\n","    y=Variable(y.float())\n","    outputs=model(x)\n","    optimizer.zero_grad()\n","    \n","    loss=criterion(outputs,y)\n","    loss.backward()\n","    optimizer.step()\n","  \n","  print(\"EPOCH {} COMPLETED\".format(epoch))\n","  print(\"Training loss: {}\".format(loss.item()))"],"execution_count":49,"outputs":[{"output_type":"stream","text":["EPOCH 0 COMPLETED\n","Training loss: 0.7295355796813965\n","EPOCH 1 COMPLETED\n","Training loss: 0.5258730053901672\n","EPOCH 2 COMPLETED\n","Training loss: 0.7450513243675232\n","EPOCH 3 COMPLETED\n","Training loss: 0.703131377696991\n","EPOCH 4 COMPLETED\n","Training loss: 0.7265751361846924\n","EPOCH 5 COMPLETED\n","Training loss: 0.7460402250289917\n","EPOCH 6 COMPLETED\n","Training loss: 0.6009770035743713\n","EPOCH 7 COMPLETED\n","Training loss: 0.6993603110313416\n","EPOCH 8 COMPLETED\n","Training loss: 0.5584316849708557\n","EPOCH 9 COMPLETED\n","Training loss: 0.7702839970588684\n","EPOCH 10 COMPLETED\n","Training loss: 0.7382069826126099\n","EPOCH 11 COMPLETED\n","Training loss: 0.5713150501251221\n","EPOCH 12 COMPLETED\n","Training loss: 0.6562929749488831\n","EPOCH 13 COMPLETED\n","Training loss: 0.6742871403694153\n","EPOCH 14 COMPLETED\n","Training loss: 0.41964834928512573\n","EPOCH 15 COMPLETED\n","Training loss: 0.5739167332649231\n","EPOCH 16 COMPLETED\n","Training loss: 0.7302465438842773\n","EPOCH 17 COMPLETED\n","Training loss: 0.6172370910644531\n","EPOCH 18 COMPLETED\n","Training loss: 0.832015872001648\n","EPOCH 19 COMPLETED\n","Training loss: 0.632999062538147\n","EPOCH 20 COMPLETED\n","Training loss: 0.5371153354644775\n","EPOCH 21 COMPLETED\n","Training loss: 0.6437430381774902\n","EPOCH 22 COMPLETED\n","Training loss: 0.6237054467201233\n","EPOCH 23 COMPLETED\n","Training loss: 0.5952484011650085\n","EPOCH 24 COMPLETED\n","Training loss: 0.8424222469329834\n","EPOCH 25 COMPLETED\n","Training loss: 0.6329050064086914\n","EPOCH 26 COMPLETED\n","Training loss: 0.6258176565170288\n","EPOCH 27 COMPLETED\n","Training loss: 0.6478738188743591\n","EPOCH 28 COMPLETED\n","Training loss: 0.6763092875480652\n","EPOCH 29 COMPLETED\n","Training loss: 0.5283512473106384\n","EPOCH 30 COMPLETED\n","Training loss: 0.7401987314224243\n","EPOCH 31 COMPLETED\n","Training loss: 0.6854779124259949\n","EPOCH 32 COMPLETED\n","Training loss: 0.7153712511062622\n","EPOCH 33 COMPLETED\n","Training loss: 0.5668667554855347\n","EPOCH 34 COMPLETED\n","Training loss: 0.7463586926460266\n","EPOCH 35 COMPLETED\n","Training loss: 0.6038421392440796\n","EPOCH 36 COMPLETED\n","Training loss: 0.6030190587043762\n","EPOCH 37 COMPLETED\n","Training loss: 0.5824782252311707\n","EPOCH 38 COMPLETED\n","Training loss: 0.697260856628418\n","EPOCH 39 COMPLETED\n","Training loss: 0.7426250576972961\n","EPOCH 40 COMPLETED\n","Training loss: 0.5155931115150452\n","EPOCH 41 COMPLETED\n","Training loss: 0.8092057108879089\n","EPOCH 42 COMPLETED\n","Training loss: 0.7786662578582764\n","EPOCH 43 COMPLETED\n","Training loss: 0.497835248708725\n","EPOCH 44 COMPLETED\n","Training loss: 0.6695605516433716\n","EPOCH 45 COMPLETED\n","Training loss: 0.8195524215698242\n","EPOCH 46 COMPLETED\n","Training loss: 0.8678067922592163\n","EPOCH 47 COMPLETED\n","Training loss: 0.7797716856002808\n","EPOCH 48 COMPLETED\n","Training loss: 0.5010072588920593\n","EPOCH 49 COMPLETED\n","Training loss: 0.6172264218330383\n","EPOCH 50 COMPLETED\n","Training loss: 0.44054728746414185\n","EPOCH 51 COMPLETED\n","Training loss: 0.6074120402336121\n","EPOCH 52 COMPLETED\n","Training loss: 0.5446517467498779\n","EPOCH 53 COMPLETED\n","Training loss: 0.5191140174865723\n","EPOCH 54 COMPLETED\n","Training loss: 0.6720255613327026\n","EPOCH 55 COMPLETED\n","Training loss: 0.5360282063484192\n","EPOCH 56 COMPLETED\n","Training loss: 0.639107346534729\n","EPOCH 57 COMPLETED\n","Training loss: 0.563778281211853\n","EPOCH 58 COMPLETED\n","Training loss: 0.5792092680931091\n","EPOCH 59 COMPLETED\n","Training loss: 0.5598112344741821\n","EPOCH 60 COMPLETED\n","Training loss: 0.6616549491882324\n","EPOCH 61 COMPLETED\n","Training loss: 0.5948680639266968\n","EPOCH 62 COMPLETED\n","Training loss: 0.6558797359466553\n","EPOCH 63 COMPLETED\n","Training loss: 0.5619891881942749\n","EPOCH 64 COMPLETED\n","Training loss: 0.625755250453949\n","EPOCH 65 COMPLETED\n","Training loss: 0.6513394713401794\n","EPOCH 66 COMPLETED\n","Training loss: 0.6625456809997559\n","EPOCH 67 COMPLETED\n","Training loss: 0.638613760471344\n","EPOCH 68 COMPLETED\n","Training loss: 0.5321028232574463\n","EPOCH 69 COMPLETED\n","Training loss: 0.5998020768165588\n","EPOCH 70 COMPLETED\n","Training loss: 0.7900547385215759\n","EPOCH 71 COMPLETED\n","Training loss: 0.6471313834190369\n","EPOCH 72 COMPLETED\n","Training loss: 0.8144316077232361\n","EPOCH 73 COMPLETED\n","Training loss: 0.5803380608558655\n","EPOCH 74 COMPLETED\n","Training loss: 0.5444541573524475\n","EPOCH 75 COMPLETED\n","Training loss: 0.5233646631240845\n","EPOCH 76 COMPLETED\n","Training loss: 0.5411121249198914\n","EPOCH 77 COMPLETED\n","Training loss: 0.7364659905433655\n","EPOCH 78 COMPLETED\n","Training loss: 0.6270213723182678\n","EPOCH 79 COMPLETED\n","Training loss: 0.5164358019828796\n","EPOCH 80 COMPLETED\n","Training loss: 0.557834804058075\n","EPOCH 81 COMPLETED\n","Training loss: 0.5998508334159851\n","EPOCH 82 COMPLETED\n","Training loss: 0.6945645213127136\n","EPOCH 83 COMPLETED\n","Training loss: 0.6200970411300659\n","EPOCH 84 COMPLETED\n","Training loss: 0.5114485621452332\n","EPOCH 85 COMPLETED\n","Training loss: 0.7008734345436096\n","EPOCH 86 COMPLETED\n","Training loss: 0.6007934212684631\n","EPOCH 87 COMPLETED\n","Training loss: 0.7114662528038025\n","EPOCH 88 COMPLETED\n","Training loss: 0.5144699215888977\n","EPOCH 89 COMPLETED\n","Training loss: 0.7174833416938782\n","EPOCH 90 COMPLETED\n","Training loss: 0.4411112666130066\n","EPOCH 91 COMPLETED\n","Training loss: 0.6063515543937683\n","EPOCH 92 COMPLETED\n","Training loss: 0.6319069266319275\n","EPOCH 93 COMPLETED\n","Training loss: 0.7493976354598999\n","EPOCH 94 COMPLETED\n","Training loss: 0.9087080955505371\n","EPOCH 95 COMPLETED\n","Training loss: 0.48376619815826416\n","EPOCH 96 COMPLETED\n","Training loss: 0.5581664443016052\n","EPOCH 97 COMPLETED\n","Training loss: 0.5509819984436035\n","EPOCH 98 COMPLETED\n","Training loss: 0.5246944427490234\n","EPOCH 99 COMPLETED\n","Training loss: 0.5507463812828064\n","EPOCH 100 COMPLETED\n","Training loss: 0.5211666822433472\n","EPOCH 101 COMPLETED\n","Training loss: 0.7374582290649414\n","EPOCH 102 COMPLETED\n","Training loss: 0.5761882066726685\n","EPOCH 103 COMPLETED\n","Training loss: 0.6688022017478943\n","EPOCH 104 COMPLETED\n","Training loss: 0.6233617663383484\n","EPOCH 105 COMPLETED\n","Training loss: 0.5055407285690308\n","EPOCH 106 COMPLETED\n","Training loss: 0.5931483507156372\n","EPOCH 107 COMPLETED\n","Training loss: 0.5617806911468506\n","EPOCH 108 COMPLETED\n","Training loss: 0.5644611120223999\n","EPOCH 109 COMPLETED\n","Training loss: 0.5997858047485352\n","EPOCH 110 COMPLETED\n","Training loss: 0.6273633241653442\n","EPOCH 111 COMPLETED\n","Training loss: 0.7508169412612915\n","EPOCH 112 COMPLETED\n","Training loss: 0.6106164455413818\n","EPOCH 113 COMPLETED\n","Training loss: 0.4749278426170349\n","EPOCH 114 COMPLETED\n","Training loss: 0.7947801947593689\n","EPOCH 115 COMPLETED\n","Training loss: 0.5728377103805542\n","EPOCH 116 COMPLETED\n","Training loss: 0.6894882321357727\n","EPOCH 117 COMPLETED\n","Training loss: 0.8046798706054688\n","EPOCH 118 COMPLETED\n","Training loss: 0.6345584988594055\n","EPOCH 119 COMPLETED\n","Training loss: 0.8728312849998474\n","EPOCH 120 COMPLETED\n","Training loss: 0.48269912600517273\n","EPOCH 121 COMPLETED\n","Training loss: 0.7002049684524536\n","EPOCH 122 COMPLETED\n","Training loss: 0.5726107358932495\n","EPOCH 123 COMPLETED\n","Training loss: 0.6357607245445251\n","EPOCH 124 COMPLETED\n","Training loss: 0.6632012128829956\n","EPOCH 125 COMPLETED\n","Training loss: 0.6956415176391602\n","EPOCH 126 COMPLETED\n","Training loss: 0.7893426418304443\n","EPOCH 127 COMPLETED\n","Training loss: 0.7816670536994934\n","EPOCH 128 COMPLETED\n","Training loss: 0.6393120288848877\n","EPOCH 129 COMPLETED\n","Training loss: 0.6989097595214844\n","EPOCH 130 COMPLETED\n","Training loss: 0.6815232634544373\n","EPOCH 131 COMPLETED\n","Training loss: 0.638676106929779\n","EPOCH 132 COMPLETED\n","Training loss: 0.6148951053619385\n","EPOCH 133 COMPLETED\n","Training loss: 0.5628480315208435\n","EPOCH 134 COMPLETED\n","Training loss: 0.4967995882034302\n","EPOCH 135 COMPLETED\n","Training loss: 0.6655436158180237\n","EPOCH 136 COMPLETED\n","Training loss: 0.7367988228797913\n","EPOCH 137 COMPLETED\n","Training loss: 0.6599127650260925\n","EPOCH 138 COMPLETED\n","Training loss: 0.3892253339290619\n","EPOCH 139 COMPLETED\n","Training loss: 0.6284735202789307\n","EPOCH 140 COMPLETED\n","Training loss: 0.5733466744422913\n","EPOCH 141 COMPLETED\n","Training loss: 0.7869952917098999\n","EPOCH 142 COMPLETED\n","Training loss: 0.5915985703468323\n","EPOCH 143 COMPLETED\n","Training loss: 0.6607456207275391\n","EPOCH 144 COMPLETED\n","Training loss: 0.5863567590713501\n","EPOCH 145 COMPLETED\n","Training loss: 0.7881498336791992\n","EPOCH 146 COMPLETED\n","Training loss: 0.5648483633995056\n","EPOCH 147 COMPLETED\n","Training loss: 0.7794963121414185\n","EPOCH 148 COMPLETED\n","Training loss: 0.6639320254325867\n","EPOCH 149 COMPLETED\n","Training loss: 0.693633496761322\n","EPOCH 150 COMPLETED\n","Training loss: 0.55876225233078\n","EPOCH 151 COMPLETED\n","Training loss: 0.7415313124656677\n","EPOCH 152 COMPLETED\n","Training loss: 0.6018280982971191\n","EPOCH 153 COMPLETED\n","Training loss: 0.8365795016288757\n","EPOCH 154 COMPLETED\n","Training loss: 0.5948435664176941\n","EPOCH 155 COMPLETED\n","Training loss: 0.6170777678489685\n","EPOCH 156 COMPLETED\n","Training loss: 0.7507243156433105\n","EPOCH 157 COMPLETED\n","Training loss: 0.6581721901893616\n","EPOCH 158 COMPLETED\n","Training loss: 0.7426480650901794\n","EPOCH 159 COMPLETED\n","Training loss: 0.7088828086853027\n","EPOCH 160 COMPLETED\n","Training loss: 0.686667263507843\n","EPOCH 161 COMPLETED\n","Training loss: 0.49782437086105347\n","EPOCH 162 COMPLETED\n","Training loss: 0.7387974858283997\n","EPOCH 163 COMPLETED\n","Training loss: 0.6570866703987122\n","EPOCH 164 COMPLETED\n","Training loss: 0.5426163077354431\n","EPOCH 165 COMPLETED\n","Training loss: 0.7960860133171082\n","EPOCH 166 COMPLETED\n","Training loss: 0.6690988540649414\n","EPOCH 167 COMPLETED\n","Training loss: 0.6192320585250854\n","EPOCH 168 COMPLETED\n","Training loss: 0.6903674602508545\n","EPOCH 169 COMPLETED\n","Training loss: 0.6194232702255249\n","EPOCH 170 COMPLETED\n","Training loss: 0.5553375482559204\n","EPOCH 171 COMPLETED\n","Training loss: 0.5905476212501526\n","EPOCH 172 COMPLETED\n","Training loss: 0.6095803380012512\n","EPOCH 173 COMPLETED\n","Training loss: 0.5795685648918152\n","EPOCH 174 COMPLETED\n","Training loss: 0.6128622889518738\n","EPOCH 175 COMPLETED\n","Training loss: 0.9307950139045715\n","EPOCH 176 COMPLETED\n","Training loss: 0.4775237441062927\n","EPOCH 177 COMPLETED\n","Training loss: 0.6288291811943054\n","EPOCH 178 COMPLETED\n","Training loss: 0.6017866134643555\n","EPOCH 179 COMPLETED\n","Training loss: 0.5438156723976135\n","EPOCH 180 COMPLETED\n","Training loss: 0.6097859740257263\n","EPOCH 181 COMPLETED\n","Training loss: 0.710692822933197\n","EPOCH 182 COMPLETED\n","Training loss: 0.6726349592208862\n","EPOCH 183 COMPLETED\n","Training loss: 0.6641700863838196\n","EPOCH 184 COMPLETED\n","Training loss: 0.6946845054626465\n","EPOCH 185 COMPLETED\n","Training loss: 0.6422879695892334\n","EPOCH 186 COMPLETED\n","Training loss: 0.44513460993766785\n","EPOCH 187 COMPLETED\n","Training loss: 0.7935020923614502\n","EPOCH 188 COMPLETED\n","Training loss: 0.6892814040184021\n","EPOCH 189 COMPLETED\n","Training loss: 0.7111767530441284\n","EPOCH 190 COMPLETED\n","Training loss: 0.5569442510604858\n","EPOCH 191 COMPLETED\n","Training loss: 0.6980600953102112\n","EPOCH 192 COMPLETED\n","Training loss: 0.7210234999656677\n","EPOCH 193 COMPLETED\n","Training loss: 0.6517099738121033\n","EPOCH 194 COMPLETED\n","Training loss: 0.45274049043655396\n","EPOCH 195 COMPLETED\n","Training loss: 0.5838631391525269\n","EPOCH 196 COMPLETED\n","Training loss: 0.7102161049842834\n","EPOCH 197 COMPLETED\n","Training loss: 0.5734764933586121\n","EPOCH 198 COMPLETED\n","Training loss: 0.6437995433807373\n","EPOCH 199 COMPLETED\n","Training loss: 0.531933069229126\n","EPOCH 200 COMPLETED\n","Training loss: 0.4766733646392822\n","EPOCH 201 COMPLETED\n","Training loss: 0.4052674472332001\n","EPOCH 202 COMPLETED\n","Training loss: 0.4960000514984131\n","EPOCH 203 COMPLETED\n","Training loss: 0.5570108890533447\n","EPOCH 204 COMPLETED\n","Training loss: 0.569438099861145\n","EPOCH 205 COMPLETED\n","Training loss: 0.6769840121269226\n","EPOCH 206 COMPLETED\n","Training loss: 0.7369503378868103\n","EPOCH 207 COMPLETED\n","Training loss: 0.722524881362915\n","EPOCH 208 COMPLETED\n","Training loss: 0.6066896915435791\n","EPOCH 209 COMPLETED\n","Training loss: 0.6055711507797241\n","EPOCH 210 COMPLETED\n","Training loss: 0.6557039022445679\n","EPOCH 211 COMPLETED\n","Training loss: 0.5661795139312744\n","EPOCH 212 COMPLETED\n","Training loss: 0.6559012532234192\n","EPOCH 213 COMPLETED\n","Training loss: 0.49810364842414856\n","EPOCH 214 COMPLETED\n","Training loss: 0.558799147605896\n","EPOCH 215 COMPLETED\n","Training loss: 0.4932968020439148\n","EPOCH 216 COMPLETED\n","Training loss: 0.546546995639801\n","EPOCH 217 COMPLETED\n","Training loss: 0.6673170924186707\n","EPOCH 218 COMPLETED\n","Training loss: 0.7961710095405579\n","EPOCH 219 COMPLETED\n","Training loss: 0.49080657958984375\n","EPOCH 220 COMPLETED\n","Training loss: 0.6968530416488647\n","EPOCH 221 COMPLETED\n","Training loss: 0.7733228802680969\n","EPOCH 222 COMPLETED\n","Training loss: 0.563022792339325\n","EPOCH 223 COMPLETED\n","Training loss: 0.7670463919639587\n","EPOCH 224 COMPLETED\n","Training loss: 0.5737211108207703\n","EPOCH 225 COMPLETED\n","Training loss: 0.5761721134185791\n","EPOCH 226 COMPLETED\n","Training loss: 0.6858476996421814\n","EPOCH 227 COMPLETED\n","Training loss: 0.6526412963867188\n","EPOCH 228 COMPLETED\n","Training loss: 0.4272271692752838\n","EPOCH 229 COMPLETED\n","Training loss: 0.6420156359672546\n","EPOCH 230 COMPLETED\n","Training loss: 0.4389994740486145\n","EPOCH 231 COMPLETED\n","Training loss: 0.6255234479904175\n","EPOCH 232 COMPLETED\n","Training loss: 0.5437204241752625\n","EPOCH 233 COMPLETED\n","Training loss: 0.6151885390281677\n","EPOCH 234 COMPLETED\n","Training loss: 0.7733734250068665\n","EPOCH 235 COMPLETED\n","Training loss: 0.6565592288970947\n","EPOCH 236 COMPLETED\n","Training loss: 0.5287662148475647\n","EPOCH 237 COMPLETED\n","Training loss: 0.5807705521583557\n","EPOCH 238 COMPLETED\n","Training loss: 0.513244092464447\n","EPOCH 239 COMPLETED\n","Training loss: 0.6493492126464844\n","EPOCH 240 COMPLETED\n","Training loss: 0.6746398210525513\n","EPOCH 241 COMPLETED\n","Training loss: 0.5688030123710632\n","EPOCH 242 COMPLETED\n","Training loss: 0.8702706694602966\n","EPOCH 243 COMPLETED\n","Training loss: 0.5941575169563293\n","EPOCH 244 COMPLETED\n","Training loss: 0.6402537822723389\n","EPOCH 245 COMPLETED\n","Training loss: 0.6017566323280334\n","EPOCH 246 COMPLETED\n","Training loss: 0.7331683039665222\n","EPOCH 247 COMPLETED\n","Training loss: 0.6324230432510376\n","EPOCH 248 COMPLETED\n","Training loss: 0.7890119552612305\n","EPOCH 249 COMPLETED\n","Training loss: 0.6788272857666016\n","EPOCH 250 COMPLETED\n","Training loss: 0.7376939654350281\n","EPOCH 251 COMPLETED\n","Training loss: 0.659545361995697\n","EPOCH 252 COMPLETED\n","Training loss: 0.8081293702125549\n","EPOCH 253 COMPLETED\n","Training loss: 0.6771588325500488\n","EPOCH 254 COMPLETED\n","Training loss: 0.525431752204895\n","EPOCH 255 COMPLETED\n","Training loss: 0.42175886034965515\n","EPOCH 256 COMPLETED\n","Training loss: 0.5580025315284729\n","EPOCH 257 COMPLETED\n","Training loss: 0.6510350704193115\n","EPOCH 258 COMPLETED\n","Training loss: 0.7777675986289978\n","EPOCH 259 COMPLETED\n","Training loss: 0.6429349184036255\n","EPOCH 260 COMPLETED\n","Training loss: 0.5850125551223755\n","EPOCH 261 COMPLETED\n","Training loss: 0.6022599339485168\n","EPOCH 262 COMPLETED\n","Training loss: 0.7069536447525024\n","EPOCH 263 COMPLETED\n","Training loss: 0.8006493449211121\n","EPOCH 264 COMPLETED\n","Training loss: 0.5502516627311707\n","EPOCH 265 COMPLETED\n","Training loss: 0.6861295700073242\n","EPOCH 266 COMPLETED\n","Training loss: 0.7052843570709229\n","EPOCH 267 COMPLETED\n","Training loss: 0.5616353750228882\n","EPOCH 268 COMPLETED\n","Training loss: 0.7603668570518494\n","EPOCH 269 COMPLETED\n","Training loss: 0.6503953337669373\n","EPOCH 270 COMPLETED\n","Training loss: 0.5685930252075195\n","EPOCH 271 COMPLETED\n","Training loss: 0.9187790751457214\n","EPOCH 272 COMPLETED\n","Training loss: 0.5227851271629333\n","EPOCH 273 COMPLETED\n","Training loss: 0.5736621618270874\n","EPOCH 274 COMPLETED\n","Training loss: 0.618215024471283\n","EPOCH 275 COMPLETED\n","Training loss: 0.6443787813186646\n","EPOCH 276 COMPLETED\n","Training loss: 0.7934586405754089\n","EPOCH 277 COMPLETED\n","Training loss: 0.7587389945983887\n","EPOCH 278 COMPLETED\n","Training loss: 0.6878992319107056\n","EPOCH 279 COMPLETED\n","Training loss: 0.7099038362503052\n","EPOCH 280 COMPLETED\n","Training loss: 0.8066744208335876\n","EPOCH 281 COMPLETED\n","Training loss: 0.6541506052017212\n","EPOCH 282 COMPLETED\n","Training loss: 0.6339647769927979\n","EPOCH 283 COMPLETED\n","Training loss: 0.6335387825965881\n","EPOCH 284 COMPLETED\n","Training loss: 0.6399864554405212\n","EPOCH 285 COMPLETED\n","Training loss: 0.474487841129303\n","EPOCH 286 COMPLETED\n","Training loss: 0.6332567930221558\n","EPOCH 287 COMPLETED\n","Training loss: 0.7833940982818604\n","EPOCH 288 COMPLETED\n","Training loss: 0.5925502181053162\n","EPOCH 289 COMPLETED\n","Training loss: 0.6003274321556091\n","EPOCH 290 COMPLETED\n","Training loss: 0.5041149854660034\n","EPOCH 291 COMPLETED\n","Training loss: 0.7769222855567932\n","EPOCH 292 COMPLETED\n","Training loss: 0.807666540145874\n","EPOCH 293 COMPLETED\n","Training loss: 0.6553012728691101\n","EPOCH 294 COMPLETED\n","Training loss: 0.5197758674621582\n","EPOCH 295 COMPLETED\n","Training loss: 0.8441281318664551\n","EPOCH 296 COMPLETED\n","Training loss: 0.7191311717033386\n","EPOCH 297 COMPLETED\n","Training loss: 0.582991361618042\n","EPOCH 298 COMPLETED\n","Training loss: 0.6563376784324646\n","EPOCH 299 COMPLETED\n","Training loss: 0.676093578338623\n","EPOCH 300 COMPLETED\n","Training loss: 0.612480640411377\n","EPOCH 301 COMPLETED\n","Training loss: 0.5903831720352173\n","EPOCH 302 COMPLETED\n","Training loss: 0.6709960103034973\n","EPOCH 303 COMPLETED\n","Training loss: 0.4618918001651764\n","EPOCH 304 COMPLETED\n","Training loss: 0.73018878698349\n","EPOCH 305 COMPLETED\n","Training loss: 0.6168678402900696\n","EPOCH 306 COMPLETED\n","Training loss: 0.6630359292030334\n","EPOCH 307 COMPLETED\n","Training loss: 0.5208795666694641\n","EPOCH 308 COMPLETED\n","Training loss: 0.6518504619598389\n","EPOCH 309 COMPLETED\n","Training loss: 0.5040733814239502\n","EPOCH 310 COMPLETED\n","Training loss: 0.5434673428535461\n","EPOCH 311 COMPLETED\n","Training loss: 0.8046610951423645\n","EPOCH 312 COMPLETED\n","Training loss: 0.6319053173065186\n","EPOCH 313 COMPLETED\n","Training loss: 0.8281296491622925\n","EPOCH 314 COMPLETED\n","Training loss: 0.5232698917388916\n","EPOCH 315 COMPLETED\n","Training loss: 0.5760466456413269\n","EPOCH 316 COMPLETED\n","Training loss: 0.816423773765564\n","EPOCH 317 COMPLETED\n","Training loss: 0.6518890261650085\n","EPOCH 318 COMPLETED\n","Training loss: 0.6531398296356201\n","EPOCH 319 COMPLETED\n","Training loss: 0.5719361305236816\n","EPOCH 320 COMPLETED\n","Training loss: 0.5652542114257812\n","EPOCH 321 COMPLETED\n","Training loss: 0.6210734844207764\n","EPOCH 322 COMPLETED\n","Training loss: 0.5315763354301453\n","EPOCH 323 COMPLETED\n","Training loss: 0.6066876649856567\n","EPOCH 324 COMPLETED\n","Training loss: 0.7714314460754395\n","EPOCH 325 COMPLETED\n","Training loss: 0.5988464951515198\n","EPOCH 326 COMPLETED\n","Training loss: 0.7094346880912781\n","EPOCH 327 COMPLETED\n","Training loss: 0.6614137887954712\n","EPOCH 328 COMPLETED\n","Training loss: 0.5897913575172424\n","EPOCH 329 COMPLETED\n","Training loss: 0.5412658452987671\n","EPOCH 330 COMPLETED\n","Training loss: 0.7165551781654358\n","EPOCH 331 COMPLETED\n","Training loss: 0.5475010871887207\n","EPOCH 332 COMPLETED\n","Training loss: 0.6619600057601929\n","EPOCH 333 COMPLETED\n","Training loss: 0.6709555387496948\n","EPOCH 334 COMPLETED\n","Training loss: 0.6366614699363708\n","EPOCH 335 COMPLETED\n","Training loss: 0.6093469262123108\n","EPOCH 336 COMPLETED\n","Training loss: 0.7590450048446655\n","EPOCH 337 COMPLETED\n","Training loss: 0.6370002031326294\n","EPOCH 338 COMPLETED\n","Training loss: 0.6837377548217773\n","EPOCH 339 COMPLETED\n","Training loss: 0.47410649061203003\n","EPOCH 340 COMPLETED\n","Training loss: 0.8451031446456909\n","EPOCH 341 COMPLETED\n","Training loss: 0.4674660563468933\n","EPOCH 342 COMPLETED\n","Training loss: 0.7659966945648193\n","EPOCH 343 COMPLETED\n","Training loss: 0.6175631284713745\n","EPOCH 344 COMPLETED\n","Training loss: 0.6170217990875244\n","EPOCH 345 COMPLETED\n","Training loss: 0.7174081802368164\n","EPOCH 346 COMPLETED\n","Training loss: 0.717483401298523\n","EPOCH 347 COMPLETED\n","Training loss: 0.4644346833229065\n","EPOCH 348 COMPLETED\n","Training loss: 0.5234935283660889\n","EPOCH 349 COMPLETED\n","Training loss: 0.5076740980148315\n","EPOCH 350 COMPLETED\n","Training loss: 0.5023096203804016\n","EPOCH 351 COMPLETED\n","Training loss: 0.7443852424621582\n","EPOCH 352 COMPLETED\n","Training loss: 0.8637548685073853\n","EPOCH 353 COMPLETED\n","Training loss: 0.7700316905975342\n","EPOCH 354 COMPLETED\n","Training loss: 0.7514046430587769\n","EPOCH 355 COMPLETED\n","Training loss: 0.6297523379325867\n","EPOCH 356 COMPLETED\n","Training loss: 0.8141480088233948\n","EPOCH 357 COMPLETED\n","Training loss: 0.7316064238548279\n","EPOCH 358 COMPLETED\n","Training loss: 0.7412928342819214\n","EPOCH 359 COMPLETED\n","Training loss: 0.7175023555755615\n","EPOCH 360 COMPLETED\n","Training loss: 0.6902047395706177\n","EPOCH 361 COMPLETED\n","Training loss: 0.740108072757721\n","EPOCH 362 COMPLETED\n","Training loss: 0.43813884258270264\n","EPOCH 363 COMPLETED\n","Training loss: 0.5454177260398865\n","EPOCH 364 COMPLETED\n","Training loss: 0.7495979070663452\n","EPOCH 365 COMPLETED\n","Training loss: 0.5472522377967834\n","EPOCH 366 COMPLETED\n","Training loss: 0.6247622966766357\n","EPOCH 367 COMPLETED\n","Training loss: 0.6190409660339355\n","EPOCH 368 COMPLETED\n","Training loss: 0.8053846955299377\n","EPOCH 369 COMPLETED\n","Training loss: 0.5985842943191528\n","EPOCH 370 COMPLETED\n","Training loss: 0.4940015971660614\n","EPOCH 371 COMPLETED\n","Training loss: 0.757543683052063\n","EPOCH 372 COMPLETED\n","Training loss: 0.49415045976638794\n","EPOCH 373 COMPLETED\n","Training loss: 0.732597827911377\n","EPOCH 374 COMPLETED\n","Training loss: 0.5384291410446167\n","EPOCH 375 COMPLETED\n","Training loss: 0.658566951751709\n","EPOCH 376 COMPLETED\n","Training loss: 0.6058000922203064\n","EPOCH 377 COMPLETED\n","Training loss: 0.5943719744682312\n","EPOCH 378 COMPLETED\n","Training loss: 0.49125441908836365\n","EPOCH 379 COMPLETED\n","Training loss: 0.5136932134628296\n","EPOCH 380 COMPLETED\n","Training loss: 0.582150936126709\n","EPOCH 381 COMPLETED\n","Training loss: 0.8098471760749817\n","EPOCH 382 COMPLETED\n","Training loss: 0.6629454493522644\n","EPOCH 383 COMPLETED\n","Training loss: 0.5522919297218323\n","EPOCH 384 COMPLETED\n","Training loss: 0.6721875667572021\n","EPOCH 385 COMPLETED\n","Training loss: 0.5953963398933411\n","EPOCH 386 COMPLETED\n","Training loss: 0.6509251594543457\n","EPOCH 387 COMPLETED\n","Training loss: 0.5554538369178772\n","EPOCH 388 COMPLETED\n","Training loss: 0.5947468280792236\n","EPOCH 389 COMPLETED\n","Training loss: 0.787847101688385\n","EPOCH 390 COMPLETED\n","Training loss: 0.48639145493507385\n","EPOCH 391 COMPLETED\n","Training loss: 0.5995351672172546\n","EPOCH 392 COMPLETED\n","Training loss: 0.5591940879821777\n","EPOCH 393 COMPLETED\n","Training loss: 0.6602985858917236\n","EPOCH 394 COMPLETED\n","Training loss: 0.6089168190956116\n","EPOCH 395 COMPLETED\n","Training loss: 0.7248772978782654\n","EPOCH 396 COMPLETED\n","Training loss: 0.7876056432723999\n","EPOCH 397 COMPLETED\n","Training loss: 0.6305397748947144\n","EPOCH 398 COMPLETED\n","Training loss: 0.5368501543998718\n","EPOCH 399 COMPLETED\n","Training loss: 0.6143011450767517\n","EPOCH 400 COMPLETED\n","Training loss: 0.6753700971603394\n","EPOCH 401 COMPLETED\n","Training loss: 0.4833953380584717\n","EPOCH 402 COMPLETED\n","Training loss: 0.7732001543045044\n","EPOCH 403 COMPLETED\n","Training loss: 0.5909175872802734\n","EPOCH 404 COMPLETED\n","Training loss: 0.6140428185462952\n","EPOCH 405 COMPLETED\n","Training loss: 0.6737774610519409\n","EPOCH 406 COMPLETED\n","Training loss: 0.5521714091300964\n","EPOCH 407 COMPLETED\n","Training loss: 0.5972247123718262\n","EPOCH 408 COMPLETED\n","Training loss: 0.625357449054718\n","EPOCH 409 COMPLETED\n","Training loss: 0.5774229168891907\n","EPOCH 410 COMPLETED\n","Training loss: 0.6213062405586243\n","EPOCH 411 COMPLETED\n","Training loss: 0.746628999710083\n","EPOCH 412 COMPLETED\n","Training loss: 0.7464730739593506\n","EPOCH 413 COMPLETED\n","Training loss: 0.571329653263092\n","EPOCH 414 COMPLETED\n","Training loss: 0.8492718935012817\n","EPOCH 415 COMPLETED\n","Training loss: 0.5975958108901978\n","EPOCH 416 COMPLETED\n","Training loss: 0.5818559527397156\n","EPOCH 417 COMPLETED\n","Training loss: 0.5720731019973755\n","EPOCH 418 COMPLETED\n","Training loss: 0.6917931437492371\n","EPOCH 419 COMPLETED\n","Training loss: 0.5577583909034729\n","EPOCH 420 COMPLETED\n","Training loss: 0.6172763705253601\n","EPOCH 421 COMPLETED\n","Training loss: 0.6309219002723694\n","EPOCH 422 COMPLETED\n","Training loss: 0.7675142288208008\n","EPOCH 423 COMPLETED\n","Training loss: 0.6887320280075073\n","EPOCH 424 COMPLETED\n","Training loss: 0.742480993270874\n","EPOCH 425 COMPLETED\n","Training loss: 0.6781618595123291\n","EPOCH 426 COMPLETED\n","Training loss: 0.47947677969932556\n","EPOCH 427 COMPLETED\n","Training loss: 0.5953482985496521\n","EPOCH 428 COMPLETED\n","Training loss: 0.8336754441261292\n","EPOCH 429 COMPLETED\n","Training loss: 0.6857804656028748\n","EPOCH 430 COMPLETED\n","Training loss: 0.6121029853820801\n","EPOCH 431 COMPLETED\n","Training loss: 0.6337251663208008\n","EPOCH 432 COMPLETED\n","Training loss: 0.7941586375236511\n","EPOCH 433 COMPLETED\n","Training loss: 0.6251774430274963\n","EPOCH 434 COMPLETED\n","Training loss: 0.821662187576294\n","EPOCH 435 COMPLETED\n","Training loss: 0.5101331472396851\n","EPOCH 436 COMPLETED\n","Training loss: 0.5001838803291321\n","EPOCH 437 COMPLETED\n","Training loss: 0.5706956386566162\n","EPOCH 438 COMPLETED\n","Training loss: 0.7352654337882996\n","EPOCH 439 COMPLETED\n","Training loss: 0.7772958278656006\n","EPOCH 440 COMPLETED\n","Training loss: 0.6503949761390686\n","EPOCH 441 COMPLETED\n","Training loss: 0.772280752658844\n","EPOCH 442 COMPLETED\n","Training loss: 0.6889825463294983\n","EPOCH 443 COMPLETED\n","Training loss: 0.6411418318748474\n","EPOCH 444 COMPLETED\n","Training loss: 0.7172707319259644\n","EPOCH 445 COMPLETED\n","Training loss: 0.643791675567627\n","EPOCH 446 COMPLETED\n","Training loss: 0.563296377658844\n","EPOCH 447 COMPLETED\n","Training loss: 0.7845137119293213\n","EPOCH 448 COMPLETED\n","Training loss: 0.5939744114875793\n","EPOCH 449 COMPLETED\n","Training loss: 0.4932372272014618\n","EPOCH 450 COMPLETED\n","Training loss: 0.6646389365196228\n","EPOCH 451 COMPLETED\n","Training loss: 0.5387179851531982\n","EPOCH 452 COMPLETED\n","Training loss: 0.5214296579360962\n","EPOCH 453 COMPLETED\n","Training loss: 0.5788207054138184\n","EPOCH 454 COMPLETED\n","Training loss: 0.6480110883712769\n","EPOCH 455 COMPLETED\n","Training loss: 0.5418260097503662\n","EPOCH 456 COMPLETED\n","Training loss: 0.612040102481842\n","EPOCH 457 COMPLETED\n","Training loss: 0.6297441720962524\n","EPOCH 458 COMPLETED\n","Training loss: 0.6762956976890564\n","EPOCH 459 COMPLETED\n","Training loss: 0.8448723554611206\n","EPOCH 460 COMPLETED\n","Training loss: 0.516776978969574\n","EPOCH 461 COMPLETED\n","Training loss: 0.6507025957107544\n","EPOCH 462 COMPLETED\n","Training loss: 0.6121960282325745\n","EPOCH 463 COMPLETED\n","Training loss: 0.7105033993721008\n","EPOCH 464 COMPLETED\n","Training loss: 0.4074864089488983\n","EPOCH 465 COMPLETED\n","Training loss: 0.6292375326156616\n","EPOCH 466 COMPLETED\n","Training loss: 0.5303846597671509\n","EPOCH 467 COMPLETED\n","Training loss: 0.7315801382064819\n","EPOCH 468 COMPLETED\n","Training loss: 0.5078177452087402\n","EPOCH 469 COMPLETED\n","Training loss: 0.8208276033401489\n","EPOCH 470 COMPLETED\n","Training loss: 0.6916698217391968\n","EPOCH 471 COMPLETED\n","Training loss: 0.6061088442802429\n","EPOCH 472 COMPLETED\n","Training loss: 0.7305487990379333\n","EPOCH 473 COMPLETED\n","Training loss: 0.6880660057067871\n","EPOCH 474 COMPLETED\n","Training loss: 0.6039972901344299\n","EPOCH 475 COMPLETED\n","Training loss: 0.5495302677154541\n","EPOCH 476 COMPLETED\n","Training loss: 0.5133786201477051\n","EPOCH 477 COMPLETED\n","Training loss: 0.5748090744018555\n","EPOCH 478 COMPLETED\n","Training loss: 0.6106317043304443\n","EPOCH 479 COMPLETED\n","Training loss: 0.5986595153808594\n","EPOCH 480 COMPLETED\n","Training loss: 0.5784809589385986\n","EPOCH 481 COMPLETED\n","Training loss: 0.6576173305511475\n","EPOCH 482 COMPLETED\n","Training loss: 0.9268597960472107\n","EPOCH 483 COMPLETED\n","Training loss: 0.5490506291389465\n","EPOCH 484 COMPLETED\n","Training loss: 0.5341918468475342\n","EPOCH 485 COMPLETED\n","Training loss: 0.631679892539978\n","EPOCH 486 COMPLETED\n","Training loss: 0.6505791544914246\n","EPOCH 487 COMPLETED\n","Training loss: 0.7833511233329773\n","EPOCH 488 COMPLETED\n","Training loss: 0.5665078163146973\n","EPOCH 489 COMPLETED\n","Training loss: 0.7432706356048584\n","EPOCH 490 COMPLETED\n","Training loss: 0.6434218287467957\n","EPOCH 491 COMPLETED\n","Training loss: 0.5201387405395508\n","EPOCH 492 COMPLETED\n","Training loss: 0.4433954358100891\n","EPOCH 493 COMPLETED\n","Training loss: 0.643161952495575\n","EPOCH 494 COMPLETED\n","Training loss: 0.5568224787712097\n","EPOCH 495 COMPLETED\n","Training loss: 0.560035765171051\n","EPOCH 496 COMPLETED\n","Training loss: 0.8390468955039978\n","EPOCH 497 COMPLETED\n","Training loss: 0.736738920211792\n","EPOCH 498 COMPLETED\n","Training loss: 0.5222057104110718\n","EPOCH 499 COMPLETED\n","Training loss: 0.4995993375778198\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"X70VAKRK8tjS","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34877},"outputId":"2e4bf1f4-3cb3-4ba2-c9db-ff6b55334cd9","executionInfo":{"status":"ok","timestamp":1559454970304,"user_tz":240,"elapsed":2142,"user":{"displayName":"Gautham Bekal","photoUrl":"","userId":"01650273333839084339"}}},"source":["count=1\n","for x, y in validation_loader:\n","    x=Variable(x.float())\n","    y=Variable(y.float())\n","    outputs=model(x)\n","    \n","    for i,j in zip(outputs,y):\n","      print(\"Predicted \"+str(i)+\" Actual \"+str(j))\n","    print(\"Batch: {} completed\".format(count))\n","    count=count+1"],"execution_count":50,"outputs":[{"output_type":"stream","text":["Predicted tensor([-0.5262, -0.4732, -0.1282], grad_fn=<SelectBackward>) Actual tensor([-0.6395, -0.0575, -0.2142])\n","Predicted tensor([-0.6785,  0.9949, -0.2675], grad_fn=<SelectBackward>) Actual tensor([-1.3403, -0.2088, -0.5490])\n","Predicted tensor([ 0.6765, -0.0855, -0.2376], grad_fn=<SelectBackward>) Actual tensor([-0.5046, -0.7332, -0.2599])\n","Predicted tensor([ 0.5866, -0.0444, -0.1861], grad_fn=<SelectBackward>) Actual tensor([ 1.0905, -0.4907, -0.3404])\n","Predicted tensor([ 0.6092,  0.0170, -0.2088], grad_fn=<SelectBackward>) Actual tensor([ 1.5404,  0.1778, -0.3527])\n","Predicted tensor([ 0.7489,  0.0223, -0.1171], grad_fn=<SelectBackward>) Actual tensor([-0.6093, -0.7794, -0.2870])\n","Predicted tensor([-1.0700,  0.5017, -0.1024], grad_fn=<SelectBackward>) Actual tensor([-1.5136, -0.5655, -0.5332])\n","Predicted tensor([ 0.6043,  0.0084, -0.1922], grad_fn=<SelectBackward>) Actual tensor([ 1.6898,  0.1213, -0.2992])\n","Predicted tensor([0.5906, 0.4414, 0.0295], grad_fn=<SelectBackward>) Actual tensor([0.6053, 1.8272, 0.5679])\n","Predicted tensor([ 0.5665, -0.0807, -0.2049], grad_fn=<SelectBackward>) Actual tensor([-1.3526,  1.1077,  0.0400])\n","Predicted tensor([-0.6526,  0.5049, -0.1555], grad_fn=<SelectBackward>) Actual tensor([-0.0800,  0.5816, -0.3617])\n","Predicted tensor([ 0.7244, -0.1002, -0.1331], grad_fn=<SelectBackward>) Actual tensor([ 1.1124, -0.5747, -0.3308])\n","Predicted tensor([0.3379, 1.2924, 0.0690], grad_fn=<SelectBackward>) Actual tensor([-0.3617,  1.7233,  0.0367])\n","Predicted tensor([-0.0642,  1.4235, -0.0588], grad_fn=<SelectBackward>) Actual tensor([-0.3038,  2.8324, -0.0986])\n","Predicted tensor([ 0.3444,  0.5324, -0.0992], grad_fn=<SelectBackward>) Actual tensor([-0.3330, -0.7702, -0.2886])\n","Predicted tensor([ 0.7271, -0.4181, -0.2718], grad_fn=<SelectBackward>) Actual tensor([ 1.1261, -0.7290, -0.3045])\n","Predicted tensor([-0.2696, -0.4482, -0.0962], grad_fn=<SelectBackward>) Actual tensor([-0.3157, -0.4770, -0.1965])\n","Predicted tensor([-0.0385, -0.3773, -0.0984], grad_fn=<SelectBackward>) Actual tensor([-0.1926, -0.5716, -0.2067])\n","Predicted tensor([ 0.6249,  0.2642, -0.1160], grad_fn=<SelectBackward>) Actual tensor([ 1.4295,  0.8348, -0.3101])\n","Predicted tensor([ 0.2112, -0.2327, -0.1412], grad_fn=<SelectBackward>) Actual tensor([ 1.1122, -0.7475, -0.3298])\n","Predicted tensor([ 0.2110, -0.3313, -0.1244], grad_fn=<SelectBackward>) Actual tensor([-0.6521, -0.7210, -0.2999])\n","Predicted tensor([-0.5484,  0.1713, -0.0945], grad_fn=<SelectBackward>) Actual tensor([-0.3235,  0.0222, -0.2793])\n","Predicted tensor([ 0.6263,  0.0192, -0.2135], grad_fn=<SelectBackward>) Actual tensor([-0.1323, -0.0243, -0.2696])\n","Predicted tensor([ 0.4421,  0.3985, -0.0451], grad_fn=<SelectBackward>) Actual tensor([-0.5988, -0.6844, -0.3086])\n","Predicted tensor([-0.4495,  1.1487,  2.6617], grad_fn=<SelectBackward>) Actual tensor([3.6782e-04, 7.5896e-01, 2.4928e+00])\n","Predicted tensor([ 0.0646, -0.0624, -0.1481], grad_fn=<SelectBackward>) Actual tensor([-0.2211,  0.0978, -0.2934])\n","Predicted tensor([-0.5562, -0.4533, -0.0954], grad_fn=<SelectBackward>) Actual tensor([-0.6754, -0.6730, -0.2988])\n","Predicted tensor([-0.2664, -0.1916, -0.0124], grad_fn=<SelectBackward>) Actual tensor([-0.5415, -0.7658, -0.2837])\n","Predicted tensor([ 0.1033, -0.2764, -0.1175], grad_fn=<SelectBackward>) Actual tensor([-0.4691, -0.5294, -0.2592])\n","Predicted tensor([-0.1791, -0.4494, -0.0877], grad_fn=<SelectBackward>) Actual tensor([-0.7787, -0.7440, -0.2672])\n","Predicted tensor([-0.6571, -0.3593, -0.1078], grad_fn=<SelectBackward>) Actual tensor([-0.7113, -0.7628, -0.2756])\n","Predicted tensor([0.1335, 0.6834, 0.3322], grad_fn=<SelectBackward>) Actual tensor([ 1.2129,  0.8575, -0.3679])\n","Predicted tensor([-0.1908,  0.6668,  1.9325], grad_fn=<SelectBackward>) Actual tensor([-0.8849,  1.0206,  3.6363])\n","Predicted tensor([-0.7120, -0.4220, -0.0981], grad_fn=<SelectBackward>) Actual tensor([-0.8553, -0.4420, -0.2895])\n","Predicted tensor([ 0.7136, -0.0091,  0.1559], grad_fn=<SelectBackward>) Actual tensor([1.0067, 0.7440, 0.2413])\n","Predicted tensor([-0.6289, -0.4628, -0.1151], grad_fn=<SelectBackward>) Actual tensor([-0.7371, -0.7633, -0.2858])\n","Predicted tensor([-0.4796, -0.3007, -0.0968], grad_fn=<SelectBackward>) Actual tensor([ 2.0958, -0.1423, -0.2910])\n","Predicted tensor([ 0.5894,  0.0895, -0.1842], grad_fn=<SelectBackward>) Actual tensor([ 1.3338,  1.6001, -0.1314])\n","Predicted tensor([-0.2963, -0.3283, -0.1173], grad_fn=<SelectBackward>) Actual tensor([ 1.1284, -0.6851, -0.3316])\n","Predicted tensor([ 0.0266, -0.1885, -0.1199], grad_fn=<SelectBackward>) Actual tensor([-0.3247,  2.2715,  0.0797])\n","Predicted tensor([-0.4071, -0.2339, -0.1100], grad_fn=<SelectBackward>) Actual tensor([-0.5342, -0.0454, -0.3089])\n","Predicted tensor([-0.0109,  0.8191,  0.5716], grad_fn=<SelectBackward>) Actual tensor([-0.1623,  1.3835,  0.7892])\n","Predicted tensor([-0.0825,  0.3181, -0.2077], grad_fn=<SelectBackward>) Actual tensor([ 1.1072, -0.6335, -0.3345])\n","Predicted tensor([-0.1368, -0.2920, -0.1428], grad_fn=<SelectBackward>) Actual tensor([ 1.1093, -0.7483, -0.3313])\n","Predicted tensor([-0.9389,  0.7400, -0.1709], grad_fn=<SelectBackward>) Actual tensor([-1.1724,  1.8569, -0.4089])\n","Predicted tensor([ 0.2676, -0.3023, -0.1172], grad_fn=<SelectBackward>) Actual tensor([ 0.2106, -0.5876, -0.1480])\n","Predicted tensor([-0.3494, -0.3046, -0.0882], grad_fn=<SelectBackward>) Actual tensor([-0.6332, -0.7444, -0.3218])\n","Predicted tensor([ 0.2033, -0.1067, -0.1237], grad_fn=<SelectBackward>) Actual tensor([ 0.8460, -0.5440, -0.2806])\n","Predicted tensor([ 0.6996, -0.3707, -0.2622], grad_fn=<SelectBackward>) Actual tensor([ 0.1352, -0.5471, -0.2483])\n","Predicted tensor([-0.7112, -0.4807, -0.0989], grad_fn=<SelectBackward>) Actual tensor([-0.6699, -0.6114, -0.2117])\n","Predicted tensor([-0.1555, -0.4431, -0.0724], grad_fn=<SelectBackward>) Actual tensor([-0.5299, -0.7697, -0.3211])\n","Predicted tensor([ 0.7057, -0.3270, -0.2928], grad_fn=<SelectBackward>) Actual tensor([ 0.9192, -0.7559, -0.3209])\n","Predicted tensor([ 0.0561,  0.4374, -0.1580], grad_fn=<SelectBackward>) Actual tensor([-0.2576, -0.2561, -0.2571])\n","Predicted tensor([0.6432, 0.4970, 0.0209], grad_fn=<SelectBackward>) Actual tensor([ 1.2661,  0.6988, -0.3096])\n","Predicted tensor([-1.4186,  0.4297,  0.0646], grad_fn=<SelectBackward>) Actual tensor([-2.1404, -0.3716, -0.3433])\n","Predicted tensor([ 0.0666,  0.0660, -0.1409], grad_fn=<SelectBackward>) Actual tensor([-0.2633, -0.0794, -0.2844])\n","Predicted tensor([ 0.7123, -0.3184, -0.2474], grad_fn=<SelectBackward>) Actual tensor([ 1.1154, -0.6563, -0.3279])\n","Predicted tensor([-0.6075,  0.0337, -0.1324], grad_fn=<SelectBackward>) Actual tensor([-0.1687, -0.3029, -0.3345])\n","Predicted tensor([-0.6470, -0.4076, -0.1333], grad_fn=<SelectBackward>) Actual tensor([-0.8289, -0.7778, -0.2670])\n","Predicted tensor([-0.5514, -0.2816, -0.1282], grad_fn=<SelectBackward>) Actual tensor([-0.5819, -0.1708, -0.2491])\n","Predicted tensor([ 0.7005, -0.3130, -0.2525], grad_fn=<SelectBackward>) Actual tensor([ 1.1133, -0.6700, -0.3265])\n","Predicted tensor([-0.7492, -0.4212, -0.0806], grad_fn=<SelectBackward>) Actual tensor([-0.8594, -0.4709, -0.2944])\n","Predicted tensor([0.5561, 0.5986, 0.4655], grad_fn=<SelectBackward>) Actual tensor([ 1.0011,  0.3471, -0.3544])\n","Predicted tensor([-0.5417, -0.3412, -0.0896], grad_fn=<SelectBackward>) Actual tensor([-0.5914, -0.6740, -0.3277])\n","Predicted tensor([ 0.0198, -0.2946, -0.1226], grad_fn=<SelectBackward>) Actual tensor([-0.2364,  0.0434, -0.2141])\n","Predicted tensor([ 0.4402,  0.3387, -0.1250], grad_fn=<SelectBackward>) Actual tensor([1.7230, 1.0850, 0.2235])\n","Predicted tensor([ 0.6938, -0.2447, -0.2543], grad_fn=<SelectBackward>) Actual tensor([-0.1913, -0.6706, -0.3156])\n","Predicted tensor([-0.5866, -0.5105, -0.1048], grad_fn=<SelectBackward>) Actual tensor([-0.7180, -0.7367, -0.2951])\n","Predicted tensor([0.0652, 0.6904, 0.3395], grad_fn=<SelectBackward>) Actual tensor([0.8512, 2.3876, 0.8714])\n","Predicted tensor([-0.6899, -0.4556, -0.1228], grad_fn=<SelectBackward>) Actual tensor([-0.7650, -0.3727, -0.2579])\n","Predicted tensor([-0.6735, -0.4870, -0.1035], grad_fn=<SelectBackward>) Actual tensor([-0.5524, -0.0891, -0.1543])\n","Predicted tensor([-0.6640, -0.4898, -0.0992], grad_fn=<SelectBackward>) Actual tensor([-0.6372, -0.5034, -0.1985])\n","Predicted tensor([-0.0200, -0.3432, -0.1134], grad_fn=<SelectBackward>) Actual tensor([ 1.1591, -0.6242, -0.3404])\n","Predicted tensor([-0.5596,  0.1813, -0.1197], grad_fn=<SelectBackward>) Actual tensor([-0.6396, -0.0498, -0.3349])\n","Predicted tensor([-0.6512, -0.3677, -0.1435], grad_fn=<SelectBackward>) Actual tensor([-0.7848, -0.7225, -0.2675])\n","Predicted tensor([-0.4373, -0.4817, -0.0862], grad_fn=<SelectBackward>) Actual tensor([-0.7895, -0.7633, -0.2773])\n","Predicted tensor([ 0.6761, -0.3147, -0.2044], grad_fn=<SelectBackward>) Actual tensor([ 1.0278,  0.2738, -0.2417])\n","Predicted tensor([ 0.3071, -0.0627, -0.0901], grad_fn=<SelectBackward>) Actual tensor([-0.3199, -0.5227, -0.3327])\n","Predicted tensor([-0.7754, -0.3946, -0.0555], grad_fn=<SelectBackward>) Actual tensor([-0.6969, -0.6413, -0.2457])\n","Predicted tensor([-0.6824,  0.1825,  3.8475], grad_fn=<SelectBackward>) Actual tensor([-0.5271,  0.5779,  4.2174])\n","Predicted tensor([-1.1261,  0.4763,  0.1460], grad_fn=<SelectBackward>) Actual tensor([-0.5384, -0.0701, -0.1145])\n","Predicted tensor([ 0.6670, -0.1096, -0.2266], grad_fn=<SelectBackward>) Actual tensor([-0.6259, -0.6836, -0.2687])\n","Predicted tensor([ 0.6786, -0.2464, -0.2147], grad_fn=<SelectBackward>) Actual tensor([-0.0299, -0.6021, -0.3028])\n","Predicted tensor([-0.3252,  0.7597, -0.2188], grad_fn=<SelectBackward>) Actual tensor([-0.9258,  0.6675, -0.3778])\n","Predicted tensor([ 0.1666, -0.2233, -0.0982], grad_fn=<SelectBackward>) Actual tensor([ 0.1565, -0.0212, -0.1872])\n","Predicted tensor([-0.9616, -0.4445,  4.4915], grad_fn=<SelectBackward>) Actual tensor([-1.0633, -0.7844,  5.1418])\n","Predicted tensor([-0.6388, -0.4650, -0.1290], grad_fn=<SelectBackward>) Actual tensor([-0.8620, -0.7350, -0.2796])\n","Predicted tensor([-0.4877, -0.4758, -0.1023], grad_fn=<SelectBackward>) Actual tensor([-0.4637, -0.6772, -0.2736])\n","Predicted tensor([-0.3383, -0.3543, -0.1035], grad_fn=<SelectBackward>) Actual tensor([-0.6031, -0.6274, -0.2516])\n","Predicted tensor([-0.3039, -0.4062,  0.0433], grad_fn=<SelectBackward>) Actual tensor([-0.4713, -0.1314,  0.0263])\n","Predicted tensor([ 0.7142,  0.1373, -0.1409], grad_fn=<SelectBackward>) Actual tensor([ 1.4081, -0.3550, -0.3420])\n","Predicted tensor([ 0.6902, -0.2524, -0.2399], grad_fn=<SelectBackward>) Actual tensor([ 1.2343, -0.5279, -0.3171])\n","Predicted tensor([ 0.6982, -0.3485, -0.2506], grad_fn=<SelectBackward>) Actual tensor([ 0.4855, -0.5193, -0.2483])\n","Predicted tensor([-0.5524,  0.7934, -0.2101], grad_fn=<SelectBackward>) Actual tensor([-2.0601, -0.1650, -0.3716])\n","Predicted tensor([ 0.2611, -0.2491, -0.1613], grad_fn=<SelectBackward>) Actual tensor([ 1.6694,  2.6080, -0.1333])\n","Predicted tensor([ 0.2436, -0.2324, -0.1338], grad_fn=<SelectBackward>) Actual tensor([ 0.3506,  0.7716, -0.2472])\n","Predicted tensor([-0.6715, -0.3535, -0.1050], grad_fn=<SelectBackward>) Actual tensor([ 0.1160,  0.1460, -0.1233])\n","Predicted tensor([-0.0575,  0.3523, -0.1138], grad_fn=<SelectBackward>) Actual tensor([-0.9373, -0.5107, -0.3843])\n","Predicted tensor([ 0.5419, -0.3188, -0.2640], grad_fn=<SelectBackward>) Actual tensor([ 0.0309,  0.3231, -0.1587])\n","Predicted tensor([-0.4051, -0.1815, -0.1513], grad_fn=<SelectBackward>) Actual tensor([-1.0465,  0.8602, -0.0645])\n","Predicted tensor([-0.6450, -0.3725, -0.1071], grad_fn=<SelectBackward>) Actual tensor([-2.1090, -0.2925, -0.0369])\n","Predicted tensor([ 0.6844, -0.1371, -0.2247], grad_fn=<SelectBackward>) Actual tensor([ 1.0508, -0.5382, -0.3223])\n","Predicted tensor([ 0.6480, -0.0194, -0.1907], grad_fn=<SelectBackward>) Actual tensor([ 1.2570,  0.1275, -0.3193])\n","Predicted tensor([ 0.3482,  0.0729, -0.0265], grad_fn=<SelectBackward>) Actual tensor([ 0.8750,  2.4239, -0.1372])\n","Predicted tensor([ 0.1137, -0.3617, -0.0996], grad_fn=<SelectBackward>) Actual tensor([ 0.0977,  0.6650, -0.1815])\n","Predicted tensor([ 0.6850, -0.3407, -0.2420], grad_fn=<SelectBackward>) Actual tensor([ 0.2734, -0.7758, -0.2981])\n","Predicted tensor([-0.6604, -0.4146, -0.1098], grad_fn=<SelectBackward>) Actual tensor([-0.7362, -0.4916, -0.2686])\n","Predicted tensor([ 0.6468, -0.3490, -0.1976], grad_fn=<SelectBackward>) Actual tensor([ 0.1349, -0.5579, -0.3277])\n","Predicted tensor([-1.0821,  0.0042, -0.0504], grad_fn=<SelectBackward>) Actual tensor([ 1.5452, -0.6670, -0.2095])\n","Predicted tensor([ 0.4410,  0.3048, -0.1770], grad_fn=<SelectBackward>) Actual tensor([ 1.0505, -0.3001, -0.3380])\n","Predicted tensor([0.3123, 0.5236, 0.1083], grad_fn=<SelectBackward>) Actual tensor([0.2358, 0.8541, 0.2601])\n","Predicted tensor([-0.9634, -0.2147,  4.3080], grad_fn=<SelectBackward>) Actual tensor([-0.0435, -0.5042,  4.2837])\n","Predicted tensor([-0.5798, -0.2822, -0.1312], grad_fn=<SelectBackward>) Actual tensor([2.1696, 3.0216, 0.5520])\n","Predicted tensor([ 0.1602, -0.3527, -0.1171], grad_fn=<SelectBackward>) Actual tensor([-0.0169, -0.4584, -0.2173])\n","Predicted tensor([-0.7010,  0.2546, -0.1321], grad_fn=<SelectBackward>) Actual tensor([-0.8791,  0.0822, -0.3356])\n","Predicted tensor([-0.6991, -0.4662, -0.1089], grad_fn=<SelectBackward>) Actual tensor([-0.7819, -0.4809, -0.2505])\n","Predicted tensor([ 0.5927, -0.1988,  0.0694], grad_fn=<SelectBackward>) Actual tensor([-0.2225, -0.7561, -0.3182])\n","Predicted tensor([-0.3857,  0.7806,  2.5858], grad_fn=<SelectBackward>) Actual tensor([-0.6468, -0.5417, -0.3197])\n","Predicted tensor([-0.3905,  0.0385, -0.1402], grad_fn=<SelectBackward>) Actual tensor([-0.6740, -0.6836, -0.3421])\n","Predicted tensor([-0.6861, -0.5024, -0.1022], grad_fn=<SelectBackward>) Actual tensor([-0.5654, -0.7809, -0.2619])\n","Predicted tensor([-0.1216, -0.2689, -0.0987], grad_fn=<SelectBackward>) Actual tensor([ 1.0996, -0.4885, -0.3347])\n","Predicted tensor([ 0.3972, -0.1187, -0.0900], grad_fn=<SelectBackward>) Actual tensor([-0.7432, -0.2832, -0.2502])\n","Predicted tensor([ 0.4804, -0.3789, -0.2147], grad_fn=<SelectBackward>) Actual tensor([ 1.1335, -0.7213, -0.3267])\n","Predicted tensor([-0.3727, -0.2238, -0.1054], grad_fn=<SelectBackward>) Actual tensor([-0.7665, -0.6969, -0.2800])\n","Predicted tensor([ 0.7496, -0.1560, -0.1291], grad_fn=<SelectBackward>) Actual tensor([ 0.6730, -0.3130, -0.2936])\n","Predicted tensor([-0.0966, -0.0908, -0.1382], grad_fn=<SelectBackward>) Actual tensor([-1.0801,  1.6654,  0.5396])\n","Predicted tensor([ 0.6890, -0.3055, -0.2431], grad_fn=<SelectBackward>) Actual tensor([ 1.1243, -0.6837, -0.3286])\n","Predicted tensor([ 0.6929, -0.3400, -0.2525], grad_fn=<SelectBackward>) Actual tensor([ 1.1009, -0.7523, -0.3297])\n","Predicted tensor([ 0.6954, -0.2698, -0.2346], grad_fn=<SelectBackward>) Actual tensor([ 1.1849, -0.5719, -0.3225])\n","Predicted tensor([-0.0372,  0.5653,  0.3936], grad_fn=<SelectBackward>) Actual tensor([-2.6376,  1.5941,  0.3179])\n","Predicted tensor([-0.4993, -0.2914, -0.0938], grad_fn=<SelectBackward>) Actual tensor([-0.3759, -0.7714, -0.3313])\n","Predicted tensor([-0.3129,  1.2003,  1.2068], grad_fn=<SelectBackward>) Actual tensor([-0.6984,  2.7547,  2.3004])\n","Predicted tensor([-0.5674, -0.4806, -0.0951], grad_fn=<SelectBackward>) Actual tensor([-0.6702, -0.7620, -0.2731])\n","Predicted tensor([ 0.5582, -0.3548, -0.1370], grad_fn=<SelectBackward>) Actual tensor([-1.2463,  0.3172,  0.0402])\n","Predicted tensor([-0.4913, -0.1371, -0.1540], grad_fn=<SelectBackward>) Actual tensor([ 0.3941,  3.3251, -0.1672])\n","Predicted tensor([ 0.7366, -0.2942, -0.2616], grad_fn=<SelectBackward>) Actual tensor([ 1.0846, -0.7607, -0.3047])\n","Predicted tensor([0.2995, 0.1163, 0.0635], grad_fn=<SelectBackward>) Actual tensor([-0.4198, -0.7224, -0.3136])\n","Predicted tensor([0.7737, 0.4741, 0.0100], grad_fn=<SelectBackward>) Actual tensor([2.3607, 2.1535, 0.1254])\n","Predicted tensor([-0.3518, -0.1718, -0.1749], grad_fn=<SelectBackward>) Actual tensor([-0.6960, -0.6063, -0.2628])\n","Predicted tensor([ 0.5814,  0.0944, -0.1796], grad_fn=<SelectBackward>) Actual tensor([ 1.1240, -0.1806, -0.3490])\n","Predicted tensor([ 0.0213,  0.1592, -0.1140], grad_fn=<SelectBackward>) Actual tensor([-0.8334, -0.5025, -0.3373])\n","Predicted tensor([ 0.7050, -0.3617, -0.2594], grad_fn=<SelectBackward>) Actual tensor([-0.6299, -0.7840, -0.3150])\n","Predicted tensor([-0.3870,  0.3463,  0.2389], grad_fn=<SelectBackward>) Actual tensor([ 1.0860, -0.6973, -0.3296])\n","Predicted tensor([-0.3895, -0.3571, -0.1402], grad_fn=<SelectBackward>) Actual tensor([-0.4703, -0.7376, -0.2200])\n","Predicted tensor([-0.1114, -0.3068, -0.1185], grad_fn=<SelectBackward>) Actual tensor([ 0.1706,  0.3029, -0.1858])\n","Predicted tensor([-0.7064, -0.4394, -0.1148], grad_fn=<SelectBackward>) Actual tensor([-0.7515, -0.7049, -0.2682])\n","Predicted tensor([-0.5931, -0.3638, -0.1488], grad_fn=<SelectBackward>) Actual tensor([-0.6196, -0.1558, -0.2336])\n","Predicted tensor([-0.6677, -0.2963, -0.1205], grad_fn=<SelectBackward>) Actual tensor([-0.7764, -0.4958, -0.2802])\n","Predicted tensor([-0.6281, -0.5274, -0.0858], grad_fn=<SelectBackward>) Actual tensor([-0.7006, -0.7379, -0.2414])\n","Predicted tensor([ 0.6982, -0.3819, -0.2609], grad_fn=<SelectBackward>) Actual tensor([ 0.8079,  0.5794, -0.1968])\n","Predicted tensor([-0.5314, -0.2965,  0.0137], grad_fn=<SelectBackward>) Actual tensor([ 1.6741, -0.3353, -0.3507])\n","Predicted tensor([ 0.6901, -0.3596, -0.2668], grad_fn=<SelectBackward>) Actual tensor([ 1.7321,  0.0482, -0.3711])\n","Predicted tensor([ 0.2044, -0.2653, -0.1223], grad_fn=<SelectBackward>) Actual tensor([ 1.1085, -0.7794, -0.3305])\n","Predicted tensor([ 0.6951, -0.3619, -0.2544], grad_fn=<SelectBackward>) Actual tensor([ 1.0845,  0.3420, -0.3575])\n","Predicted tensor([-0.6392, -0.4338, -0.1284], grad_fn=<SelectBackward>) Actual tensor([-0.8153,  0.0607, -0.1832])\n","Predicted tensor([-0.6509, -0.3378, -0.1183], grad_fn=<SelectBackward>) Actual tensor([-0.6212, -0.7400, -0.2601])\n","Predicted tensor([0.4238, 0.9448, 0.3190], grad_fn=<SelectBackward>) Actual tensor([0.4419, 0.1674, 0.6998])\n","Predicted tensor([0.4205, 1.4016, 0.1362], grad_fn=<SelectBackward>) Actual tensor([-0.0989, -0.3910, -0.2904])\n","Predicted tensor([-0.0753, -0.2293, -0.1561], grad_fn=<SelectBackward>) Actual tensor([-0.2217, -0.5600, -0.3257])\n","Predicted tensor([ 0.4133,  0.1568, -0.2291], grad_fn=<SelectBackward>) Actual tensor([-0.4596, -0.6753, -0.3021])\n","Predicted tensor([-0.5721, -0.3886, -0.1262], grad_fn=<SelectBackward>) Actual tensor([-1.8458, -0.5991,  0.0080])\n","Predicted tensor([ 0.7201, -0.3450, -0.2948], grad_fn=<SelectBackward>) Actual tensor([ 0.8410, -0.2635, -0.3191])\n","Predicted tensor([ 0.0262, -0.2806, -0.1143], grad_fn=<SelectBackward>) Actual tensor([ 1.8283, -0.5173,  0.3671])\n","Predicted tensor([ 0.7465, -0.2986, -0.2222], grad_fn=<SelectBackward>) Actual tensor([ 0.9366, -0.6098, -0.3169])\n","Predicted tensor([-0.2399, -0.3210, -0.1184], grad_fn=<SelectBackward>) Actual tensor([-0.4365, -0.6393, -0.3073])\n","Predicted tensor([0.3397, 0.9073, 0.0157], grad_fn=<SelectBackward>) Actual tensor([ 1.0014,  1.1378, -0.2230])\n","Predicted tensor([ 0.6389, -0.1307, -0.2140], grad_fn=<SelectBackward>) Actual tensor([ 0.0753,  1.3359, -0.1343])\n","Predicted tensor([-0.5637, -0.4206, -0.1039], grad_fn=<SelectBackward>) Actual tensor([-0.7399, -0.7301, -0.2976])\n","Predicted tensor([ 0.6757, -0.2370, -0.2268], grad_fn=<SelectBackward>) Actual tensor([ 0.3057,  0.4931, -0.2494])\n","Predicted tensor([0.0973, 0.5982, 0.1571], grad_fn=<SelectBackward>) Actual tensor([1.1748, 2.2168, 0.6327])\n","Predicted tensor([-0.1968, -0.3097, -0.1063], grad_fn=<SelectBackward>) Actual tensor([ 1.0329, -0.7189, -0.2174])\n","Predicted tensor([ 0.1415, -0.3159, -0.1150], grad_fn=<SelectBackward>) Actual tensor([ 0.3907, -0.6433, -0.2376])\n","Predicted tensor([ 0.5350, -0.0623, -0.2074], grad_fn=<SelectBackward>) Actual tensor([ 1.0842,  0.0105, -0.3473])\n","Predicted tensor([ 0.3994, -0.3561, -0.1490], grad_fn=<SelectBackward>) Actual tensor([ 1.1129, -0.7447, -0.3309])\n","Predicted tensor([-0.5577, -0.5542, -0.0920], grad_fn=<SelectBackward>) Actual tensor([-0.7359, -0.7149, -0.2904])\n","Predicted tensor([-1.0545,  0.3526, -0.0572], grad_fn=<SelectBackward>) Actual tensor([-0.3943,  1.1790, -0.3620])\n","Predicted tensor([ 0.0558, -0.2123, -0.1345], grad_fn=<SelectBackward>) Actual tensor([ 1.7542, -0.0635,  0.0110])\n","Predicted tensor([ 0.4789, -0.3905, -0.2091], grad_fn=<SelectBackward>) Actual tensor([ 0.1392, -0.2603, -0.2419])\n","Predicted tensor([ 0.0427, -0.3770, -0.1035], grad_fn=<SelectBackward>) Actual tensor([-0.3065, -0.5800, -0.2178])\n","Predicted tensor([-0.3949, -0.2947, -0.1040], grad_fn=<SelectBackward>) Actual tensor([-0.3519, -0.5484, -0.2207])\n","Predicted tensor([-0.6459, -0.5282, -0.0990], grad_fn=<SelectBackward>) Actual tensor([-0.7926, -0.6785, -0.2524])\n","Predicted tensor([0.0247, 1.0745, 0.1110], grad_fn=<SelectBackward>) Actual tensor([ 1.0310,  2.0286, -0.2396])\n","Predicted tensor([-0.6835,  0.1341, -0.1269], grad_fn=<SelectBackward>) Actual tensor([-0.5271, -0.3812, -0.3004])\n","Predicted tensor([-0.5269, -0.2691, -0.1343], grad_fn=<SelectBackward>) Actual tensor([ 0.1162, -0.7283, -0.3322])\n","Predicted tensor([ 0.2134,  0.7522, -0.1442], grad_fn=<SelectBackward>) Actual tensor([-1.8984,  0.6186,  0.1896])\n","Predicted tensor([-0.5317, -0.3072, -0.1178], grad_fn=<SelectBackward>) Actual tensor([-0.6391, -0.7842, -0.3155])\n","Predicted tensor([ 0.1134, -0.2953, -0.1292], grad_fn=<SelectBackward>) Actual tensor([ 0.9494,  1.8433, -0.1820])\n","Predicted tensor([-0.6497, -0.4928, -0.0965], grad_fn=<SelectBackward>) Actual tensor([ 0.3442, -0.3443, -0.1566])\n","Predicted tensor([ 0.1502,  0.4765, -0.0661], grad_fn=<SelectBackward>) Actual tensor([ 0.4931,  1.3368, -0.2472])\n","Predicted tensor([ 0.7020, -0.1826, -0.2497], grad_fn=<SelectBackward>) Actual tensor([ 1.1100, -0.4624, -0.3102])\n","Predicted tensor([ 0.1870, -0.1633, -0.1167], grad_fn=<SelectBackward>) Actual tensor([ 0.2126, -0.5920, -0.3272])\n","Predicted tensor([0.6489, 0.0009, 0.1676], grad_fn=<SelectBackward>) Actual tensor([-0.4115, -0.7928, -0.2983])\n","Predicted tensor([-0.2487, -0.4594, -0.0834], grad_fn=<SelectBackward>) Actual tensor([-0.5353, -0.7435, -0.1925])\n","Predicted tensor([0.7279, 0.1382, 0.4271], grad_fn=<SelectBackward>) Actual tensor([-0.9598,  0.9541,  0.2795])\n","Predicted tensor([0.4255, 1.1351, 0.0425], grad_fn=<SelectBackward>) Actual tensor([ 1.2347,  0.0827, -0.3566])\n","Predicted tensor([ 0.7391, -0.4133, -0.2879], grad_fn=<SelectBackward>) Actual tensor([ 0.0359,  0.5231, -0.1619])\n","Predicted tensor([ 0.6971, -0.3285, -0.2487], grad_fn=<SelectBackward>) Actual tensor([-0.2932,  0.3202, -0.2977])\n","Predicted tensor([-0.5626, -0.5079, -0.0607], grad_fn=<SelectBackward>) Actual tensor([ 1.9955,  1.0284, -0.3471])\n","Predicted tensor([-0.6764, -0.4793, -0.0954], grad_fn=<SelectBackward>) Actual tensor([-0.8631, -0.6802, -0.2749])\n","Predicted tensor([-0.3528, -0.3993, -0.0949], grad_fn=<SelectBackward>) Actual tensor([-0.5557, -0.7890, -0.2714])\n","Batch: 1 completed\n","Predicted tensor([-0.5535, -0.5514, -0.1019], grad_fn=<SelectBackward>) Actual tensor([-0.6920, -0.7945, -0.2396])\n","Predicted tensor([-0.5777, -0.4181, -0.0896], grad_fn=<SelectBackward>) Actual tensor([ 1.0561, -0.5762, -0.3364])\n","Predicted tensor([ 0.7076, -0.3568, -0.2214], grad_fn=<SelectBackward>) Actual tensor([ 0.8982,  2.2071, -0.1720])\n","Predicted tensor([ 0.5293, -0.2856, -0.1995], grad_fn=<SelectBackward>) Actual tensor([ 1.6155,  0.0216, -0.3566])\n","Predicted tensor([-0.2872, -0.4473, -0.1181], grad_fn=<SelectBackward>) Actual tensor([-0.8153, -0.6238, -0.2693])\n","Predicted tensor([-0.5513, -0.4702, -0.0852], grad_fn=<SelectBackward>) Actual tensor([-0.6978, -0.5518, -0.2639])\n","Predicted tensor([ 0.7004, -0.3967, -0.2646], grad_fn=<SelectBackward>) Actual tensor([ 1.1591, -0.7624, -0.3051])\n","Predicted tensor([-0.5530, -0.4636, -0.0972], grad_fn=<SelectBackward>) Actual tensor([-0.6071, -0.7453, -0.2662])\n","Predicted tensor([ 0.1986, -0.4033, -0.1054], grad_fn=<SelectBackward>) Actual tensor([-0.0508, -0.7812, -0.2613])\n","Predicted tensor([ 0.0428,  0.0799, -0.0983], grad_fn=<SelectBackward>) Actual tensor([ 1.4379, -0.1662, -0.3391])\n","Predicted tensor([0.1546, 1.0091, 0.1793], grad_fn=<SelectBackward>) Actual tensor([ 0.9339,  0.4509, -0.3438])\n","Predicted tensor([-0.6935, -0.5728, -0.0178], grad_fn=<SelectBackward>) Actual tensor([-0.1240, -0.0632,  4.3291])\n","Predicted tensor([-0.0584,  0.8325,  0.6525], grad_fn=<SelectBackward>) Actual tensor([-0.5555, -0.6433, -0.3262])\n","Predicted tensor([-0.6825,  0.2137, -0.0438], grad_fn=<SelectBackward>) Actual tensor([-1.0266,  0.1681, -0.3733])\n","Predicted tensor([0.5189, 0.0174, 0.1437], grad_fn=<SelectBackward>) Actual tensor([-0.5873, -0.7012, -0.2919])\n","Predicted tensor([ 0.0417,  0.3219, -0.1036], grad_fn=<SelectBackward>) Actual tensor([ 1.0188, -0.2078, -0.2619])\n","Predicted tensor([ 0.1766, -0.1895, -0.1278], grad_fn=<SelectBackward>) Actual tensor([-0.1054, -0.1006, -0.2527])\n","Predicted tensor([0.2974, 0.6408, 0.0633], grad_fn=<SelectBackward>) Actual tensor([-0.5321, -0.7954, -0.2775])\n","Predicted tensor([0.0736, 1.1658, 0.3555], grad_fn=<SelectBackward>) Actual tensor([-1.2014,  1.8152,  2.2112])\n","Predicted tensor([-0.1346, -0.2506, -0.1244], grad_fn=<SelectBackward>) Actual tensor([-0.6358, -0.1952, -0.1659])\n","Predicted tensor([-0.6533, -0.3827, -0.1337], grad_fn=<SelectBackward>) Actual tensor([-0.7700, -0.5352, -0.2614])\n","Predicted tensor([-0.7015, -0.5209, -0.0921], grad_fn=<SelectBackward>) Actual tensor([-0.6905, -0.6135, -0.2261])\n","Predicted tensor([-0.5177,  0.6427, -0.1817], grad_fn=<SelectBackward>) Actual tensor([-0.1812,  1.0183, -0.3521])\n","Predicted tensor([ 0.7077, -0.3358, -0.2591], grad_fn=<SelectBackward>) Actual tensor([ 1.1123, -0.6835, -0.3286])\n","Predicted tensor([ 0.6958, -0.3820, -0.2575], grad_fn=<SelectBackward>) Actual tensor([ 1.1289, -0.7164, -0.3276])\n","Predicted tensor([ 0.2188, -0.3054, -0.1323], grad_fn=<SelectBackward>) Actual tensor([ 0.2253, -0.7878, -0.3098])\n","Predicted tensor([-0.6718, -0.5039, -0.0870], grad_fn=<SelectBackward>) Actual tensor([-0.1638,  0.0570, -0.1306])\n","Predicted tensor([-0.0758,  0.4101, -0.1303], grad_fn=<SelectBackward>) Actual tensor([-0.1603,  0.7098, -0.3241])\n","Predicted tensor([-0.8038, -0.4215, -0.0809], grad_fn=<SelectBackward>) Actual tensor([-0.7704, -0.4483, -0.2683])\n","Predicted tensor([-0.3549,  1.2776,  2.6895], grad_fn=<SelectBackward>) Actual tensor([0.3287, 3.0934, 4.5049])\n","Predicted tensor([-0.7102, -0.4969, -0.1075], grad_fn=<SelectBackward>) Actual tensor([-0.8492, -0.7600, -0.2617])\n","Predicted tensor([ 0.2177, -0.3695, -0.0916], grad_fn=<SelectBackward>) Actual tensor([-0.6799, -0.6512, -0.2517])\n","Predicted tensor([ 0.0533,  1.2190, -0.0705], grad_fn=<SelectBackward>) Actual tensor([-0.3969,  0.2738, -0.3028])\n","Predicted tensor([-0.1956, -0.2532, -0.1282], grad_fn=<SelectBackward>) Actual tensor([-0.1623, -0.2850, -0.3332])\n","Predicted tensor([0.1538, 0.2984, 0.1705], grad_fn=<SelectBackward>) Actual tensor([-0.1067, -0.6023, -0.3299])\n","Predicted tensor([ 0.1274, -0.2004, -0.1066], grad_fn=<SelectBackward>) Actual tensor([ 0.8070, -0.5585, -0.3489])\n","Predicted tensor([ 0.6916, -0.3466, -0.2792], grad_fn=<SelectBackward>) Actual tensor([ 0.2328, -0.5225, -0.3317])\n","Predicted tensor([-0.5428, -0.5358, -0.1005], grad_fn=<SelectBackward>) Actual tensor([-0.6825, -0.7507, -0.2590])\n","Predicted tensor([-0.5166, -0.4646, -0.0839], grad_fn=<SelectBackward>) Actual tensor([-0.6921, -0.7717, -0.2875])\n","Predicted tensor([ 0.6916, -0.2952, -0.2410], grad_fn=<SelectBackward>) Actual tensor([ 1.4760,  1.4002, -0.2140])\n","Predicted tensor([-0.7107, -0.4741, -0.0965], grad_fn=<SelectBackward>) Actual tensor([-0.7188, -0.7734, -0.2360])\n","Predicted tensor([ 0.6990, -0.3284, -0.2532], grad_fn=<SelectBackward>) Actual tensor([ 0.7143, -0.6136, -0.3153])\n","Predicted tensor([ 0.1474,  1.7267, -0.2895], grad_fn=<SelectBackward>) Actual tensor([ 0.9719,  4.1914, -0.2733])\n","Predicted tensor([-0.5554, -0.3367, -0.1285], grad_fn=<SelectBackward>) Actual tensor([-0.9102, -0.5806, -0.1989])\n","Predicted tensor([0.6958, 0.2697, 0.0965], grad_fn=<SelectBackward>) Actual tensor([ 1.8801,  0.2224, -0.0637])\n","Predicted tensor([-0.4188,  0.4500, -0.1933], grad_fn=<SelectBackward>) Actual tensor([ 0.0474,  0.3975, -0.2911])\n","Predicted tensor([ 0.1112, -0.1959, -0.1686], grad_fn=<SelectBackward>) Actual tensor([ 1.1103, -0.7639, -0.3301])\n","Predicted tensor([-1.1833,  0.4804, -0.1395], grad_fn=<SelectBackward>) Actual tensor([-2.3345, -0.4910, -0.4898])\n","Predicted tensor([ 0.6958, -0.2654, -0.2541], grad_fn=<SelectBackward>) Actual tensor([ 1.1195, -0.7212, -0.3264])\n","Predicted tensor([ 0.6786, -0.1575, -0.2200], grad_fn=<SelectBackward>) Actual tensor([-0.7287, -0.3806, -0.2233])\n","Predicted tensor([-0.4938, -0.5135, -0.0997], grad_fn=<SelectBackward>) Actual tensor([-0.5479, -0.7787, -0.2344])\n","Predicted tensor([-0.0335,  0.2227, -0.1364], grad_fn=<SelectBackward>) Actual tensor([-1.0456, -0.2035,  4.7551])\n","Predicted tensor([-0.3221, -0.2572, -0.1448], grad_fn=<SelectBackward>) Actual tensor([-0.3610, -0.4606, -0.2640])\n","Predicted tensor([ 0.0575, -0.3414, -0.1170], grad_fn=<SelectBackward>) Actual tensor([-0.3911, -0.5755, -0.2436])\n","Predicted tensor([-0.6602, -0.3779, -0.1134], grad_fn=<SelectBackward>) Actual tensor([-0.7943, -0.4212, -0.2701])\n","Predicted tensor([ 0.5977,  0.4295, -0.0177], grad_fn=<SelectBackward>) Actual tensor([-0.1516, -0.1044, -0.3293])\n","Predicted tensor([ 0.1923,  0.0558, -0.0529], grad_fn=<SelectBackward>) Actual tensor([ 0.0437,  0.8976, -0.2619])\n","Predicted tensor([-0.8463, -0.0607,  4.1224], grad_fn=<SelectBackward>) Actual tensor([-0.5423,  0.8598,  5.0824])\n","Predicted tensor([-0.5381, -0.3380, -0.0090], grad_fn=<SelectBackward>) Actual tensor([-1.3969, -0.2183, -0.0691])\n","Predicted tensor([ 0.5086,  0.1403, -0.1969], grad_fn=<SelectBackward>) Actual tensor([-0.4824, -0.0759, -0.2386])\n","Predicted tensor([ 0.7022, -0.1683, -0.2110], grad_fn=<SelectBackward>) Actual tensor([ 1.1105, -0.3818, -0.3251])\n","Predicted tensor([ 0.2140, -0.2567, -0.1274], grad_fn=<SelectBackward>) Actual tensor([ 1.1600, -0.4138, -0.2934])\n","Predicted tensor([-0.0056, -0.3140, -0.1285], grad_fn=<SelectBackward>) Actual tensor([-0.2023, -0.2469, -0.1668])\n","Predicted tensor([-0.6904, -0.5004, -0.0731], grad_fn=<SelectBackward>) Actual tensor([-0.4925, -0.6729, -0.2397])\n","Predicted tensor([5.6088e-04, 1.1248e+00, 8.4774e-01], grad_fn=<SelectBackward>) Actual tensor([-1.1499,  0.5236,  1.1067])\n","Predicted tensor([-0.4421,  1.1553,  1.0776], grad_fn=<SelectBackward>) Actual tensor([-1.7008,  1.6134,  0.8615])\n","Predicted tensor([ 0.4405, -0.3354, -0.2820], grad_fn=<SelectBackward>) Actual tensor([-0.0910, -0.7667, -0.3157])\n","Predicted tensor([ 0.1839, -0.1679, -0.1346], grad_fn=<SelectBackward>) Actual tensor([ 0.1120,  0.0849, -0.1864])\n","Predicted tensor([ 0.1416, -0.0627, -0.1153], grad_fn=<SelectBackward>) Actual tensor([-0.5322, -0.2881, -0.3402])\n","Predicted tensor([-0.5634,  0.4582, -0.1620], grad_fn=<SelectBackward>) Actual tensor([ 0.3121,  1.4865, -0.3213])\n","Predicted tensor([-0.2650, -0.3962, -0.0980], grad_fn=<SelectBackward>) Actual tensor([-0.4065, -0.7098, -0.2939])\n","Predicted tensor([-0.0119,  0.5630,  0.8342], grad_fn=<SelectBackward>) Actual tensor([ 0.5389,  0.1657, -0.2380])\n","Predicted tensor([ 0.0033, -0.2068, -0.1129], grad_fn=<SelectBackward>) Actual tensor([-0.5052, -0.6317, -0.3017])\n","Predicted tensor([ 0.4438, -0.4473, -0.2966], grad_fn=<SelectBackward>) Actual tensor([-1.8550, -0.6342,  0.0912])\n","Predicted tensor([-0.5989, -0.2291, -0.1550], grad_fn=<SelectBackward>) Actual tensor([-0.5809, -0.4593, -0.2671])\n","Predicted tensor([0.3643, 0.7462, 0.0236], grad_fn=<SelectBackward>) Actual tensor([ 1.1014,  1.1161, -0.2411])\n","Predicted tensor([0.0081, 0.4211, 0.1732], grad_fn=<SelectBackward>) Actual tensor([2.4650, 1.9625, 0.5176])\n","Predicted tensor([ 0.7491, -0.3869, -0.2944], grad_fn=<SelectBackward>) Actual tensor([ 1.1099, -0.7782, -0.3288])\n","Predicted tensor([ 0.3250,  0.0839, -0.0997], grad_fn=<SelectBackward>) Actual tensor([ 0.5980, -0.2060, -0.3384])\n","Predicted tensor([-0.3321, -0.2980, -0.1140], grad_fn=<SelectBackward>) Actual tensor([-0.6855, -0.7421, -0.3072])\n","Predicted tensor([ 0.0140, -0.2637, -0.1268], grad_fn=<SelectBackward>) Actual tensor([ 1.1470, -0.4837, -0.3388])\n","Predicted tensor([-0.7015, -0.4504, -0.1016], grad_fn=<SelectBackward>) Actual tensor([-0.8353, -0.4195, -0.2601])\n","Predicted tensor([ 0.1416, -0.0472, -0.1219], grad_fn=<SelectBackward>) Actual tensor([-0.1013, -0.1640, -0.3230])\n","Predicted tensor([-0.3830, -0.4315, -0.1073], grad_fn=<SelectBackward>) Actual tensor([-0.4027, -0.3708, -0.2138])\n","Predicted tensor([ 0.7016, -0.3160, -0.2455], grad_fn=<SelectBackward>) Actual tensor([ 1.1334, -0.5857, -0.3261])\n","Predicted tensor([ 0.1806, -0.3299, -0.1194], grad_fn=<SelectBackward>) Actual tensor([ 0.4696, -0.5594, -0.2322])\n","Predicted tensor([0.3611, 0.9113, 0.0435], grad_fn=<SelectBackward>) Actual tensor([-0.7985, -0.7421,  5.1434])\n","Predicted tensor([-0.2148,  1.0914,  0.8037], grad_fn=<SelectBackward>) Actual tensor([-1.4073,  1.4595,  2.5226])\n","Predicted tensor([-0.6684, -0.4945, -0.1099], grad_fn=<SelectBackward>) Actual tensor([-0.8204, -0.4863, -0.2428])\n","Predicted tensor([-0.3314, -0.4806, -0.0906], grad_fn=<SelectBackward>) Actual tensor([-0.5222, -0.5690, -0.1948])\n","Predicted tensor([-0.3560, -0.2608, -0.0526], grad_fn=<SelectBackward>) Actual tensor([ 0.6646,  0.6469, -0.1878])\n","Predicted tensor([-0.4092,  1.4705,  2.5061], grad_fn=<SelectBackward>) Actual tensor([0.0633, 1.8919, 2.5959])\n","Predicted tensor([ 0.0209, -0.1528, -0.1368], grad_fn=<SelectBackward>) Actual tensor([-0.0307, -0.3184, -0.3222])\n","Predicted tensor([0.7424, 0.6669, 0.1375], grad_fn=<SelectBackward>) Actual tensor([ 0.7729, -0.2296, -0.3611])\n","Predicted tensor([ 1.3608e-04, -3.2906e-01, -1.0705e-01], grad_fn=<SelectBackward>) Actual tensor([-1.1268, -0.7809,  5.1445])\n","Predicted tensor([-0.6133,  0.1676, -0.1247], grad_fn=<SelectBackward>) Actual tensor([-0.5447, -0.1772, -0.3533])\n","Predicted tensor([-0.5379, -0.5357, -0.1102], grad_fn=<SelectBackward>) Actual tensor([-0.8835, -0.4334, -0.2465])\n","Predicted tensor([-0.6552, -0.4603, -0.0905], grad_fn=<SelectBackward>) Actual tensor([-0.7262, -0.7681, -0.2817])\n","Predicted tensor([ 0.5226,  0.6506, -0.0103], grad_fn=<SelectBackward>) Actual tensor([ 0.6580, -0.2681, -0.0880])\n","Predicted tensor([ 0.5720, -0.1073, -0.1957], grad_fn=<SelectBackward>) Actual tensor([-0.6569,  1.5136,  0.0301])\n","Predicted tensor([ 0.0796, -0.2823, -0.1367], grad_fn=<SelectBackward>) Actual tensor([ 1.3734, -0.3752, -0.3472])\n","Predicted tensor([ 0.2699,  0.1680, -0.2409], grad_fn=<SelectBackward>) Actual tensor([1.2977, 2.8193, 0.1159])\n","Predicted tensor([-0.3747, -0.4882, -0.1003], grad_fn=<SelectBackward>) Actual tensor([-0.8797, -0.4090, -0.2556])\n","Predicted tensor([ 0.2814,  0.0463, -0.3155], grad_fn=<SelectBackward>) Actual tensor([-0.5323, -0.7928, -0.2699])\n","Predicted tensor([-0.5566, -0.3076, -0.1119], grad_fn=<SelectBackward>) Actual tensor([-0.5172,  0.0042, -0.2015])\n","Predicted tensor([ 0.2900, -0.2153, -0.1384], grad_fn=<SelectBackward>) Actual tensor([ 0.8127,  2.2470, -0.1631])\n","Predicted tensor([ 0.6589, -0.2300, -0.2092], grad_fn=<SelectBackward>) Actual tensor([ 1.0804, -0.6204, -0.3391])\n","Predicted tensor([-0.6173, -0.1223, -0.1152], grad_fn=<SelectBackward>) Actual tensor([-0.4106, -0.7259, -0.2736])\n","Predicted tensor([ 0.6941, -0.3675, -0.2677], grad_fn=<SelectBackward>) Actual tensor([ 1.0993, -0.7499, -0.3351])\n","Predicted tensor([ 0.1966,  1.0814, -0.5001], grad_fn=<SelectBackward>) Actual tensor([ 1.0732,  2.8719, -0.3039])\n","Predicted tensor([ 0.6654, -0.0984, -0.2274], grad_fn=<SelectBackward>) Actual tensor([ 0.9585,  1.2821, -0.2035])\n","Predicted tensor([ 0.2011, -0.1669, -0.1319], grad_fn=<SelectBackward>) Actual tensor([ 0.2456, -0.5610, -0.2738])\n","Predicted tensor([ 0.4136, -0.0244, -0.0950], grad_fn=<SelectBackward>) Actual tensor([ 0.3523,  0.2267, -0.2758])\n","Predicted tensor([0.5891, 0.7904, 0.0559], grad_fn=<SelectBackward>) Actual tensor([-0.6757, -0.5185, -0.3007])\n","Predicted tensor([ 0.1640,  1.1135, -0.0646], grad_fn=<SelectBackward>) Actual tensor([-0.2956,  0.2012, -0.2872])\n","Predicted tensor([-0.1089, -0.3310, -0.1415], grad_fn=<SelectBackward>) Actual tensor([-0.3380,  1.0642, -0.1240])\n","Predicted tensor([-0.1253, -0.4424, -0.0626], grad_fn=<SelectBackward>) Actual tensor([-0.6626, -0.3700, -0.2417])\n","Predicted tensor([ 0.6878, -0.3412, -0.2535], grad_fn=<SelectBackward>) Actual tensor([ 1.1269, -0.6520, -0.3321])\n","Predicted tensor([0.7459, 0.5088, 0.1025], grad_fn=<SelectBackward>) Actual tensor([-0.7546, -0.3749, -0.2578])\n","Predicted tensor([ 0.2317, -0.2626, -0.1389], grad_fn=<SelectBackward>) Actual tensor([-0.7661, -0.7421, -0.3167])\n","Predicted tensor([-0.3391,  0.6355, -0.1683], grad_fn=<SelectBackward>) Actual tensor([-0.5691,  1.0088, -0.3657])\n","Predicted tensor([ 0.7542, -0.1672, -0.2459], grad_fn=<SelectBackward>) Actual tensor([ 1.0272, -0.6289, -0.2661])\n","Predicted tensor([ 0.6368, -0.0679, -0.2022], grad_fn=<SelectBackward>) Actual tensor([-0.3480, -0.7783, -0.3016])\n","Predicted tensor([-0.7084, -0.4254, -0.1124], grad_fn=<SelectBackward>) Actual tensor([-0.7570, -0.5058, -0.2701])\n","Predicted tensor([ 0.6915, -0.3507, -0.2381], grad_fn=<SelectBackward>) Actual tensor([ 0.4326, -0.1104, -0.3081])\n","Predicted tensor([ 0.7168, -0.1155, -0.1833], grad_fn=<SelectBackward>) Actual tensor([ 0.8710,  0.9238, -0.1438])\n","Predicted tensor([-0.6245, -0.2487, -0.1616], grad_fn=<SelectBackward>) Actual tensor([-0.8464, -0.7019, -0.1136])\n","Predicted tensor([-0.4950, -0.2536, -0.0979], grad_fn=<SelectBackward>) Actual tensor([1.4705, 3.5367, 1.5154])\n","Predicted tensor([-0.0379, -0.3343, -0.1131], grad_fn=<SelectBackward>) Actual tensor([-0.3419,  0.2270, -0.1931])\n","Predicted tensor([ 0.0929, -0.3271, -0.1010], grad_fn=<SelectBackward>) Actual tensor([ 0.0839, -0.1986, -0.2083])\n","Predicted tensor([ 0.1968, -0.3507, -0.1083], grad_fn=<SelectBackward>) Actual tensor([ 0.1049, -0.3180, -0.2449])\n","Predicted tensor([ 0.3759, -0.2708, -0.1208], grad_fn=<SelectBackward>) Actual tensor([ 0.4544, -0.7579, -0.2520])\n","Predicted tensor([-0.7515, -0.3036, -0.1130], grad_fn=<SelectBackward>) Actual tensor([-0.6831, -0.7840, -0.2492])\n","Predicted tensor([ 0.3516,  0.0433, -0.2843], grad_fn=<SelectBackward>) Actual tensor([-0.3817, -0.7684, -0.3223])\n","Predicted tensor([-0.8303,  0.0237, -0.0877], grad_fn=<SelectBackward>) Actual tensor([-1.8291,  0.1291, -0.5650])\n","Predicted tensor([ 0.6730, -0.1515, -0.2275], grad_fn=<SelectBackward>) Actual tensor([ 0.8493,  0.4886, -0.2365])\n","Predicted tensor([0.3665, 0.8536, 0.0128], grad_fn=<SelectBackward>) Actual tensor([-0.5856,  0.5456, -0.0589])\n","Predicted tensor([-0.4562, -0.4078, -0.0892], grad_fn=<SelectBackward>) Actual tensor([-0.8435, -0.6146, -0.1438])\n","Predicted tensor([ 0.4650,  0.4192, -0.0675], grad_fn=<SelectBackward>) Actual tensor([-2.2489,  1.0970, -0.3540])\n","Predicted tensor([ 0.7383, -0.0726, -0.2058], grad_fn=<SelectBackward>) Actual tensor([-0.0498,  0.9694, -0.1928])\n","Predicted tensor([ 0.6932, -0.3708, -0.2586], grad_fn=<SelectBackward>) Actual tensor([ 1.3970, -0.0430, -0.3594])\n","Predicted tensor([ 0.1675, -0.2757, -0.1161], grad_fn=<SelectBackward>) Actual tensor([ 1.9610,  0.2329, -0.3138])\n","Predicted tensor([ 0.0991, -0.3367, -0.1122], grad_fn=<SelectBackward>) Actual tensor([-0.1788, -0.7220, -0.2191])\n","Predicted tensor([-0.6782, -0.1645, -0.0085], grad_fn=<SelectBackward>) Actual tensor([-0.7090, -0.7107, -0.2821])\n","Predicted tensor([ 0.2293, -0.3348, -0.4230], grad_fn=<SelectBackward>) Actual tensor([2.2084, 2.0658, 0.0080])\n","Predicted tensor([-1.2633,  0.2875, -0.0097], grad_fn=<SelectBackward>) Actual tensor([-1.8635,  0.6043, -0.5002])\n","Predicted tensor([-0.6590, -0.0718, -0.0396], grad_fn=<SelectBackward>) Actual tensor([-1.4501, -0.0683, -0.0551])\n","Predicted tensor([-0.3131, -0.3441, -0.0992], grad_fn=<SelectBackward>) Actual tensor([-0.7513, -0.6693, -0.3129])\n","Predicted tensor([-0.0784, -0.2683, -0.1204], grad_fn=<SelectBackward>) Actual tensor([ 1.1972, -0.4446, -0.3411])\n","Predicted tensor([-0.6371, -0.5084, -0.0869], grad_fn=<SelectBackward>) Actual tensor([ 0.5715,  2.6047, -0.0685])\n","Predicted tensor([ 0.6799, -0.3303, -0.2431], grad_fn=<SelectBackward>) Actual tensor([ 0.6104, -0.4317, -0.2242])\n","Predicted tensor([ 0.4888,  0.2243, -0.1795], grad_fn=<SelectBackward>) Actual tensor([-0.6536, -0.6782, -0.2984])\n","Predicted tensor([ 0.6538, -0.0293, -0.2038], grad_fn=<SelectBackward>) Actual tensor([ 1.2191, -0.2039, -0.3415])\n","Predicted tensor([ 0.6769, -0.2088, -0.2311], grad_fn=<SelectBackward>) Actual tensor([ 0.8742,  0.7925, -0.0285])\n","Predicted tensor([-0.6879, -0.4488, -0.1232], grad_fn=<SelectBackward>) Actual tensor([-0.8159, -0.3924, -0.2738])\n","Predicted tensor([-0.7355, -0.0964, -0.1004], grad_fn=<SelectBackward>) Actual tensor([-0.1273,  0.0927, -0.2573])\n","Predicted tensor([0.0503, 1.0732, 0.1182], grad_fn=<SelectBackward>) Actual tensor([-0.4607, -0.4871, -0.3290])\n","Predicted tensor([-0.3222, -0.4439, -0.1146], grad_fn=<SelectBackward>) Actual tensor([-0.4921, -0.7867, -0.2412])\n","Predicted tensor([-0.6050, -0.4886, -0.0900], grad_fn=<SelectBackward>) Actual tensor([-0.0721, -0.7892, -0.3254])\n","Predicted tensor([ 0.2711,  0.1853, -0.2441], grad_fn=<SelectBackward>) Actual tensor([1.9612, 0.8843, 0.4823])\n","Predicted tensor([-0.4418, -0.3785, -0.1376], grad_fn=<SelectBackward>) Actual tensor([-0.6343, -0.7258, -0.2920])\n","Predicted tensor([-0.7858, -0.1441, -0.0761], grad_fn=<SelectBackward>) Actual tensor([-0.8264,  1.3284,  5.1262])\n","Predicted tensor([-0.2360,  1.2866,  0.8618], grad_fn=<SelectBackward>) Actual tensor([-0.1852, -0.1790, -0.2320])\n","Predicted tensor([-0.1722, -0.2821, -0.1501], grad_fn=<SelectBackward>) Actual tensor([ 0.2360, -0.6542, -0.2372])\n","Predicted tensor([-0.4635,  0.4801, -0.1597], grad_fn=<SelectBackward>) Actual tensor([-0.2356,  0.7812, -0.3749])\n","Predicted tensor([-0.5863, -0.4569, -0.1184], grad_fn=<SelectBackward>) Actual tensor([ 0.0744, -0.7872, -0.2574])\n","Predicted tensor([ 0.3827, -0.1545, -0.3194], grad_fn=<SelectBackward>) Actual tensor([-0.1614, -0.6896, -0.3206])\n","Predicted tensor([ 0.2035, -0.3057, -0.1408], grad_fn=<SelectBackward>) Actual tensor([-0.1755, -0.7956, -0.3139])\n","Predicted tensor([-0.2021, -0.1458, -0.1144], grad_fn=<SelectBackward>) Actual tensor([-0.1665,  0.0822, -0.2564])\n","Predicted tensor([ 0.7439, -0.2115, -0.2290], grad_fn=<SelectBackward>) Actual tensor([ 1.1135, -0.7404, -0.3270])\n","Predicted tensor([ 0.5488,  0.1272, -0.1911], grad_fn=<SelectBackward>) Actual tensor([ 1.0410,  2.0774, -0.2626])\n","Predicted tensor([-0.6781, -0.4676, -0.1254], grad_fn=<SelectBackward>) Actual tensor([-0.7738, -0.7969, -0.2533])\n","Predicted tensor([-0.6210,  0.1664, -0.0918], grad_fn=<SelectBackward>) Actual tensor([-0.6772, -0.1849, -0.2995])\n","Predicted tensor([ 0.7140, -0.3222, -0.2676], grad_fn=<SelectBackward>) Actual tensor([ 1.0961, -0.5940, -0.3287])\n","Predicted tensor([-0.7403, -0.2374, -0.0872], grad_fn=<SelectBackward>) Actual tensor([-1.7419, -0.4817, -0.2404])\n","Predicted tensor([-0.7523,  0.5579, -0.1440], grad_fn=<SelectBackward>) Actual tensor([ 0.1330,  1.4213, -0.3155])\n","Predicted tensor([ 0.5382,  0.7627, -0.0577], grad_fn=<SelectBackward>) Actual tensor([ 0.7346, -0.5107, -0.3508])\n","Predicted tensor([ 0.6354, -0.0367, -0.2145], grad_fn=<SelectBackward>) Actual tensor([-0.5203, -0.7824, -0.2850])\n","Predicted tensor([ 0.6943, -0.3836, -0.2655], grad_fn=<SelectBackward>) Actual tensor([ 1.1098, -0.7783, -0.3288])\n","Predicted tensor([ 0.2024,  0.7169, -0.1750], grad_fn=<SelectBackward>) Actual tensor([0.9563, 3.3369, 1.3883])\n","Predicted tensor([ 0.6673, -0.3210, -0.2001], grad_fn=<SelectBackward>) Actual tensor([ 1.3452, -0.6281, -0.3156])\n","Predicted tensor([-0.6487, -0.5291, -0.0860], grad_fn=<SelectBackward>) Actual tensor([-0.7740, -0.4774, -0.2783])\n","Predicted tensor([ 0.1963, -0.3897, -0.1159], grad_fn=<SelectBackward>) Actual tensor([-1.1675,  0.3308,  0.1057])\n","Predicted tensor([-0.6244, -0.5225, -0.1134], grad_fn=<SelectBackward>) Actual tensor([-0.8308, -0.6225, -0.2642])\n","Predicted tensor([-1.4926,  0.0836,  0.0593], grad_fn=<SelectBackward>) Actual tensor([ 1.2093, -0.2797, -0.0992])\n","Predicted tensor([-0.6090, -0.4729, -0.1010], grad_fn=<SelectBackward>) Actual tensor([-0.7112, -0.5864, -0.2961])\n","Predicted tensor([ 0.1180, -0.2791, -0.1064], grad_fn=<SelectBackward>) Actual tensor([ 0.4764,  0.0364, -0.2185])\n","Predicted tensor([-0.0604,  1.2880,  0.5267], grad_fn=<SelectBackward>) Actual tensor([0.2977, 3.8297, 1.6275])\n","Predicted tensor([-0.4290, -0.4625, -0.1037], grad_fn=<SelectBackward>) Actual tensor([ 0.2286,  1.2871, -0.1294])\n","Predicted tensor([0.2239, 0.8802, 0.1597], grad_fn=<SelectBackward>) Actual tensor([ 0.1860, -0.7943, -0.3235])\n","Predicted tensor([ 0.1990,  0.5286, -0.1872], grad_fn=<SelectBackward>) Actual tensor([-0.2994, -0.6919, -0.3132])\n","Predicted tensor([-0.3530, -0.2969, -0.1525], grad_fn=<SelectBackward>) Actual tensor([-0.5039,  0.8735, -0.1312])\n","Predicted tensor([ 0.0399, -0.1811, -0.1121], grad_fn=<SelectBackward>) Actual tensor([-0.3377, -0.6924, -0.2957])\n","Predicted tensor([ 0.6843, -0.2450, -0.2341], grad_fn=<SelectBackward>) Actual tensor([-0.5752, -0.7663, -0.3065])\n","Predicted tensor([ 0.2573, -0.2680, -0.1357], grad_fn=<SelectBackward>) Actual tensor([ 0.0310, -0.6634, -0.3308])\n","Predicted tensor([ 0.2875,  0.0251, -0.0685], grad_fn=<SelectBackward>) Actual tensor([-1.9164,  0.5557,  0.6661])\n","Predicted tensor([0.3883, 0.7936, 0.0028], grad_fn=<SelectBackward>) Actual tensor([ 0.8423,  1.6345, -0.2835])\n","Predicted tensor([-0.6154, -0.3215, -0.1745], grad_fn=<SelectBackward>) Actual tensor([-0.5796, -0.7339, -0.1618])\n","Predicted tensor([-0.8885, -0.0880,  0.0825], grad_fn=<SelectBackward>) Actual tensor([-1.9154, -0.6021, -0.0501])\n","Predicted tensor([ 0.5912, -0.0090, -0.1334], grad_fn=<SelectBackward>) Actual tensor([-0.1242, -0.2478, -0.2541])\n","Batch: 2 completed\n","Predicted tensor([-1.1176, -0.8668,  4.5037], grad_fn=<SelectBackward>) Actual tensor([-1.1115, -0.4241,  5.1583])\n","Predicted tensor([-0.5429,  1.2711,  2.9263], grad_fn=<SelectBackward>) Actual tensor([-1.0893,  1.9547,  5.0747])\n","Predicted tensor([-0.0278,  0.2728, -0.2332], grad_fn=<SelectBackward>) Actual tensor([ 0.4606, -0.5192, -0.2350])\n","Predicted tensor([-0.7118, -0.4229, -0.1005], grad_fn=<SelectBackward>) Actual tensor([-0.8391, -0.4079, -0.2676])\n","Predicted tensor([0.6090, 1.1874, 0.0306], grad_fn=<SelectBackward>) Actual tensor([ 1.6998,  3.5393, -0.0963])\n","Predicted tensor([ 0.4133,  0.2086, -0.1239], grad_fn=<SelectBackward>) Actual tensor([ 0.1422,  0.0985, -0.2549])\n","Predicted tensor([ 0.6889, -0.2612, -0.2535], grad_fn=<SelectBackward>) Actual tensor([-0.0521,  1.3934, -0.1290])\n","Predicted tensor([-0.6503, -0.4015, -0.1142], grad_fn=<SelectBackward>) Actual tensor([-0.8601, -0.7289, -0.2704])\n","Predicted tensor([0.7071, 0.2968, 0.1129], grad_fn=<SelectBackward>) Actual tensor([ 1.8266,  0.2412, -0.0042])\n","Predicted tensor([ 0.5191, -0.1662, -0.2196], grad_fn=<SelectBackward>) Actual tensor([-0.6520,  1.3219,  0.1022])\n","Predicted tensor([ 0.6986, -0.3257, -0.2304], grad_fn=<SelectBackward>) Actual tensor([ 0.9211, -0.7162, -0.2634])\n","Predicted tensor([-0.9461, -0.1332, -0.0891], grad_fn=<SelectBackward>) Actual tensor([-1.4928,  0.1919, -0.2042])\n","Predicted tensor([ 0.7016, -0.3413, -0.2542], grad_fn=<SelectBackward>) Actual tensor([ 0.6381, -0.6006, -0.3105])\n","Predicted tensor([ 0.1617,  0.7530, -0.0595], grad_fn=<SelectBackward>) Actual tensor([ 0.6652,  0.6978, -0.2148])\n","Predicted tensor([ 0.3652, -0.1005, -0.1151], grad_fn=<SelectBackward>) Actual tensor([ 1.6265,  1.6380, -0.2440])\n","Predicted tensor([-0.2294, -0.1744, -0.1248], grad_fn=<SelectBackward>) Actual tensor([-0.3903, -0.3644, -0.2203])\n","Predicted tensor([-0.8019, -0.3620,  0.0965], grad_fn=<SelectBackward>) Actual tensor([-0.7627, -0.5649, -0.2829])\n","Predicted tensor([-0.9983, -0.4958,  4.5994], grad_fn=<SelectBackward>) Actual tensor([-0.9832, -0.4908,  5.1522])\n","Predicted tensor([-0.4558, -0.4996, -0.1212], grad_fn=<SelectBackward>) Actual tensor([-0.7431, -0.5092, -0.2280])\n","Predicted tensor([-0.5920, -0.3948, -0.0767], grad_fn=<SelectBackward>) Actual tensor([ 0.0669, -0.7937, -0.2624])\n","Predicted tensor([ 0.1717,  0.1373, -0.0409], grad_fn=<SelectBackward>) Actual tensor([-0.3945, -0.7140, -0.3129])\n","Predicted tensor([ 0.3721,  0.5184, -0.0316], grad_fn=<SelectBackward>) Actual tensor([-2.0972,  0.0817, -0.4478])\n","Predicted tensor([ 0.0108, -0.3306, -0.1131], grad_fn=<SelectBackward>) Actual tensor([ 0.1131, -0.3957, -0.2023])\n","Predicted tensor([ 0.6886, -0.3667, -0.2648], grad_fn=<SelectBackward>) Actual tensor([ 1.0976, -0.7297, -0.3331])\n","Predicted tensor([ 0.6001,  0.1478, -0.0904], grad_fn=<SelectBackward>) Actual tensor([ 0.9999, -0.1550, -0.2401])\n","Predicted tensor([-0.3164, -0.1542, -0.1800], grad_fn=<SelectBackward>) Actual tensor([-0.3051,  0.1455, -0.1669])\n","Predicted tensor([-0.3343, -0.4567, -0.1062], grad_fn=<SelectBackward>) Actual tensor([-0.1125,  0.1922, -0.1804])\n","Predicted tensor([-0.5917, -0.5283, -0.0837], grad_fn=<SelectBackward>) Actual tensor([-0.5625, -0.7885, -0.2355])\n","Predicted tensor([ 0.6698, -0.1927, -0.1839], grad_fn=<SelectBackward>) Actual tensor([ 1.4244, -0.2977, -0.2893])\n","Predicted tensor([-1.3169,  0.3675, -0.0329], grad_fn=<SelectBackward>) Actual tensor([-2.2922, -0.6594, -0.4779])\n","Predicted tensor([ 0.0837, -0.1070, -0.1542], grad_fn=<SelectBackward>) Actual tensor([ 1.1245,  0.1517, -0.3535])\n","Predicted tensor([-0.6602, -0.2977, -0.1320], grad_fn=<SelectBackward>) Actual tensor([-0.6399, -0.5108, -0.1935])\n","Predicted tensor([-0.6979, -0.5238, -0.0842], grad_fn=<SelectBackward>) Actual tensor([-0.7219, -0.7954, -0.2814])\n","Predicted tensor([ 0.6352, -0.0802, -0.2006], grad_fn=<SelectBackward>) Actual tensor([-0.3963, -0.7823, -0.3014])\n","Predicted tensor([ 0.2177, -0.2674, -0.1196], grad_fn=<SelectBackward>) Actual tensor([-0.3756, -0.7352, -0.2729])\n","Predicted tensor([ 0.6940, -0.3838, -0.2657], grad_fn=<SelectBackward>) Actual tensor([ 0.1992, -0.7500, -0.3318])\n","Predicted tensor([-0.3987, -0.1919, -0.1817], grad_fn=<SelectBackward>) Actual tensor([-0.0886,  0.7497, -0.1522])\n","Predicted tensor([-0.7043, -0.2127, -0.0904], grad_fn=<SelectBackward>) Actual tensor([-0.7993, -0.7235, -0.3413])\n","Predicted tensor([ 0.4202,  0.3736, -0.0670], grad_fn=<SelectBackward>) Actual tensor([ 1.1140, -0.6456, -0.3332])\n","Predicted tensor([-0.4781,  0.0632, -0.0914], grad_fn=<SelectBackward>) Actual tensor([-0.5300, -0.2276, -0.3422])\n","Predicted tensor([ 0.6619, -0.0567,  0.3079], grad_fn=<SelectBackward>) Actual tensor([2.2062, 2.1870, 0.0846])\n","Predicted tensor([-0.2541, -0.0286, -0.1069], grad_fn=<SelectBackward>) Actual tensor([ 0.6401,  2.2046, -0.0046])\n","Predicted tensor([-0.6557, -0.4170, -0.1084], grad_fn=<SelectBackward>) Actual tensor([-0.7117, -0.6749, -0.2705])\n","Predicted tensor([ 0.7033, -0.3938, -0.2680], grad_fn=<SelectBackward>) Actual tensor([ 1.1128, -0.4499, -0.3277])\n","Predicted tensor([ 0.1488, -0.1653, -0.1212], grad_fn=<SelectBackward>) Actual tensor([ 1.8832,  0.2701, -0.3599])\n","Predicted tensor([-0.3641, -0.4647, -0.0918], grad_fn=<SelectBackward>) Actual tensor([-0.3885, -0.7850, -0.2081])\n","Predicted tensor([ 0.7066, -0.4354, -0.2428], grad_fn=<SelectBackward>) Actual tensor([ 0.7029, -0.6569, -0.2979])\n","Predicted tensor([ 0.2430,  0.0189, -0.1141], grad_fn=<SelectBackward>) Actual tensor([ 1.1372, -0.5587, -0.3366])\n","Predicted tensor([-0.6365, -0.3506, -0.1295], grad_fn=<SelectBackward>) Actual tensor([-0.7403, -0.7411, -0.2791])\n","Predicted tensor([-0.6388, -0.4165, -0.1255], grad_fn=<SelectBackward>) Actual tensor([-0.6002, -0.6825, -0.3181])\n","Predicted tensor([-0.5116, -0.5823, -0.0593], grad_fn=<SelectBackward>) Actual tensor([ 0.0595,  1.0431, -0.1730])\n","Predicted tensor([-0.5930,  0.3918, -0.1054], grad_fn=<SelectBackward>) Actual tensor([-0.0496,  0.8877, -0.3483])\n","Predicted tensor([ 0.0531, -0.1734, -0.1411], grad_fn=<SelectBackward>) Actual tensor([ 1.1851,  0.0540, -0.3555])\n","Predicted tensor([ 0.6685, -0.3679, -0.1920], grad_fn=<SelectBackward>) Actual tensor([-0.4506, -0.4828, -0.2526])\n","Predicted tensor([-0.4302, -0.4139, -0.0988], grad_fn=<SelectBackward>) Actual tensor([-0.4527, -0.7879, -0.3155])\n","Predicted tensor([ 0.7158, -0.3537, -0.2859], grad_fn=<SelectBackward>) Actual tensor([ 1.3191, -0.1795, -0.3097])\n","Predicted tensor([0.4424, 0.0390, 0.1357], grad_fn=<SelectBackward>) Actual tensor([-0.5831, -0.7730, -0.3209])\n","Predicted tensor([-0.3163, -0.3847, -0.0886], grad_fn=<SelectBackward>) Actual tensor([ 0.6337, -0.2937,  0.0155])\n","Predicted tensor([ 0.0958, -0.1275, -0.1116], grad_fn=<SelectBackward>) Actual tensor([-0.3998, -0.6513, -0.2653])\n","Predicted tensor([ 0.6459, -0.0417, -0.2074], grad_fn=<SelectBackward>) Actual tensor([ 1.3328, -0.1570, -0.3453])\n","Predicted tensor([-0.5694, -0.2836, -0.1212], grad_fn=<SelectBackward>) Actual tensor([-0.4842, -0.5622, -0.3305])\n","Predicted tensor([-0.8920,  0.0519, -0.0998], grad_fn=<SelectBackward>) Actual tensor([-0.2034,  0.1310, -0.3702])\n","Predicted tensor([-0.7762,  0.0259, -0.1422], grad_fn=<SelectBackward>) Actual tensor([-1.1771, -0.6707,  5.1607])\n","Predicted tensor([ 0.7007, -0.2658, -0.2355], grad_fn=<SelectBackward>) Actual tensor([ 1.1591, -0.4870, -0.3269])\n","Predicted tensor([ 0.6910, -0.2207, -0.2405], grad_fn=<SelectBackward>) Actual tensor([-0.5812, -0.7820, -0.3170])\n","Predicted tensor([-0.6690, -0.6016, -0.0506], grad_fn=<SelectBackward>) Actual tensor([-1.5899,  0.2921, -0.3082])\n","Predicted tensor([ 0.1470, -0.2208, -0.1309], grad_fn=<SelectBackward>) Actual tensor([ 0.9238,  0.9610, -0.2588])\n","Predicted tensor([-0.5382, -0.4831, -0.0852], grad_fn=<SelectBackward>) Actual tensor([ 1.1049, -0.7195, -0.3313])\n","Predicted tensor([ 0.7586, -0.4053, -0.2920], grad_fn=<SelectBackward>) Actual tensor([ 1.0083, -0.4286, -0.2808])\n","Predicted tensor([-0.2068, -0.2871, -0.1030], grad_fn=<SelectBackward>) Actual tensor([-0.4794, -0.7463, -0.3130])\n","Predicted tensor([-0.2567,  0.5573, -0.1370], grad_fn=<SelectBackward>) Actual tensor([-0.6631,  0.4983, -0.3824])\n","Predicted tensor([ 0.6902, -0.1959, -0.2443], grad_fn=<SelectBackward>) Actual tensor([-0.3746, -0.6153, -0.3317])\n","Predicted tensor([-0.6729, -0.4597, -0.1058], grad_fn=<SelectBackward>) Actual tensor([-0.8270, -0.5930, -0.2794])\n","Predicted tensor([ 0.6474, -0.0965, -0.2188], grad_fn=<SelectBackward>) Actual tensor([-0.3053, -0.4200, -0.2552])\n","Predicted tensor([-0.1709, -0.4398, -0.1163], grad_fn=<SelectBackward>) Actual tensor([-0.8303, -0.5243, -0.2944])\n","Predicted tensor([-1.3860,  0.3178,  0.0123], grad_fn=<SelectBackward>) Actual tensor([ 1.1756, -0.4638, -0.3259])\n","Predicted tensor([-0.2848, -0.3550, -0.1336], grad_fn=<SelectBackward>) Actual tensor([ 1.1800, -0.5293, -0.3311])\n","Predicted tensor([-0.6087, -0.0260, -0.1038], grad_fn=<SelectBackward>) Actual tensor([ 1.5535, -0.3566, -0.3457])\n","Predicted tensor([ 0.6931, -0.3394, -0.2560], grad_fn=<SelectBackward>) Actual tensor([ 1.1181, -0.7208, -0.3326])\n","Predicted tensor([ 0.4017,  0.5628, -0.0425], grad_fn=<SelectBackward>) Actual tensor([ 0.8211,  1.4592, -0.1972])\n","Predicted tensor([-0.2136, -0.2802, -0.1192], grad_fn=<SelectBackward>) Actual tensor([-0.6978, -0.7935, -0.3105])\n","Predicted tensor([0.3568, 0.2934, 0.1181], grad_fn=<SelectBackward>) Actual tensor([-0.4464, -0.7392, -0.3106])\n","Predicted tensor([ 0.6909, -0.3953, -0.2656], grad_fn=<SelectBackward>) Actual tensor([-0.5673, -0.0597, -0.2109])\n","Predicted tensor([ 0.6861, -0.2514, -0.2160], grad_fn=<SelectBackward>) Actual tensor([ 0.8131, -0.0339, -0.2733])\n","Predicted tensor([0.2884, 0.9635, 0.1535], grad_fn=<SelectBackward>) Actual tensor([-0.3419,  1.4131,  0.5037])\n","Predicted tensor([ 0.5234, -0.1539, -0.2334], grad_fn=<SelectBackward>) Actual tensor([-0.5267, -0.7594, -0.2460])\n","Predicted tensor([-0.6893, -0.4908, -0.1039], grad_fn=<SelectBackward>) Actual tensor([-0.8323, -0.4404, -0.2863])\n","Predicted tensor([ 0.4300,  0.3289, -0.1330], grad_fn=<SelectBackward>) Actual tensor([0.4896, 2.5187, 0.1322])\n","Predicted tensor([ 0.4910,  0.3695, -0.0945], grad_fn=<SelectBackward>) Actual tensor([ 1.5717,  0.5281, -0.1254])\n","Predicted tensor([-0.0142, -0.1594, -0.1581], grad_fn=<SelectBackward>) Actual tensor([ 1.1099, -0.7414, -0.3312])\n","Predicted tensor([ 0.5408,  0.3241, -0.0108], grad_fn=<SelectBackward>) Actual tensor([ 2.1402,  0.2599, -0.2216])\n","Predicted tensor([0.2271, 0.0008, 0.0292], grad_fn=<SelectBackward>) Actual tensor([-0.4807,  0.4136,  0.1435])\n","Predicted tensor([ 0.5490,  0.2509, -0.1353], grad_fn=<SelectBackward>) Actual tensor([ 1.4588,  0.5990, -0.2890])\n","Predicted tensor([-0.6580, -0.4243, -0.1295], grad_fn=<SelectBackward>) Actual tensor([-0.4850, -0.6992, -0.2153])\n","Predicted tensor([ 0.5468, -0.4016, -0.2396], grad_fn=<SelectBackward>) Actual tensor([ 0.0942, -0.2864, -0.2960])\n","Predicted tensor([-0.3834, -0.0745, -0.1156], grad_fn=<SelectBackward>) Actual tensor([ 0.0544, -0.4554, -0.2794])\n","Predicted tensor([-0.6745,  1.3971, -0.2257], grad_fn=<SelectBackward>) Actual tensor([ 0.2223,  0.5590, -0.0908])\n","Predicted tensor([ 0.7127, -0.3244, -0.2718], grad_fn=<SelectBackward>) Actual tensor([ 0.3809, -0.0589, -0.3271])\n","Predicted tensor([-0.6139, -0.3848, -0.1026], grad_fn=<SelectBackward>) Actual tensor([-0.3624, -0.7795, -0.3266])\n","Predicted tensor([ 0.6532, -0.0635, -0.2010], grad_fn=<SelectBackward>) Actual tensor([ 1.1133, -0.4324, -0.3342])\n","Predicted tensor([-0.0447, -0.2441, -0.1125], grad_fn=<SelectBackward>) Actual tensor([-0.4330, -0.7685, -0.3051])\n","Predicted tensor([-0.4269,  1.2182,  1.0761], grad_fn=<SelectBackward>) Actual tensor([ 0.0200, -0.2975,  0.4197])\n","Predicted tensor([-0.6617, -0.3951, -0.1403], grad_fn=<SelectBackward>) Actual tensor([-0.8481, -0.5266, -0.2567])\n","Predicted tensor([-0.5385,  0.0378, -0.1117], grad_fn=<SelectBackward>) Actual tensor([-0.6237, -0.0550, -0.3186])\n","Predicted tensor([-0.2958, -0.0920, -0.1704], grad_fn=<SelectBackward>) Actual tensor([-0.7229, -0.7882, -0.2784])\n","Predicted tensor([-1.0955,  0.6092, -0.1337], grad_fn=<SelectBackward>) Actual tensor([ 0.0008,  0.3515, -0.2088])\n","Predicted tensor([ 0.2291, -0.3567, -0.1532], grad_fn=<SelectBackward>) Actual tensor([-0.1562, -0.7416, -0.2702])\n","Predicted tensor([-0.5619, -0.4814, -0.0893], grad_fn=<SelectBackward>) Actual tensor([ 0.2855, -0.7242, -0.2130])\n","Predicted tensor([-0.0683, -0.3302, -0.1046], grad_fn=<SelectBackward>) Actual tensor([-0.5089, -0.4498, -0.2420])\n","Predicted tensor([ 0.2106, -0.4142, -0.0803], grad_fn=<SelectBackward>) Actual tensor([-0.6225, -0.6621, -0.2748])\n","Predicted tensor([0.3152, 0.9905, 0.1449], grad_fn=<SelectBackward>) Actual tensor([ 0.4532,  1.0256, -0.0837])\n","Predicted tensor([ 0.1199, -0.3583, -0.1116], grad_fn=<SelectBackward>) Actual tensor([ 1.1106, -0.7799, -0.3302])\n","Predicted tensor([ 0.0213,  1.2285, -0.0615], grad_fn=<SelectBackward>) Actual tensor([ 0.3374,  1.6279, -0.2664])\n","Predicted tensor([ 0.4186,  0.1676, -0.1487], grad_fn=<SelectBackward>) Actual tensor([ 1.2874,  1.1957, -0.2369])\n","Predicted tensor([-0.1726, -0.3145, -0.1211], grad_fn=<SelectBackward>) Actual tensor([1.7021, 1.0994, 0.1515])\n","Predicted tensor([-0.5802, -0.3263, -0.1122], grad_fn=<SelectBackward>) Actual tensor([-0.7242, -0.7943, -0.2860])\n","Predicted tensor([-0.6725, -0.5427, -0.0803], grad_fn=<SelectBackward>) Actual tensor([-0.6753, -0.7722, -0.2920])\n","Predicted tensor([ 0.6709, -0.2425, -0.2767], grad_fn=<SelectBackward>) Actual tensor([-0.5385, -0.5027, -0.2989])\n","Predicted tensor([-0.6708, -0.5015, -0.1100], grad_fn=<SelectBackward>) Actual tensor([-0.6951, -0.7539, -0.2521])\n","Predicted tensor([-0.5278, -0.1849, -0.1349], grad_fn=<SelectBackward>) Actual tensor([-1.2869,  1.3281, -0.2591])\n","Predicted tensor([-0.6775, -0.5468, -0.0697], grad_fn=<SelectBackward>) Actual tensor([ 1.3963, -0.6528, -0.3128])\n","Predicted tensor([ 0.0171,  0.0011, -0.0685], grad_fn=<SelectBackward>) Actual tensor([-0.5255, -0.6215, -0.2608])\n","Predicted tensor([ 0.7415, -0.4181, -0.2827], grad_fn=<SelectBackward>) Actual tensor([ 1.1921, -0.6784, -0.3119])\n","Predicted tensor([ 0.1515, -0.2642, -0.1168], grad_fn=<SelectBackward>) Actual tensor([ 1.3411, -0.4081, -0.3378])\n","Predicted tensor([-0.3620,  0.0276, -0.0928], grad_fn=<SelectBackward>) Actual tensor([-0.3122,  0.2424, -0.2819])\n","Predicted tensor([-0.3086, -0.4535, -0.1190], grad_fn=<SelectBackward>) Actual tensor([-0.5052, -0.7381, -0.2261])\n","Predicted tensor([-0.5849, -0.1433, -0.0950], grad_fn=<SelectBackward>) Actual tensor([-0.2820,  0.0131, -0.3660])\n","Predicted tensor([0.1998, 1.5673, 0.0387], grad_fn=<SelectBackward>) Actual tensor([ 1.2055, -0.0463, -0.3432])\n","Predicted tensor([ 0.4577, -0.2958, -0.2178], grad_fn=<SelectBackward>) Actual tensor([ 1.1092, -0.7785, -0.3303])\n","Predicted tensor([ 0.7018, -0.2961, -0.2322], grad_fn=<SelectBackward>) Actual tensor([ 1.1494, -0.5431, -0.3144])\n","Predicted tensor([-0.6674, -0.4366, -0.1035], grad_fn=<SelectBackward>) Actual tensor([-0.8205, -0.4617, -0.2950])\n","Predicted tensor([ 0.0386, -0.3225,  0.0824], grad_fn=<SelectBackward>) Actual tensor([-0.6467, -0.2972,  0.0577])\n","Predicted tensor([ 0.6954, -0.3639, -0.2569], grad_fn=<SelectBackward>) Actual tensor([ 0.2080, -0.3341, -0.2182])\n","Predicted tensor([-0.6565, -0.3901, -0.1014], grad_fn=<SelectBackward>) Actual tensor([-0.6383, -0.1743, -0.2551])\n","Predicted tensor([ 0.8122, -0.1698, -0.1904], grad_fn=<SelectBackward>) Actual tensor([ 1.5576,  1.0240, -0.2405])\n","Predicted tensor([ 0.2350,  0.2314, -0.0597], grad_fn=<SelectBackward>) Actual tensor([-0.8052,  0.3290,  0.1584])\n","Predicted tensor([-0.9486,  0.2974, -0.0719], grad_fn=<SelectBackward>) Actual tensor([-0.7843,  0.3607, -0.4156])\n","Predicted tensor([0.4236, 1.2262, 0.0712], grad_fn=<SelectBackward>) Actual tensor([ 1.2235,  1.3089, -0.2171])\n","Predicted tensor([-0.3396, -0.3955, -0.1336], grad_fn=<SelectBackward>) Actual tensor([-0.3329, -0.3737, -0.2030])\n","Predicted tensor([ 0.6828, -0.2861, -0.2460], grad_fn=<SelectBackward>) Actual tensor([ 1.4887, -0.3530, -0.2940])\n","Predicted tensor([ 0.6981, -0.2540, -0.2323], grad_fn=<SelectBackward>) Actual tensor([ 1.1554, -0.4363, -0.3274])\n","Predicted tensor([ 0.1363, -0.2894, -0.1160], grad_fn=<SelectBackward>) Actual tensor([-0.1095,  2.1098, -0.0643])\n","Predicted tensor([ 0.5921, -0.3207, -0.1632], grad_fn=<SelectBackward>) Actual tensor([ 1.7181, -0.4469, -0.3471])\n","Predicted tensor([-1.0483, -0.7380,  4.4349], grad_fn=<SelectBackward>) Actual tensor([-0.9232, -0.5109,  5.1437])\n","Predicted tensor([-0.9708, -0.0446, -0.0955], grad_fn=<SelectBackward>) Actual tensor([-0.5794,  2.4831,  0.0403])\n","Predicted tensor([ 0.1894,  0.3500, -0.0909], grad_fn=<SelectBackward>) Actual tensor([ 0.5892,  1.4484, -0.1887])\n","Predicted tensor([ 0.0201, -0.1938, -0.1700], grad_fn=<SelectBackward>) Actual tensor([ 1.3640, -0.5498, -0.3289])\n","Predicted tensor([-0.6250, -0.3681, -0.0871], grad_fn=<SelectBackward>) Actual tensor([-0.5792, -0.7242, -0.3274])\n","Predicted tensor([ 0.1371, -0.2355, -0.0976], grad_fn=<SelectBackward>) Actual tensor([-0.1242, -0.7787, -0.3125])\n","Predicted tensor([-0.5169,  1.2894,  1.4072], grad_fn=<SelectBackward>) Actual tensor([-0.7042, -0.7050, -0.3204])\n","Predicted tensor([ 0.0495, -0.2995, -0.0993], grad_fn=<SelectBackward>) Actual tensor([1.5361, 1.0386, 0.1319])\n","Predicted tensor([0.2627, 0.0869, 0.3918], grad_fn=<SelectBackward>) Actual tensor([-1.0039,  0.1817,  0.6812])\n","Predicted tensor([-0.6458, -0.2118, -0.0943], grad_fn=<SelectBackward>) Actual tensor([-0.2982, -0.1648, -0.3395])\n","Predicted tensor([-0.6305, -0.3359, -0.1324], grad_fn=<SelectBackward>) Actual tensor([-0.7607, -0.4994, -0.2991])\n","Predicted tensor([-0.6189, -0.3748, -0.1030], grad_fn=<SelectBackward>) Actual tensor([-0.7237, -0.7066, -0.3245])\n","Predicted tensor([ 0.1929,  0.8327, -0.0917], grad_fn=<SelectBackward>) Actual tensor([-0.3485,  2.3821,  1.2355])\n","Predicted tensor([-1.0676,  0.6956, -0.1501], grad_fn=<SelectBackward>) Actual tensor([ 0.7543,  2.7068, -0.0461])\n","Predicted tensor([-0.6749,  0.8157, -0.2713], grad_fn=<SelectBackward>) Actual tensor([ 0.0945,  2.6455, -0.2538])\n","Predicted tensor([-0.9572,  0.5106, -0.0943], grad_fn=<SelectBackward>) Actual tensor([-1.3346, -0.3905, -0.4615])\n","Predicted tensor([ 0.0155, -0.1749, -0.1390], grad_fn=<SelectBackward>) Actual tensor([-0.6737, -0.6745, -0.3001])\n","Predicted tensor([ 0.6976, -0.3718, -0.2565], grad_fn=<SelectBackward>) Actual tensor([ 0.1469, -0.6810, -0.2700])\n","Predicted tensor([-0.0464, -0.2236, -0.1078], grad_fn=<SelectBackward>) Actual tensor([-0.4997,  0.1185, -0.1334])\n","Predicted tensor([ 0.6828, -0.2621, -0.2356], grad_fn=<SelectBackward>) Actual tensor([ 1.1262, -0.6229, -0.3324])\n","Predicted tensor([-0.9090,  0.5772, -0.1517], grad_fn=<SelectBackward>) Actual tensor([-1.5333,  0.4136, -0.5175])\n","Predicted tensor([ 0.6743,  0.5232, -0.0468], grad_fn=<SelectBackward>) Actual tensor([ 0.9616, -0.2792, -0.3394])\n","Predicted tensor([ 0.0759, -0.3026, -0.0814], grad_fn=<SelectBackward>) Actual tensor([-0.6711, -0.7591, -0.2625])\n","Predicted tensor([-0.1129,  1.0284,  1.4985], grad_fn=<SelectBackward>) Actual tensor([0.5591, 2.6582, 0.4104])\n","Predicted tensor([ 0.5959, -0.0951, -0.0292], grad_fn=<SelectBackward>) Actual tensor([ 0.9364, -0.5029, -0.3507])\n","Predicted tensor([ 0.6888, -0.2602, -0.2457], grad_fn=<SelectBackward>) Actual tensor([ 0.6989,  0.0186, -0.2350])\n","Predicted tensor([-0.6365, -0.5284, -0.0919], grad_fn=<SelectBackward>) Actual tensor([-0.8404, -0.4444, -0.2927])\n","Predicted tensor([0.4505, 1.1644, 0.0962], grad_fn=<SelectBackward>) Actual tensor([-0.7969, -0.0517,  4.5949])\n","Predicted tensor([-0.6821,  0.5288, -0.1515], grad_fn=<SelectBackward>) Actual tensor([-0.3401,  0.8619, -0.3793])\n","Predicted tensor([ 0.0634, -0.0122, -0.1639], grad_fn=<SelectBackward>) Actual tensor([ 1.1073, -0.7547, -0.3316])\n","Predicted tensor([ 0.6102, -0.0410, -0.1855], grad_fn=<SelectBackward>) Actual tensor([-1.1336,  0.1881,  0.1412])\n","Predicted tensor([ 0.2569,  0.4033, -0.0842], grad_fn=<SelectBackward>) Actual tensor([ 2.1831,  1.0066, -0.1689])\n","Predicted tensor([-0.6329, -0.4879, -0.1079], grad_fn=<SelectBackward>) Actual tensor([ 1.1104, -0.6950, -0.3305])\n","Predicted tensor([ 0.2031, -0.2833, -0.1217], grad_fn=<SelectBackward>) Actual tensor([-0.6248, -0.6628, -0.2706])\n","Predicted tensor([ 0.7903,  0.2411, -0.0301], grad_fn=<SelectBackward>) Actual tensor([2.0771, 0.4619, 0.0156])\n","Predicted tensor([-0.5110, -0.5036, -0.1083], grad_fn=<SelectBackward>) Actual tensor([-0.6454, -0.7611, -0.2697])\n","Predicted tensor([-0.6186, -0.3488, -0.1472], grad_fn=<SelectBackward>) Actual tensor([-0.6813, -0.7411, -0.2655])\n","Predicted tensor([-0.7030, -0.0090, -0.0990], grad_fn=<SelectBackward>) Actual tensor([-0.4523, -0.7032, -0.3838])\n","Predicted tensor([ 0.1322, -0.2329, -0.1298], grad_fn=<SelectBackward>) Actual tensor([ 2.3290, -0.6106, -0.2335])\n","Predicted tensor([-0.2909, -0.2779, -0.1143], grad_fn=<SelectBackward>) Actual tensor([-0.4691, -0.7540, -0.3186])\n","Predicted tensor([-0.6856, -0.5143, -0.0835], grad_fn=<SelectBackward>) Actual tensor([-0.7299, -0.5209, -0.2624])\n","Predicted tensor([ 0.0954, -0.0552, -0.1121], grad_fn=<SelectBackward>) Actual tensor([ 1.3494,  1.6030, -0.2696])\n","Predicted tensor([-0.0832, -0.3712, -0.1024], grad_fn=<SelectBackward>) Actual tensor([-0.4467, -0.6917, -0.2485])\n","Predicted tensor([0.4417, 1.3370, 0.0865], grad_fn=<SelectBackward>) Actual tensor([-2.0400, -0.5299, -0.5125])\n","Predicted tensor([-0.0107, -0.3669, -0.1218], grad_fn=<SelectBackward>) Actual tensor([ 0.0748, -0.4206, -0.1868])\n","Predicted tensor([-0.6781, -0.3701, -0.1268], grad_fn=<SelectBackward>) Actual tensor([-0.7754, -0.6776, -0.2831])\n","Predicted tensor([-0.7740, -0.2103, -0.1262], grad_fn=<SelectBackward>) Actual tensor([ 0.0854,  0.2837, -0.0755])\n","Predicted tensor([ 0.4211,  0.2868, -0.1078], grad_fn=<SelectBackward>) Actual tensor([ 1.1272,  1.6072, -0.1072])\n","Predicted tensor([-0.2133,  0.8171,  2.4489], grad_fn=<SelectBackward>) Actual tensor([-0.4349,  1.2403,  1.4678])\n","Predicted tensor([-0.2996, -0.2676, -0.1166], grad_fn=<SelectBackward>) Actual tensor([-0.9488, -0.4483, -0.1893])\n","Predicted tensor([-0.2856, -0.2109, -0.1257], grad_fn=<SelectBackward>) Actual tensor([-0.2390, -0.4081, -0.3247])\n","Predicted tensor([-0.5885, -0.1946, -0.1019], grad_fn=<SelectBackward>) Actual tensor([-0.2384, -0.0503, -0.3379])\n","Predicted tensor([-0.3505, -0.4383, -0.0593], grad_fn=<SelectBackward>) Actual tensor([-0.8309,  0.5112, -0.0326])\n","Predicted tensor([-0.9269, -0.3821,  4.4678], grad_fn=<SelectBackward>) Actual tensor([-1.0369, -0.7856,  5.1429])\n","Predicted tensor([ 0.3195,  0.1268, -0.0909], grad_fn=<SelectBackward>) Actual tensor([ 0.0645, -0.5555, -0.1813])\n","Predicted tensor([-0.5023, -0.4438, -0.1094], grad_fn=<SelectBackward>) Actual tensor([-0.6584, -0.7837, -0.2844])\n","Predicted tensor([-0.9005,  0.3535, -0.0736], grad_fn=<SelectBackward>) Actual tensor([-0.2519,  0.9665, -0.3459])\n","Batch: 3 completed\n","Predicted tensor([-0.6665, -0.3224, -0.1414], grad_fn=<SelectBackward>) Actual tensor([-0.8605, -0.5194, -0.2812])\n","Predicted tensor([-0.4332, -0.5180, -0.0756], grad_fn=<SelectBackward>) Actual tensor([-0.6279, -0.7372, -0.3042])\n","Predicted tensor([0.6529, 0.1134, 0.1626], grad_fn=<SelectBackward>) Actual tensor([ 2.5142,  0.0840, -0.0236])\n","Predicted tensor([ 0.3089,  0.4539, -0.0845], grad_fn=<SelectBackward>) Actual tensor([-0.3204, -0.6861, -0.3185])\n","Predicted tensor([-0.6394, -0.3516, -0.1505], grad_fn=<SelectBackward>) Actual tensor([-0.7058, -0.7723, -0.2763])\n","Predicted tensor([-1.1042,  0.4785, -0.0367], grad_fn=<SelectBackward>) Actual tensor([-1.9520, -0.1815, -0.2976])\n","Predicted tensor([ 0.1158, -0.2959, -0.0938], grad_fn=<SelectBackward>) Actual tensor([-0.1947, -0.4289, -0.2517])\n","Predicted tensor([-0.4411,  0.6806,  3.1324], grad_fn=<SelectBackward>) Actual tensor([ 0.0757, -0.4300,  1.6493])\n","Predicted tensor([ 0.0563,  0.1247, -0.1476], grad_fn=<SelectBackward>) Actual tensor([-0.1878, -0.1365, -0.2972])\n","Predicted tensor([-0.6446, -0.3284, -0.1028], grad_fn=<SelectBackward>) Actual tensor([-0.2721, -0.1222, -0.3669])\n","Predicted tensor([ 0.7046, -0.2992, -0.2343], grad_fn=<SelectBackward>) Actual tensor([ 1.1808, -0.5493, -0.3253])\n","Predicted tensor([ 0.0483, -0.1755, -0.1110], grad_fn=<SelectBackward>) Actual tensor([-1.5704,  1.0447,  0.6235])\n","Predicted tensor([ 0.1761,  0.6445, -0.0974], grad_fn=<SelectBackward>) Actual tensor([ 1.3551,  0.1044, -0.3617])\n","Predicted tensor([-0.5520,  0.5797, -0.1358], grad_fn=<SelectBackward>) Actual tensor([-0.5029,  0.1490, -0.4359])\n","Predicted tensor([-0.9542, -0.4375,  4.5271], grad_fn=<SelectBackward>) Actual tensor([-0.9939,  0.2149,  1.3945])\n","Predicted tensor([-0.9102, -0.1071, -0.1170], grad_fn=<SelectBackward>) Actual tensor([-1.3295, -0.0130, -0.2295])\n","Predicted tensor([ 0.3182, -0.3172, -0.1544], grad_fn=<SelectBackward>) Actual tensor([ 1.2995, -0.6155, -0.3128])\n","Predicted tensor([ 0.0403, -0.1145, -0.0945], grad_fn=<SelectBackward>) Actual tensor([-0.2687, -0.6130, -0.3238])\n","Predicted tensor([0.1473, 0.2628, 0.1146], grad_fn=<SelectBackward>) Actual tensor([ 2.3985,  0.5945, -0.1747])\n","Predicted tensor([ 0.6752, -0.2528, -0.2349], grad_fn=<SelectBackward>) Actual tensor([-0.2905, -0.6478, -0.2874])\n","Predicted tensor([-0.1114,  0.0735, -0.1796], grad_fn=<SelectBackward>) Actual tensor([-0.0135,  3.7578, -0.1450])\n","Predicted tensor([-0.6495, -0.2291, -0.1076], grad_fn=<SelectBackward>) Actual tensor([-0.4450, -0.2911, -0.3353])\n","Predicted tensor([-0.6727, -0.4898, -0.0980], grad_fn=<SelectBackward>) Actual tensor([-0.7844, -0.3885, -0.2743])\n","Predicted tensor([ 0.4727, -0.2718, -0.2626], grad_fn=<SelectBackward>) Actual tensor([-0.5951, -0.5534, -0.2936])\n","Predicted tensor([-0.5263, -0.4875, -0.1212], grad_fn=<SelectBackward>) Actual tensor([-0.7825, -0.6288, -0.2801])\n","Predicted tensor([-0.6737, -0.3168, -0.0988], grad_fn=<SelectBackward>) Actual tensor([-0.7800, -0.6630, -0.2903])\n","Predicted tensor([ 0.5694,  2.2164, -0.4653], grad_fn=<SelectBackward>) Actual tensor([ 1.3659,  3.1472, -0.1945])\n","Predicted tensor([ 0.2566,  0.2340, -0.0142], grad_fn=<SelectBackward>) Actual tensor([-0.4320, -0.7008, -0.3050])\n","Predicted tensor([-0.4215,  0.2733, -0.1162], grad_fn=<SelectBackward>) Actual tensor([-0.0889,  0.4629, -0.3061])\n","Predicted tensor([ 0.6279, -0.0151, -0.2295], grad_fn=<SelectBackward>) Actual tensor([ 1.6005,  1.0705, -0.3040])\n","Predicted tensor([-0.6782, -0.5159, -0.0966], grad_fn=<SelectBackward>) Actual tensor([-0.7877, -0.4468, -0.2703])\n","Predicted tensor([ 0.1059, -0.0094, -0.1252], grad_fn=<SelectBackward>) Actual tensor([ 1.1275,  0.3790, -0.3576])\n","Predicted tensor([-0.4063, -0.2395, -0.0958], grad_fn=<SelectBackward>) Actual tensor([0.1088, 0.3274, 0.6669])\n","Predicted tensor([-0.1571,  0.0680, -0.0699], grad_fn=<SelectBackward>) Actual tensor([-0.5356, -0.7419, -0.2891])\n","Predicted tensor([ 0.5659,  0.0565, -0.1911], grad_fn=<SelectBackward>) Actual tensor([ 2.1269, -0.0370, -0.3170])\n","Predicted tensor([ 0.3017, -0.1056,  0.0524], grad_fn=<SelectBackward>) Actual tensor([-0.6243, -0.7785, -0.2936])\n","Predicted tensor([ 0.6843, -0.2711, -0.2474], grad_fn=<SelectBackward>) Actual tensor([-0.3782, -0.3894,  0.2352])\n","Predicted tensor([ 0.5212,  0.0556, -0.1896], grad_fn=<SelectBackward>) Actual tensor([-0.9747,  3.6120, -0.0694])\n","Predicted tensor([ 0.2238,  0.3940, -0.0931], grad_fn=<SelectBackward>) Actual tensor([ 0.7132, -0.0536, -0.2520])\n","Predicted tensor([ 0.7320, -0.4122, -0.2626], grad_fn=<SelectBackward>) Actual tensor([ 1.2187, -0.7121, -0.3100])\n","Predicted tensor([-0.8096, -0.4715, -0.0714], grad_fn=<SelectBackward>) Actual tensor([-0.7526, -0.7821, -0.2711])\n","Predicted tensor([-0.2858,  0.2679, -0.1021], grad_fn=<SelectBackward>) Actual tensor([-0.7088, -0.0164, -0.3526])\n","Predicted tensor([ 0.6057,  0.0365, -0.1508], grad_fn=<SelectBackward>) Actual tensor([ 1.2578, -0.1868, -0.3356])\n","Predicted tensor([ 0.6757, -0.2719, -0.2350], grad_fn=<SelectBackward>) Actual tensor([-0.0924, -0.6817, -0.2714])\n","Predicted tensor([-0.1168, -0.3500, -0.1109], grad_fn=<SelectBackward>) Actual tensor([-0.6949, -0.2070, -0.2503])\n","Predicted tensor([ 0.5456, -0.3102, -0.1979], grad_fn=<SelectBackward>) Actual tensor([-0.5580, -0.4232, -0.3004])\n","Predicted tensor([-0.6246,  0.1217, -0.1136], grad_fn=<SelectBackward>) Actual tensor([-0.5502, -0.0578, -0.3492])\n","Predicted tensor([ 0.6624, -0.0771, -0.2241], grad_fn=<SelectBackward>) Actual tensor([ 0.3658, -0.5868,  0.2718])\n","Predicted tensor([ 0.7134, -0.3896, -0.2354], grad_fn=<SelectBackward>) Actual tensor([ 1.0871, -0.7231, -0.3274])\n","Predicted tensor([ 0.3817, -0.2957, -0.1679], grad_fn=<SelectBackward>) Actual tensor([ 0.4276, -0.3885, -0.3168])\n","Predicted tensor([-0.6226, -0.4877, -0.1070], grad_fn=<SelectBackward>) Actual tensor([-0.7344, -0.5971, -0.2913])\n","Predicted tensor([-0.6043, -0.4570, -0.1069], grad_fn=<SelectBackward>) Actual tensor([-0.7103, -0.7631, -0.2894])\n","Predicted tensor([-0.6343, -0.5450, -0.0818], grad_fn=<SelectBackward>) Actual tensor([-0.5720, -0.7583, -0.2733])\n","Predicted tensor([0.3230, 1.9836, 0.0083], grad_fn=<SelectBackward>) Actual tensor([ 0.8139,  1.5577, -0.1116])\n","Predicted tensor([-0.1097,  0.1795, -0.1644], grad_fn=<SelectBackward>) Actual tensor([-0.1758, -0.4684, -0.3289])\n","Predicted tensor([-0.8392,  0.1005, -0.1288], grad_fn=<SelectBackward>) Actual tensor([-0.1212,  0.0735, -0.1899])\n","Predicted tensor([ 0.7074, -0.3252, -0.2535], grad_fn=<SelectBackward>) Actual tensor([ 1.1355, -0.5879, -0.3290])\n","Predicted tensor([-0.5567, -0.4173, -0.1166], grad_fn=<SelectBackward>) Actual tensor([-0.6060, -0.7478, -0.3085])\n","Predicted tensor([-0.6790, -0.3090, -0.1011], grad_fn=<SelectBackward>) Actual tensor([-0.8268, -0.6823, -0.2910])\n","Predicted tensor([ 0.6012,  0.1336, -0.1686], grad_fn=<SelectBackward>) Actual tensor([ 0.9436,  0.9973, -0.1753])\n","Predicted tensor([ 0.6688, -0.4159, -0.2060], grad_fn=<SelectBackward>) Actual tensor([ 1.0666, -0.6376, -0.3358])\n","Predicted tensor([-0.3972,  0.3700, -0.1314], grad_fn=<SelectBackward>) Actual tensor([-0.2032, -0.0518, -0.3300])\n","Predicted tensor([ 0.6714, -0.2782, -0.2300], grad_fn=<SelectBackward>) Actual tensor([ 1.1947, -0.6328, -0.3386])\n","Predicted tensor([0.5082, 0.7253, 0.0027], grad_fn=<SelectBackward>) Actual tensor([ 0.3100,  0.1319, -0.0539])\n","Predicted tensor([-0.2591, -0.3182, -0.1604], grad_fn=<SelectBackward>) Actual tensor([-0.4737, -0.3808, -0.2657])\n","Predicted tensor([-1.3244,  0.1574, -0.0466], grad_fn=<SelectBackward>) Actual tensor([-2.4458, -0.4511, -0.5506])\n","Predicted tensor([ 0.4834, -0.1112, -0.1521], grad_fn=<SelectBackward>) Actual tensor([ 1.1135, -0.7065, -0.3295])\n","Predicted tensor([ 0.6715, -0.1742, -0.2186], grad_fn=<SelectBackward>) Actual tensor([ 1.1061, -0.0165, -0.2834])\n","Predicted tensor([ 0.4293,  0.3790, -0.1293], grad_fn=<SelectBackward>) Actual tensor([ 1.5533,  2.0563, -0.3114])\n","Predicted tensor([ 0.3498,  0.3384, -0.1181], grad_fn=<SelectBackward>) Actual tensor([-1.7267,  0.7005,  0.3122])\n","Predicted tensor([ 0.6939, -0.4008, -0.1993], grad_fn=<SelectBackward>) Actual tensor([ 1.2187, -0.7509, -0.2608])\n","Predicted tensor([ 0.2839,  0.7659, -0.0607], grad_fn=<SelectBackward>) Actual tensor([ 0.7538, -0.0793, -0.0872])\n","Predicted tensor([ 0.5996,  0.1447, -0.1937], grad_fn=<SelectBackward>) Actual tensor([ 1.1357,  2.4432, -0.1404])\n","Predicted tensor([ 0.6962, -0.3583, -0.2569], grad_fn=<SelectBackward>) Actual tensor([ 0.9282,  0.2300, -0.2760])\n","Predicted tensor([ 0.6745, -0.1801, -0.2309], grad_fn=<SelectBackward>) Actual tensor([ 1.3329,  1.0361, -0.3672])\n","Predicted tensor([-0.7596, -0.4684, -0.0925], grad_fn=<SelectBackward>) Actual tensor([-0.6881, -0.5263, -0.2038])\n","Predicted tensor([-0.3418,  0.2607,  2.2209], grad_fn=<SelectBackward>) Actual tensor([ 0.4575, -0.2212,  2.0526])\n","Predicted tensor([ 0.0940, -0.3701, -0.0984], grad_fn=<SelectBackward>) Actual tensor([-0.2081,  1.7649, -0.0038])\n","Predicted tensor([ 0.7925, -0.1287, -0.1655], grad_fn=<SelectBackward>) Actual tensor([ 1.7398,  0.0235, -0.2037])\n","Predicted tensor([0.1529, 0.7571, 0.1565], grad_fn=<SelectBackward>) Actual tensor([-0.7071, -0.6887, -0.3222])\n","Predicted tensor([ 0.6954, -0.4042, -0.2703], grad_fn=<SelectBackward>) Actual tensor([ 1.1486,  1.3717, -0.2385])\n","Predicted tensor([ 0.5302, -0.3855, -0.2286], grad_fn=<SelectBackward>) Actual tensor([ 1.1616, -0.6896, -0.3293])\n","Predicted tensor([-0.1514, -0.2045, -0.0996], grad_fn=<SelectBackward>) Actual tensor([-0.5047, -0.7440, -0.3093])\n","Predicted tensor([ 0.0111, -0.0559, -0.0568], grad_fn=<SelectBackward>) Actual tensor([-0.7562, -0.6672, -0.2775])\n","Predicted tensor([-0.0230,  0.2821, -0.1058], grad_fn=<SelectBackward>) Actual tensor([-0.3205,  0.0140, -0.3439])\n","Predicted tensor([-0.6514, -0.1897, -0.1207], grad_fn=<SelectBackward>) Actual tensor([-1.0883, -0.6943,  4.9547])\n","Predicted tensor([0.8000, 0.3774, 0.0080], grad_fn=<SelectBackward>) Actual tensor([ 1.0054,  0.3995, -0.3608])\n","Predicted tensor([-0.1157,  0.3455, -0.1151], grad_fn=<SelectBackward>) Actual tensor([-0.7665, -0.6975, -0.3612])\n","Predicted tensor([ 0.0634, -0.2567, -0.1308], grad_fn=<SelectBackward>) Actual tensor([-0.3699, -0.7941, -0.2983])\n","Predicted tensor([ 0.6877, -0.3089, -0.2270], grad_fn=<SelectBackward>) Actual tensor([ 1.8033,  2.0682, -0.2319])\n","Predicted tensor([-0.2310, -0.2646, -0.1045], grad_fn=<SelectBackward>) Actual tensor([-0.7928, -0.6448, -0.2693])\n","Predicted tensor([ 0.2206, -0.1366, -0.1254], grad_fn=<SelectBackward>) Actual tensor([-0.5628,  0.6187, -0.2186])\n","Predicted tensor([ 0.6814, -0.4016, -0.2083], grad_fn=<SelectBackward>) Actual tensor([ 1.3467, -0.7196, -0.3190])\n","Predicted tensor([ 0.6346,  0.0108, -0.1788], grad_fn=<SelectBackward>) Actual tensor([0.3027, 0.3602, 0.5040])\n","Predicted tensor([ 0.0650, -0.2164, -0.1266], grad_fn=<SelectBackward>) Actual tensor([-0.2426, -0.3172, -0.2239])\n","Predicted tensor([ 0.4951, -0.3286, -0.2217], grad_fn=<SelectBackward>) Actual tensor([ 0.6481, -0.7179, -0.2859])\n","Predicted tensor([0.5994, 0.7681, 0.0578], grad_fn=<SelectBackward>) Actual tensor([ 1.4113,  2.3823, -0.1117])\n","Predicted tensor([0.4515, 0.2719, 0.6226], grad_fn=<SelectBackward>) Actual tensor([-0.6640,  0.0741,  0.6468])\n","Predicted tensor([-0.4677,  1.1280,  0.9304], grad_fn=<SelectBackward>) Actual tensor([-1.7105,  0.4262,  1.2848])\n","Predicted tensor([ 0.7015, -0.3523, -0.2748], grad_fn=<SelectBackward>) Actual tensor([ 1.1124, -0.7017, -0.3271])\n","Predicted tensor([-0.4756, -0.4253, -0.1272], grad_fn=<SelectBackward>) Actual tensor([-0.4929, -0.6996, -0.2486])\n","Predicted tensor([0.1990, 0.7901, 0.4626], grad_fn=<SelectBackward>) Actual tensor([1.9764, 3.9159, 1.5282])\n","Predicted tensor([ 0.0296,  0.1923, -0.1238], grad_fn=<SelectBackward>) Actual tensor([-0.6379, -0.3306, -0.2949])\n","Predicted tensor([0.1712, 0.0142, 0.1140], grad_fn=<SelectBackward>) Actual tensor([0.6951, 0.7282, 0.0956])\n","Predicted tensor([-0.2931, -0.4093, -0.1112], grad_fn=<SelectBackward>) Actual tensor([-0.5900, -0.1157, -0.2127])\n","Predicted tensor([-0.2962, -0.0143, -0.1685], grad_fn=<SelectBackward>) Actual tensor([-0.6197,  0.1418, -0.0726])\n","Predicted tensor([0.0386, 1.2556, 0.4547], grad_fn=<SelectBackward>) Actual tensor([ 0.8651,  0.5554, -0.3426])\n","Predicted tensor([ 0.5617, -0.4007, -0.1617], grad_fn=<SelectBackward>) Actual tensor([-0.9098,  1.6598,  0.0641])\n","Predicted tensor([ 0.6958, -0.3842, -0.2587], grad_fn=<SelectBackward>) Actual tensor([-0.2962, -0.3401, -0.1931])\n","Predicted tensor([-0.0628, -0.2021, -0.1097], grad_fn=<SelectBackward>) Actual tensor([ 2.2456,  0.4185, -0.2817])\n","Predicted tensor([ 0.6949, -0.3094, -0.2469], grad_fn=<SelectBackward>) Actual tensor([ 1.1805, -0.6217, -0.3144])\n","Predicted tensor([ 0.4389,  0.6610, -0.0270], grad_fn=<SelectBackward>) Actual tensor([ 1.7885,  2.0194, -0.2621])\n","Predicted tensor([ 0.3754, -0.0288, -0.1237], grad_fn=<SelectBackward>) Actual tensor([ 0.2024,  0.4616, -0.2092])\n","Predicted tensor([0.5708, 0.9572, 0.0223], grad_fn=<SelectBackward>) Actual tensor([-2.0637, -0.7683,  0.2556])\n","Predicted tensor([-0.3457, -0.2751, -0.1384], grad_fn=<SelectBackward>) Actual tensor([-0.5190, -0.7726, -0.3191])\n","Predicted tensor([-0.6452, -0.3345, -0.0901], grad_fn=<SelectBackward>) Actual tensor([-0.5450, -0.7311, -0.3299])\n","Predicted tensor([0.6058, 0.5297, 0.0178], grad_fn=<SelectBackward>) Actual tensor([ 1.5278,  1.6144, -0.2164])\n","Predicted tensor([-0.8535, -0.3470, -0.0400], grad_fn=<SelectBackward>) Actual tensor([-1.0748,  1.9300, -0.0555])\n","Predicted tensor([-0.6436,  0.7491, -0.2243], grad_fn=<SelectBackward>) Actual tensor([-0.8245,  1.6466, -0.3841])\n","Predicted tensor([ 0.7048, -0.3329, -0.2566], grad_fn=<SelectBackward>) Actual tensor([ 1.1222, -0.7081, -0.3317])\n","Predicted tensor([ 0.6805, -0.2895, -0.2384], grad_fn=<SelectBackward>) Actual tensor([ 1.1278, -0.6213, -0.3331])\n","Predicted tensor([ 0.6990, -0.3232, -0.2362], grad_fn=<SelectBackward>) Actual tensor([ 1.1367, -0.5911, -0.3140])\n","Predicted tensor([ 0.2521,  0.8422, -0.1415], grad_fn=<SelectBackward>) Actual tensor([-0.2314,  0.1616,  0.6421])\n","Predicted tensor([ 0.5181, -0.3404, -0.1850], grad_fn=<SelectBackward>) Actual tensor([-1.4936, -0.1454,  0.0786])\n","Predicted tensor([-0.2252, -0.4066, -0.1273], grad_fn=<SelectBackward>) Actual tensor([ 0.1238, -0.5294, -0.2053])\n","Predicted tensor([-0.7116, -0.3578, -0.1003], grad_fn=<SelectBackward>) Actual tensor([-0.8709, -0.7518, -0.2585])\n","Predicted tensor([-0.0494,  0.2545, -0.1497], grad_fn=<SelectBackward>) Actual tensor([-0.0664,  0.7462, -0.2249])\n","Predicted tensor([ 0.7204, -0.3835, -0.2784], grad_fn=<SelectBackward>) Actual tensor([ 0.5876, -0.7152, -0.2791])\n","Predicted tensor([-1.0852, -0.7708,  4.5624], grad_fn=<SelectBackward>) Actual tensor([-1.2246, -0.5120,  5.0865])\n","Predicted tensor([ 0.6481, -0.1032, -0.2049], grad_fn=<SelectBackward>) Actual tensor([-0.4953, -0.7241, -0.3174])\n","Predicted tensor([-0.4819,  0.3276, -0.1266], grad_fn=<SelectBackward>) Actual tensor([-0.8134, -0.3087, -0.3394])\n","Predicted tensor([ 0.7121, -0.2989, -0.2318], grad_fn=<SelectBackward>) Actual tensor([ 1.1225, -0.6003, -0.3304])\n","Predicted tensor([ 0.0657, -0.1088, -0.1138], grad_fn=<SelectBackward>) Actual tensor([-0.6011, -0.6240, -0.2886])\n","Predicted tensor([ 0.7067, -0.3496, -0.2392], grad_fn=<SelectBackward>) Actual tensor([ 0.8384,  0.9572, -0.2281])\n","Predicted tensor([ 0.1802, -0.2614, -0.1206], grad_fn=<SelectBackward>) Actual tensor([ 1.3036, -0.4725, -0.3299])\n","Predicted tensor([ 0.6930, -0.1934, -0.2300], grad_fn=<SelectBackward>) Actual tensor([ 1.0821, -0.5989, -0.3266])\n","Predicted tensor([-0.1441, -0.2680, -0.1267], grad_fn=<SelectBackward>) Actual tensor([-0.4867, -0.7397, -0.3120])\n","Predicted tensor([-0.5690, -0.5164, -0.0595], grad_fn=<SelectBackward>) Actual tensor([-0.5600, -0.7263, -0.2787])\n","Predicted tensor([0.1449, 0.3750, 0.3199], grad_fn=<SelectBackward>) Actual tensor([ 0.0857,  1.5236, -0.0460])\n","Predicted tensor([ 0.1437, -0.2188, -0.1188], grad_fn=<SelectBackward>) Actual tensor([-0.2854, -0.5711, -0.3248])\n","Predicted tensor([-0.1720, -0.1959, -0.0918], grad_fn=<SelectBackward>) Actual tensor([1.5109, 3.6470, 0.2221])\n","Predicted tensor([0.4348, 0.3977, 0.0653], grad_fn=<SelectBackward>) Actual tensor([-0.3181, -0.1732, -0.2070])\n","Predicted tensor([-0.1969, -0.4646, -0.0618], grad_fn=<SelectBackward>) Actual tensor([-0.5878,  0.3030, -0.1825])\n","Predicted tensor([ 0.4419,  0.2616, -0.0528], grad_fn=<SelectBackward>) Actual tensor([-0.0788,  0.2481, -0.2760])\n","Predicted tensor([ 0.1043, -0.2177, -0.1262], grad_fn=<SelectBackward>) Actual tensor([ 1.3673, -0.3132, -0.3459])\n","Predicted tensor([ 0.6195,  0.2957, -0.1124], grad_fn=<SelectBackward>) Actual tensor([ 1.2318,  0.2085, -0.2882])\n","Predicted tensor([-0.6984, -0.3581, -0.1252], grad_fn=<SelectBackward>) Actual tensor([-0.8471, -0.7143, -0.2718])\n","Predicted tensor([ 0.3045,  0.4660, -0.0921], grad_fn=<SelectBackward>) Actual tensor([-1.0069, -0.3330,  0.4323])\n","Predicted tensor([ 0.7312, -0.4009, -0.2502], grad_fn=<SelectBackward>) Actual tensor([ 1.1605, -0.4784, -0.3064])\n","Predicted tensor([-0.2538,  1.1090,  0.7550], grad_fn=<SelectBackward>) Actual tensor([-0.4968, -0.6626, -0.3279])\n","Predicted tensor([-0.5077, -0.4132, -0.0391], grad_fn=<SelectBackward>) Actual tensor([-0.5938, -0.4118, -0.2542])\n","Predicted tensor([ 0.0893, -0.0166,  0.4226], grad_fn=<SelectBackward>) Actual tensor([-1.8127,  0.1339,  1.2465])\n","Predicted tensor([-0.1089, -0.3393, -0.1042], grad_fn=<SelectBackward>) Actual tensor([-0.7134, -0.6948, -0.2635])\n","Predicted tensor([-0.3481, -0.0145, -0.0968], grad_fn=<SelectBackward>) Actual tensor([-0.7491, -0.6744, -0.3335])\n","Predicted tensor([ 0.5763,  0.1351, -0.1778], grad_fn=<SelectBackward>) Actual tensor([ 0.0612, -0.4962,  0.4578])\n","Predicted tensor([ 0.6919, -0.3363, -0.2566], grad_fn=<SelectBackward>) Actual tensor([ 0.5048, -0.3582, -0.2472])\n","Predicted tensor([ 0.4351,  0.0946, -0.2293], grad_fn=<SelectBackward>) Actual tensor([ 1.9052,  1.9625, -0.1374])\n","Predicted tensor([ 0.1651, -0.2494, -0.1374], grad_fn=<SelectBackward>) Actual tensor([-0.7630, -0.6992, -0.2943])\n","Predicted tensor([ 0.6009, -0.0131, -0.2063], grad_fn=<SelectBackward>) Actual tensor([ 1.6327,  0.3947, -0.3610])\n","Predicted tensor([0.7373, 0.2015, 0.4348], grad_fn=<SelectBackward>) Actual tensor([ 1.2210,  0.7527, -0.3721])\n","Predicted tensor([-0.6577, -0.5044, -0.1245], grad_fn=<SelectBackward>) Actual tensor([-0.6810, -0.7874, -0.2442])\n","Predicted tensor([-1.0975,  0.2677, -0.0502], grad_fn=<SelectBackward>) Actual tensor([-2.3617, -0.5397, -0.5801])\n","Predicted tensor([-0.2553, -0.2883, -0.1352], grad_fn=<SelectBackward>) Actual tensor([-0.5029, -0.7107, -0.3327])\n","Predicted tensor([-0.6792, -0.3118, -0.0994], grad_fn=<SelectBackward>) Actual tensor([-0.6989, -0.6011, -0.2164])\n","Predicted tensor([ 0.6513, -0.3323, -0.2888], grad_fn=<SelectBackward>) Actual tensor([ 0.8021, -0.7701, -0.2985])\n","Predicted tensor([-0.3392,  1.0364,  0.8232], grad_fn=<SelectBackward>) Actual tensor([-0.6161, -0.6410, -0.3232])\n","Predicted tensor([-0.6774, -0.4164, -0.1299], grad_fn=<SelectBackward>) Actual tensor([-0.8609, -0.3587, -0.2473])\n","Predicted tensor([-0.6774, -0.4877, -0.1078], grad_fn=<SelectBackward>) Actual tensor([-0.7373, -0.7781, -0.2122])\n","Predicted tensor([-0.5971, -0.2188, -0.1045], grad_fn=<SelectBackward>) Actual tensor([-0.2093, -0.7100, -0.3338])\n","Predicted tensor([ 0.3621, -0.0392, -0.2980], grad_fn=<SelectBackward>) Actual tensor([ 0.9652,  0.5379, -0.3620])\n","Predicted tensor([ 0.6744, -0.0311, -0.2073], grad_fn=<SelectBackward>) Actual tensor([ 1.1713,  0.5475, -0.2313])\n","Predicted tensor([-0.5826, -0.3367, -0.1215], grad_fn=<SelectBackward>) Actual tensor([-1.1105, -0.3764,  2.0925])\n","Predicted tensor([-0.7002, -0.3184, -0.1096], grad_fn=<SelectBackward>) Actual tensor([-0.8443, -0.4528, -0.2856])\n","Predicted tensor([ 0.7017, -0.3755, -0.2668], grad_fn=<SelectBackward>) Actual tensor([ 0.1329, -0.7835, -0.3303])\n","Predicted tensor([ 0.6333, -0.1361,  0.0812], grad_fn=<SelectBackward>) Actual tensor([ 2.1868, -0.4851, -0.0144])\n","Predicted tensor([-0.5688, -0.4838, -0.1283], grad_fn=<SelectBackward>) Actual tensor([-0.4286, -0.4845, -0.1865])\n","Predicted tensor([-0.9552,  0.2275, -0.0889], grad_fn=<SelectBackward>) Actual tensor([-0.4514, -0.3906, -0.1313])\n","Predicted tensor([-0.2453,  0.0308, -0.1250], grad_fn=<SelectBackward>) Actual tensor([-0.7116, -0.7333, -0.3393])\n","Predicted tensor([-0.0375, -0.0300, -0.1276], grad_fn=<SelectBackward>) Actual tensor([-0.0709, -0.2415, -0.3172])\n","Predicted tensor([ 0.6934, -0.3353, -0.2512], grad_fn=<SelectBackward>) Actual tensor([ 0.5926, -0.4633, -0.2449])\n","Predicted tensor([ 0.5129, -0.2431, -0.2297], grad_fn=<SelectBackward>) Actual tensor([-1.4804,  0.7583,  0.0214])\n","Predicted tensor([-0.6434, -0.4407, -0.1355], grad_fn=<SelectBackward>) Actual tensor([-0.7677, -0.4408, -0.2747])\n","Predicted tensor([-0.7077, -0.4066, -0.1082], grad_fn=<SelectBackward>) Actual tensor([-0.8675, -0.5274, -0.2714])\n","Predicted tensor([-0.2131, -0.2049, -0.0970], grad_fn=<SelectBackward>) Actual tensor([-0.8123,  2.4480,  1.3857])\n","Predicted tensor([0.7656, 0.0326, 0.1877], grad_fn=<SelectBackward>) Actual tensor([ 1.0125, -0.3082,  0.6205])\n","Predicted tensor([-0.6236,  0.1938, -0.1042], grad_fn=<SelectBackward>) Actual tensor([-0.5616,  0.3255, -0.3354])\n","Predicted tensor([ 0.6950, -0.2090, -0.2364], grad_fn=<SelectBackward>) Actual tensor([ 1.1974, -0.4949, -0.3299])\n","Predicted tensor([-0.6083, -0.4669, -0.1203], grad_fn=<SelectBackward>) Actual tensor([-0.5020, -0.7435, -0.3015])\n","Predicted tensor([-0.7359, -0.4592, -0.0803], grad_fn=<SelectBackward>) Actual tensor([ 1.5089,  1.6269, -0.3629])\n","Predicted tensor([-0.3112,  1.1187,  1.6788], grad_fn=<SelectBackward>) Actual tensor([0.1482, 3.0338, 2.8652])\n","Predicted tensor([-0.5823, -0.3855, -0.1468], grad_fn=<SelectBackward>) Actual tensor([ 1.0859, -0.7462, -0.3361])\n","Predicted tensor([-0.6435, -0.4774, -0.1129], grad_fn=<SelectBackward>) Actual tensor([-0.5052, -0.5001, -0.1830])\n","Predicted tensor([-0.5488, -0.5057, -0.0971], grad_fn=<SelectBackward>) Actual tensor([-0.7789, -0.6462, -0.2824])\n","Predicted tensor([-0.5323, -0.5532, -0.0894], grad_fn=<SelectBackward>) Actual tensor([-0.6858, -0.6999, -0.2239])\n","Predicted tensor([-0.7138, -0.4928, -0.0827], grad_fn=<SelectBackward>) Actual tensor([-0.6780, -0.7643, -0.2561])\n","Predicted tensor([ 0.2161, -0.0008, -0.1134], grad_fn=<SelectBackward>) Actual tensor([ 0.1370, -0.0639, -0.2978])\n","Predicted tensor([-0.6663, -0.3236, -0.1388], grad_fn=<SelectBackward>) Actual tensor([-0.8404, -0.5814, -0.2749])\n","Predicted tensor([-0.6752, -0.3797, -0.1146], grad_fn=<SelectBackward>) Actual tensor([-0.7901, -0.4231, -0.2708])\n","Predicted tensor([0.2196, 1.2136, 0.0471], grad_fn=<SelectBackward>) Actual tensor([ 0.6637,  3.2475, -0.0923])\n","Predicted tensor([ 0.6894, -0.1282, -0.2173], grad_fn=<SelectBackward>) Actual tensor([ 1.1548, -0.3144, -0.3187])\n","Batch: 4 completed\n","Predicted tensor([ 0.0237, -0.1626, -0.1421], grad_fn=<SelectBackward>) Actual tensor([ 1.0126, -0.1195, -0.3480])\n","Predicted tensor([-0.6901, -0.4047, -0.1283], grad_fn=<SelectBackward>) Actual tensor([-0.6377, -0.5804, -0.2007])\n","Predicted tensor([-0.5009, -0.2382, -0.0915], grad_fn=<SelectBackward>) Actual tensor([-0.6680, -0.6395, -0.3263])\n","Predicted tensor([ 0.2412,  0.1038, -0.0820], grad_fn=<SelectBackward>) Actual tensor([ 1.6839,  0.4321, -0.3718])\n","Predicted tensor([-0.4103,  1.2162,  1.1561], grad_fn=<SelectBackward>) Actual tensor([-0.7400,  2.7453,  2.7257])\n","Predicted tensor([-0.4565, -0.3723, -0.0957], grad_fn=<SelectBackward>) Actual tensor([-0.5645, -0.7485, -0.3104])\n","Predicted tensor([ 0.7579, -0.4120, -0.2788], grad_fn=<SelectBackward>) Actual tensor([ 0.3188, -0.6493, -0.3034])\n","Predicted tensor([-0.6717, -0.5665, -0.0516], grad_fn=<SelectBackward>) Actual tensor([-0.7977, -0.3034, -0.2489])\n","Predicted tensor([0.0632, 0.4193, 0.2619], grad_fn=<SelectBackward>) Actual tensor([2.2056, 2.4235, 0.2433])\n","Predicted tensor([-0.1240, -0.4437, -0.0795], grad_fn=<SelectBackward>) Actual tensor([-0.7521,  0.2158, -0.1868])\n","Predicted tensor([ 0.6985, -0.2536, -0.2244], grad_fn=<SelectBackward>) Actual tensor([ 1.1503, -0.4704, -0.3249])\n","Predicted tensor([-0.5638, -0.4667, -0.1150], grad_fn=<SelectBackward>) Actual tensor([-0.4406, -0.5299, -0.2708])\n","Predicted tensor([-0.2850, -0.4830, -0.0578], grad_fn=<SelectBackward>) Actual tensor([ 1.3366,  0.9671, -0.3538])\n","Predicted tensor([0.0117, 1.2640, 0.5969], grad_fn=<SelectBackward>) Actual tensor([-0.3793,  2.7705,  1.2808])\n","Predicted tensor([-0.3401, -0.3915, -0.1002], grad_fn=<SelectBackward>) Actual tensor([ 1.1571,  0.0625, -0.1357])\n","Predicted tensor([ 0.2658,  0.0872, -0.0757], grad_fn=<SelectBackward>) Actual tensor([-0.1153, -0.5267, -0.2931])\n","Predicted tensor([ 0.1696, -0.1074, -0.1275], grad_fn=<SelectBackward>) Actual tensor([-0.2342, -0.2869, -0.3039])\n","Predicted tensor([ 0.3235, -0.3749, -0.1436], grad_fn=<SelectBackward>) Actual tensor([ 0.0403, -0.1202, -0.2640])\n","Predicted tensor([ 0.6956, -0.3067, -0.2496], grad_fn=<SelectBackward>) Actual tensor([ 1.2020, -0.4060, -0.3336])\n","Predicted tensor([-0.2805, -0.3441, -0.1087], grad_fn=<SelectBackward>) Actual tensor([ 2.1000,  0.4753, -0.3472])\n","Predicted tensor([ 0.7566, -0.3725, -0.2940], grad_fn=<SelectBackward>) Actual tensor([ 0.1076,  0.7884, -0.1812])\n","Predicted tensor([-0.6196, -0.5600, -0.0727], grad_fn=<SelectBackward>) Actual tensor([-0.8366, -0.7481, -0.2673])\n","Predicted tensor([ 0.1793, -0.1129, -0.1187], grad_fn=<SelectBackward>) Actual tensor([ 1.4079, -0.5583, -0.2998])\n","Predicted tensor([-0.7250, -0.4152, -0.0979], grad_fn=<SelectBackward>) Actual tensor([-0.9093, -0.6754, -0.2766])\n","Predicted tensor([0.0716, 0.0664, 0.0059], grad_fn=<SelectBackward>) Actual tensor([-0.8092, -0.4132, -0.2573])\n","Predicted tensor([-0.2827, -0.3831, -0.1047], grad_fn=<SelectBackward>) Actual tensor([ 1.1179, -0.5050, -0.3392])\n","Predicted tensor([ 0.6983, -0.3765, -0.2291], grad_fn=<SelectBackward>) Actual tensor([ 1.1092, -0.7829, -0.3297])\n","Predicted tensor([ 0.1931,  0.5426, -0.0561], grad_fn=<SelectBackward>) Actual tensor([-0.4307, -0.7175, -0.3284])\n","Predicted tensor([-0.4036, -0.4055, -0.1235], grad_fn=<SelectBackward>) Actual tensor([-0.4182, -0.4979, -0.2655])\n","Predicted tensor([-0.2806, -0.4339, -0.0916], grad_fn=<SelectBackward>) Actual tensor([-0.3029,  0.0030, -0.1938])\n","Predicted tensor([ 0.6982, -0.3336, -0.2343], grad_fn=<SelectBackward>) Actual tensor([ 0.4322, -0.4735, -0.2364])\n","Predicted tensor([1.0502, 0.5426, 0.6379], grad_fn=<SelectBackward>) Actual tensor([0.6543, 5.2855, 3.1954])\n","Predicted tensor([-0.0835, -0.0968, -0.1489], grad_fn=<SelectBackward>) Actual tensor([-0.4417, -0.0201, -0.2685])\n","Predicted tensor([-0.6913, -0.5073, -0.0898], grad_fn=<SelectBackward>) Actual tensor([-0.6673, -0.2196, -0.1709])\n","Predicted tensor([ 0.2153, -0.4013, -0.1104], grad_fn=<SelectBackward>) Actual tensor([-0.6638, -0.7835, -0.2774])\n","Predicted tensor([ 0.3336, -0.0339, -0.0955], grad_fn=<SelectBackward>) Actual tensor([ 0.2822,  0.3973, -0.2792])\n","Predicted tensor([-0.6664, -0.4689, -0.1148], grad_fn=<SelectBackward>) Actual tensor([-0.7836, -0.7457, -0.2872])\n","Predicted tensor([-0.6995, -0.3062, -0.0993], grad_fn=<SelectBackward>) Actual tensor([-0.8182, -0.4627, -0.2851])\n","Predicted tensor([ 0.5329,  0.1658, -0.1550], grad_fn=<SelectBackward>) Actual tensor([1.9337, 3.0424, 0.7880])\n","Predicted tensor([ 0.6198, -0.0330, -0.1840], grad_fn=<SelectBackward>) Actual tensor([-1.1776,  0.1258,  0.1470])\n","Predicted tensor([ 0.7126,  0.3020, -0.0357], grad_fn=<SelectBackward>) Actual tensor([ 1.0935, -0.1699, -0.3498])\n","Predicted tensor([ 0.4877, -0.1682, -0.2373], grad_fn=<SelectBackward>) Actual tensor([-0.6705, -0.5394, -0.2840])\n","Predicted tensor([ 0.6938, -0.1961, -0.2488], grad_fn=<SelectBackward>) Actual tensor([-0.4212, -0.7545, -0.3181])\n","Predicted tensor([-1.2102,  0.1350, -0.0221], grad_fn=<SelectBackward>) Actual tensor([1.6983, 0.3427, 0.0150])\n","Predicted tensor([ 0.7588,  0.2102, -0.1161], grad_fn=<SelectBackward>) Actual tensor([ 0.0851,  0.5286, -0.2851])\n","Predicted tensor([ 0.7006, -0.3542, -0.2587], grad_fn=<SelectBackward>) Actual tensor([ 1.1245, -0.6932, -0.3239])\n","Predicted tensor([-0.6854, -0.5428, -0.0568], grad_fn=<SelectBackward>) Actual tensor([-0.7473, -0.4672, -0.2930])\n","Predicted tensor([0.2688, 0.0745, 0.4348], grad_fn=<SelectBackward>) Actual tensor([-1.9023, -0.5346,  0.2461])\n","Predicted tensor([-0.7255, -0.5538, -0.0304], grad_fn=<SelectBackward>) Actual tensor([-0.7330, -0.7574, -0.2816])\n","Predicted tensor([-0.9138, -0.3748,  4.4364], grad_fn=<SelectBackward>) Actual tensor([-0.9958, -0.7510,  5.1446])\n","Predicted tensor([ 0.5078,  0.3686, -0.0665], grad_fn=<SelectBackward>) Actual tensor([-0.4265,  1.9590, -0.2931])\n","Predicted tensor([ 0.2797,  0.0357, -0.1338], grad_fn=<SelectBackward>) Actual tensor([ 1.1103, -0.7549, -0.3305])\n","Predicted tensor([-0.6730, -0.6246,  0.0026], grad_fn=<SelectBackward>) Actual tensor([-0.6496, -0.3310, -0.2511])\n","Predicted tensor([ 0.6647, -0.2505, -0.2666], grad_fn=<SelectBackward>) Actual tensor([ 1.1836,  0.0360, -0.3096])\n","Predicted tensor([ 0.4658, -0.2640, -0.1718], grad_fn=<SelectBackward>) Actual tensor([ 0.5328, -0.3091, -0.2756])\n","Predicted tensor([ 0.6466, -0.1404, -0.2079], grad_fn=<SelectBackward>) Actual tensor([ 1.3262,  0.1692, -0.2674])\n","Predicted tensor([-0.7339, -0.0734, -0.1236], grad_fn=<SelectBackward>) Actual tensor([-0.6173, -0.1466, -0.3477])\n","Predicted tensor([-0.7222, -0.4722, -0.0609], grad_fn=<SelectBackward>) Actual tensor([-1.6044,  0.8043,  0.0382])\n","Predicted tensor([ 0.1183, -0.1963, -0.1068], grad_fn=<SelectBackward>) Actual tensor([-0.5734, -0.5021, -0.2968])\n","Predicted tensor([-0.2621, -0.3810, -0.1007], grad_fn=<SelectBackward>) Actual tensor([0.1896, 0.5655, 0.0265])\n","Predicted tensor([ 0.0583,  0.0733, -0.1064], grad_fn=<SelectBackward>) Actual tensor([2.0784, 3.7395, 0.9763])\n","Predicted tensor([-0.4062, -0.0354, -0.0450], grad_fn=<SelectBackward>) Actual tensor([-0.6866, -0.5361, -0.2799])\n","Predicted tensor([-0.4598,  0.0773, -0.1156], grad_fn=<SelectBackward>) Actual tensor([-0.7094, -0.1472, -0.3214])\n","Predicted tensor([-0.4389, -0.3837, -0.1262], grad_fn=<SelectBackward>) Actual tensor([-0.6140, -0.7358, -0.3013])\n","Predicted tensor([-0.5916, -0.4377, -0.1125], grad_fn=<SelectBackward>) Actual tensor([-0.8125, -0.4805, -0.2630])\n","Predicted tensor([-0.7511, -0.5678, -0.0340], grad_fn=<SelectBackward>) Actual tensor([-0.3822, -0.6908, -0.2927])\n","Predicted tensor([-0.4221,  0.7477,  3.0920], grad_fn=<SelectBackward>) Actual tensor([-1.0513, -0.0858,  3.5187])\n","Predicted tensor([ 0.5843, -0.4122, -0.2937], grad_fn=<SelectBackward>) Actual tensor([-0.1477, -0.7972, -0.2937])\n","Predicted tensor([0.3085, 1.0558, 0.0415], grad_fn=<SelectBackward>) Actual tensor([-2.3936, -0.3894, -0.4461])\n","Predicted tensor([-0.0632, -0.1680, -0.1527], grad_fn=<SelectBackward>) Actual tensor([-0.1695,  3.2592,  1.4775])\n","Predicted tensor([-0.7054, -0.4964, -0.0900], grad_fn=<SelectBackward>) Actual tensor([-0.8726, -0.6617, -0.2735])\n","Predicted tensor([ 0.0151,  0.0648, -0.1116], grad_fn=<SelectBackward>) Actual tensor([-0.2299, -0.2934, -0.3323])\n","Predicted tensor([-0.0963, -0.4183, -0.1012], grad_fn=<SelectBackward>) Actual tensor([-0.5771, -0.7242, -0.2580])\n","Predicted tensor([ 0.7389,  0.4062, -0.0113], grad_fn=<SelectBackward>) Actual tensor([1.7358, 2.7478, 0.2868])\n","Predicted tensor([-0.0819,  0.4592, -0.1434], grad_fn=<SelectBackward>) Actual tensor([-0.4986, -0.4542, -0.3429])\n","Predicted tensor([-0.6902, -0.4517, -0.1118], grad_fn=<SelectBackward>) Actual tensor([-0.8045, -0.5300, -0.2657])\n","Predicted tensor([ 0.6972, -0.3502, -0.2526], grad_fn=<SelectBackward>) Actual tensor([ 1.2013, -0.6266, -0.3158])\n","Predicted tensor([ 0.7006, -0.3275, -0.2407], grad_fn=<SelectBackward>) Actual tensor([ 1.1088, -0.7470, -0.3283])\n","Predicted tensor([-0.3295, -0.3802, -0.1152], grad_fn=<SelectBackward>) Actual tensor([-0.6340, -0.6559,  0.2584])\n","Predicted tensor([-0.4065, -0.3189, -0.1193], grad_fn=<SelectBackward>) Actual tensor([-0.5925, -0.0553, -0.3151])\n","Predicted tensor([-0.6635, -0.5404, -0.0811], grad_fn=<SelectBackward>) Actual tensor([-0.8312, -0.5026, -0.2704])\n","Predicted tensor([ 0.6991, -0.3219, -0.2507], grad_fn=<SelectBackward>) Actual tensor([ 1.1609, -0.6249, -0.3087])\n","Predicted tensor([-0.0610,  0.5603, -0.1230], grad_fn=<SelectBackward>) Actual tensor([ 0.2378,  0.9507, -0.3305])\n","Predicted tensor([ 0.1146, -0.0641, -0.1507], grad_fn=<SelectBackward>) Actual tensor([ 1.0979, -0.2108, -0.3488])\n","Predicted tensor([ 0.6091,  0.3386, -0.0701], grad_fn=<SelectBackward>) Actual tensor([ 1.5707,  0.6078, -0.0917])\n","Predicted tensor([ 0.6772, -0.2455, -0.2541], grad_fn=<SelectBackward>) Actual tensor([ 1.4410, -0.0027, -0.3529])\n","Predicted tensor([-0.0063, -0.3088, -0.1254], grad_fn=<SelectBackward>) Actual tensor([ 1.3589, -0.3257, -0.3540])\n","Predicted tensor([-0.5135, -0.4196, -0.0633], grad_fn=<SelectBackward>) Actual tensor([-0.6166, -0.7575, -0.2977])\n","Predicted tensor([0.1364, 0.3522, 0.2081], grad_fn=<SelectBackward>) Actual tensor([-1.5729, -0.7795,  0.2465])\n","Predicted tensor([-0.0767, -0.1867, -0.1513], grad_fn=<SelectBackward>) Actual tensor([ 1.1125, -0.7563, -0.3301])\n","Predicted tensor([-0.5749, -0.2945, -0.1192], grad_fn=<SelectBackward>) Actual tensor([-1.9295, -0.1134,  0.7673])\n","Predicted tensor([-0.9161,  0.4996, -0.1352], grad_fn=<SelectBackward>) Actual tensor([ 0.0895,  1.1730, -0.3391])\n","Predicted tensor([-1.3259,  0.2082, -0.0173], grad_fn=<SelectBackward>) Actual tensor([-2.3125, -0.4109, -0.4640])\n","Predicted tensor([-0.0411, -0.3428, -0.1173], grad_fn=<SelectBackward>) Actual tensor([-0.0155, -0.3789, -0.1939])\n","Predicted tensor([ 0.2073, -0.1971, -0.1158], grad_fn=<SelectBackward>) Actual tensor([-0.6652, -0.5217, -0.3052])\n","Predicted tensor([ 0.3027,  0.1533, -0.0843], grad_fn=<SelectBackward>) Actual tensor([ 0.6533,  0.7165, -0.2617])\n","Predicted tensor([ 0.1468, -0.2064, -0.1297], grad_fn=<SelectBackward>) Actual tensor([ 2.0381, -0.5846, -0.3534])\n","Predicted tensor([-0.6542, -0.3958, -0.0933], grad_fn=<SelectBackward>) Actual tensor([-0.5993, -0.7739, -0.3258])\n","Predicted tensor([ 0.6492, -0.3395, -0.1891], grad_fn=<SelectBackward>) Actual tensor([-0.7165, -0.1161, -0.0970])\n","Predicted tensor([-1.0307, -0.6941,  4.4307], grad_fn=<SelectBackward>) Actual tensor([-0.8810, -0.5008,  5.1483])\n","Predicted tensor([-0.6543, -0.3955, -0.1405], grad_fn=<SelectBackward>) Actual tensor([-0.7933, -0.2516, -0.2292])\n","Predicted tensor([ 0.0350, -0.1845, -0.1200], grad_fn=<SelectBackward>) Actual tensor([-0.6273, -0.5939, -0.2898])\n","Predicted tensor([-0.6794, -0.3749, -0.1244], grad_fn=<SelectBackward>) Actual tensor([-0.8510, -0.4684, -0.2964])\n","Predicted tensor([-0.4991, -0.4522, -0.0915], grad_fn=<SelectBackward>) Actual tensor([-0.8065, -0.6521, -0.2709])\n","Predicted tensor([ 0.7024, -0.3786, -0.2731], grad_fn=<SelectBackward>) Actual tensor([ 1.1153, -0.7064, -0.3273])\n","Predicted tensor([0.3061, 1.2734, 0.0451], grad_fn=<SelectBackward>) Actual tensor([ 0.9363,  1.2355, -0.1819])\n","Predicted tensor([-0.5125, -0.3707, -0.1429], grad_fn=<SelectBackward>) Actual tensor([-0.8079, -0.4981, -0.2489])\n","Predicted tensor([-0.7027, -0.5183, -0.0883], grad_fn=<SelectBackward>) Actual tensor([-0.8797, -0.5759, -0.2681])\n","Predicted tensor([-0.1551, -0.1966, -0.1251], grad_fn=<SelectBackward>) Actual tensor([-0.2226, -0.4356, -0.3254])\n","Predicted tensor([-1.1683,  0.7590, -0.0970], grad_fn=<SelectBackward>) Actual tensor([-1.8628, -0.1746, -0.5239])\n","Predicted tensor([-0.7436, -0.2435, -0.1226], grad_fn=<SelectBackward>) Actual tensor([-0.0048,  1.2828, -0.2650])\n","Predicted tensor([0.3985, 1.4919, 0.1353], grad_fn=<SelectBackward>) Actual tensor([-1.9773,  0.4412,  0.2327])\n","Predicted tensor([-0.6589, -0.3187, -0.1587], grad_fn=<SelectBackward>) Actual tensor([-0.7634, -0.2843, -0.2280])\n","Predicted tensor([-0.6131, -0.5341, -0.0889], grad_fn=<SelectBackward>) Actual tensor([-0.7444, -0.7600, -0.2831])\n","Predicted tensor([0.7311, 0.6473, 0.0490], grad_fn=<SelectBackward>) Actual tensor([ 0.8316, -0.3646, -0.3548])\n","Predicted tensor([-0.6638, -0.4012, -0.1486], grad_fn=<SelectBackward>) Actual tensor([-0.8078, -0.7436, -0.2746])\n","Predicted tensor([-1.1684,  0.6200, -0.1232], grad_fn=<SelectBackward>) Actual tensor([ 1.0945,  1.2532, -0.1738])\n","Predicted tensor([-0.6577, -0.2703, -0.1539], grad_fn=<SelectBackward>) Actual tensor([-0.7678, -0.4917, -0.2869])\n","Predicted tensor([-0.6341, -0.6200, -0.0171], grad_fn=<SelectBackward>) Actual tensor([-0.5868, -0.2654, -0.2442])\n","Predicted tensor([ 0.7217,  0.2699, -0.0228], grad_fn=<SelectBackward>) Actual tensor([ 0.5383, -0.2992, -0.3255])\n","Predicted tensor([ 1.5539e-04, -2.2729e-01, -1.3954e-01], grad_fn=<SelectBackward>) Actual tensor([-0.5868, -0.3873, -0.3129])\n","Predicted tensor([-0.9008,  0.4626, -0.1235], grad_fn=<SelectBackward>) Actual tensor([-1.0546,  0.2733, -0.4101])\n","Predicted tensor([-1.0746, -0.1766, -0.0322], grad_fn=<SelectBackward>) Actual tensor([ 0.9914, -0.5799, -0.1097])\n","Predicted tensor([-1.0548,  0.5558, -0.1071], grad_fn=<SelectBackward>) Actual tensor([-1.9619, -0.4128, -0.4835])\n","Predicted tensor([-0.9773, -0.4788,  4.5744], grad_fn=<SelectBackward>) Actual tensor([-1.0721, -0.7286,  5.1410])\n","Predicted tensor([-0.5606, -0.4142, -0.1276], grad_fn=<SelectBackward>) Actual tensor([ 1.7227,  0.0279, -0.3598])\n","Predicted tensor([-0.0384, -0.2118, -0.1207], grad_fn=<SelectBackward>) Actual tensor([-0.6632, -0.5919, -0.2946])\n","Predicted tensor([-0.6959, -0.4547, -0.1039], grad_fn=<SelectBackward>) Actual tensor([-0.8280, -0.4385, -0.2580])\n","Predicted tensor([ 0.0983, -0.2536, -0.1100], grad_fn=<SelectBackward>) Actual tensor([ 1.3205,  0.0174, -0.3585])\n","Predicted tensor([ 0.2380, -0.2640, -0.4005], grad_fn=<SelectBackward>) Actual tensor([-1.3065,  0.3227,  0.0123])\n","Predicted tensor([ 0.1365,  0.0945, -0.1613], grad_fn=<SelectBackward>) Actual tensor([ 0.2977,  1.9975, -0.0516])\n","Predicted tensor([-0.0380, -0.1564, -0.1186], grad_fn=<SelectBackward>) Actual tensor([-0.5593, -0.5875, -0.3061])\n","Predicted tensor([-0.5575, -0.4505, -0.0922], grad_fn=<SelectBackward>) Actual tensor([ 0.6153,  1.0745, -0.2772])\n","Predicted tensor([ 0.2608, -0.3052, -0.1247], grad_fn=<SelectBackward>) Actual tensor([ 0.0551, -0.3587, -0.2795])\n","Predicted tensor([-0.3406, -0.2899, -0.1366], grad_fn=<SelectBackward>) Actual tensor([ 1.1193,  1.5386, -0.0897])\n","Predicted tensor([-0.5780, -0.4231, -0.1130], grad_fn=<SelectBackward>) Actual tensor([-0.7211, -0.5044, -0.2500])\n","Predicted tensor([ 0.5767, -0.3840, -0.1648], grad_fn=<SelectBackward>) Actual tensor([-0.9963, -0.6851, -0.1020])\n","Predicted tensor([-0.3686,  0.5637, -0.1795], grad_fn=<SelectBackward>) Actual tensor([-0.3993,  0.8607, -0.3662])\n","Predicted tensor([-0.6788, -0.2698, -0.1278], grad_fn=<SelectBackward>) Actual tensor([-0.4095, -0.7882, -0.3290])\n","Predicted tensor([ 0.3009, -0.2746, -0.1408], grad_fn=<SelectBackward>) Actual tensor([ 1.1230, -0.7263, -0.3254])\n","Predicted tensor([ 0.6930, -0.3609, -0.2240], grad_fn=<SelectBackward>) Actual tensor([ 1.1064, -0.4409, -0.2915])\n","Predicted tensor([-0.6689, -0.5146, -0.0937], grad_fn=<SelectBackward>) Actual tensor([-0.8247, -0.6379, -0.2595])\n","Predicted tensor([ 0.4614,  0.3240, -0.1080], grad_fn=<SelectBackward>) Actual tensor([0.9096, 0.9878, 0.6853])\n","Predicted tensor([ 0.0127, -0.3559, -0.1340], grad_fn=<SelectBackward>) Actual tensor([-0.4773, -0.7725, -0.2569])\n","Predicted tensor([-0.4957, -0.4456, -0.1072], grad_fn=<SelectBackward>) Actual tensor([ 0.0628, -0.7726, -0.3300])\n","Predicted tensor([-0.6796, -0.3684, -0.1090], grad_fn=<SelectBackward>) Actual tensor([-0.7528, -0.7769, -0.2777])\n","Predicted tensor([ 0.4604,  0.2601, -0.0652], grad_fn=<SelectBackward>) Actual tensor([ 0.8832, -0.0403, -0.2964])\n","Predicted tensor([-0.3547, -0.1326, -0.0058], grad_fn=<SelectBackward>) Actual tensor([-1.3290,  0.3576,  0.0074])\n","Predicted tensor([ 0.7007, -0.2989, -0.2189], grad_fn=<SelectBackward>) Actual tensor([ 1.2640, -0.5042, -0.3222])\n","Predicted tensor([ 0.1175, -0.2719, -0.1340], grad_fn=<SelectBackward>) Actual tensor([ 1.1780, -0.5860, -0.3340])\n","Predicted tensor([-0.7186,  0.4135, -0.1316], grad_fn=<SelectBackward>) Actual tensor([-0.8300,  0.2015, -0.3897])\n","Predicted tensor([-0.8068, -0.2954, -0.0919], grad_fn=<SelectBackward>) Actual tensor([ 1.5044, -0.0794, -0.1487])\n","Predicted tensor([ 0.3121, -0.0894, -0.1091], grad_fn=<SelectBackward>) Actual tensor([-0.0876, -0.1251, -0.2559])\n","Predicted tensor([-0.4389,  0.9606,  0.7007], grad_fn=<SelectBackward>) Actual tensor([-1.8383, -0.2182,  1.0234])\n","Predicted tensor([ 0.0888, -0.0324, -0.1458], grad_fn=<SelectBackward>) Actual tensor([-0.4252, -0.7793, -0.2922])\n","Predicted tensor([-0.7011, -0.3696, -0.0940], grad_fn=<SelectBackward>) Actual tensor([ 0.4399,  2.0222, -0.2506])\n","Predicted tensor([ 0.3112, -0.2903, -0.1666], grad_fn=<SelectBackward>) Actual tensor([ 1.7075,  0.3953, -0.3726])\n","Predicted tensor([0.6733, 0.4260, 0.0084], grad_fn=<SelectBackward>) Actual tensor([1.9904, 2.7642, 0.2712])\n","Predicted tensor([ 0.2025, -0.3773, -0.1276], grad_fn=<SelectBackward>) Actual tensor([-0.6432, -0.6939, -0.3029])\n","Predicted tensor([ 0.5614, -0.0504, -0.1744], grad_fn=<SelectBackward>) Actual tensor([ 2.0252,  1.3081, -0.2985])\n","Predicted tensor([-0.5885, -0.3287, -0.1154], grad_fn=<SelectBackward>) Actual tensor([2.2967, 2.7434, 0.3143])\n","Predicted tensor([ 0.2045, -0.2385, -0.1284], grad_fn=<SelectBackward>) Actual tensor([ 1.1410, -0.5445, -0.3330])\n","Predicted tensor([ 0.6943, -0.3291, -0.2553], grad_fn=<SelectBackward>) Actual tensor([ 1.2897, -0.7674, -0.3149])\n","Predicted tensor([-0.1360, -0.1281, -0.1170], grad_fn=<SelectBackward>) Actual tensor([-1.5163,  1.5643,  0.8790])\n","Predicted tensor([ 0.5345, -0.3249, -0.2369], grad_fn=<SelectBackward>) Actual tensor([ 0.6914, -0.7438, -0.2899])\n","Predicted tensor([-0.5274,  0.1620, -0.1046], grad_fn=<SelectBackward>) Actual tensor([-0.6641, -0.0740, -0.3299])\n","Predicted tensor([ 0.6896, -0.1508, -0.2162], grad_fn=<SelectBackward>) Actual tensor([ 0.4542,  0.4020, -0.2875])\n","Predicted tensor([-1.2036, -0.1721,  0.0337], grad_fn=<SelectBackward>) Actual tensor([-1.9986, -0.2685, -0.3915])\n","Predicted tensor([-1.0254, -0.5630,  4.6323], grad_fn=<SelectBackward>) Actual tensor([-1.0671, -0.2964,  5.1079])\n","Predicted tensor([-0.4945, -0.4599, -0.1177], grad_fn=<SelectBackward>) Actual tensor([-0.9997, -0.2628, -0.2279])\n","Predicted tensor([-0.2216, -0.2167, -0.0903], grad_fn=<SelectBackward>) Actual tensor([-0.5009, -0.7331, -0.2857])\n","Predicted tensor([0.2773, 1.0953, 0.2390], grad_fn=<SelectBackward>) Actual tensor([ 1.0534, -0.3062, -0.3425])\n","Predicted tensor([ 0.3840,  0.4476, -0.0974], grad_fn=<SelectBackward>) Actual tensor([ 1.0823,  0.9324, -0.3272])\n","Predicted tensor([-0.2485,  0.7324, -0.1969], grad_fn=<SelectBackward>) Actual tensor([-1.2346, -0.1756, -0.3512])\n","Predicted tensor([0.2343, 1.0778, 0.0162], grad_fn=<SelectBackward>) Actual tensor([-0.5104, -0.7499, -0.3231])\n","Predicted tensor([-0.5752, -0.3735, -0.1267], grad_fn=<SelectBackward>) Actual tensor([-0.5341, -0.3215, -0.2197])\n","Predicted tensor([-0.3080, -0.0195,  0.0631], grad_fn=<SelectBackward>) Actual tensor([ 0.1199, -0.0752, -0.3328])\n","Predicted tensor([0.7184, 0.3668, 0.0303], grad_fn=<SelectBackward>) Actual tensor([ 1.5081,  0.5340, -0.3698])\n","Predicted tensor([-0.4900,  1.2933,  2.7605], grad_fn=<SelectBackward>) Actual tensor([0.1751, 1.8248, 2.6034])\n","Predicted tensor([ 0.7065, -0.4194, -0.2341], grad_fn=<SelectBackward>) Actual tensor([-0.6239, -0.5167, -0.2204])\n","Predicted tensor([-0.1232,  0.0843,  1.5041], grad_fn=<SelectBackward>) Actual tensor([-0.5042, -0.7282,  3.5981])\n","Predicted tensor([ 0.6989, -0.3152, -0.2523], grad_fn=<SelectBackward>) Actual tensor([ 1.1758, -0.5509, -0.3286])\n","Predicted tensor([-0.1494,  0.2584,  0.1691], grad_fn=<SelectBackward>) Actual tensor([ 1.7431,  0.5703, -0.3713])\n","Predicted tensor([ 0.7032, -0.2959, -0.2411], grad_fn=<SelectBackward>) Actual tensor([ 1.1231, -0.6826, -0.3246])\n","Predicted tensor([-0.0818, -0.1103, -0.1202], grad_fn=<SelectBackward>) Actual tensor([-0.0677,  1.3265, -0.1247])\n","Predicted tensor([-0.6177, -0.4150, -0.1052], grad_fn=<SelectBackward>) Actual tensor([-0.4134, -0.7616, -0.3250])\n","Predicted tensor([-0.4446, -0.2929, -0.1004], grad_fn=<SelectBackward>) Actual tensor([-0.6077, -0.7528, -0.3290])\n","Predicted tensor([ 0.5600,  0.8932, -0.0136], grad_fn=<SelectBackward>) Actual tensor([ 2.2329, -0.6334, -0.2615])\n","Predicted tensor([-1.1586,  0.4740, -0.0432], grad_fn=<SelectBackward>) Actual tensor([-2.3192, -0.7961, -0.4616])\n","Predicted tensor([0.5115, 0.9418, 0.1198], grad_fn=<SelectBackward>) Actual tensor([-0.2484, -0.4693, -0.3195])\n","Predicted tensor([0.1517, 0.3611, 0.2078], grad_fn=<SelectBackward>) Actual tensor([1.7701, 4.7830, 1.0717])\n","Predicted tensor([ 0.4299,  0.2974, -0.1517], grad_fn=<SelectBackward>) Actual tensor([ 0.9940,  2.8972, -0.0411])\n","Predicted tensor([-0.1775,  1.0580,  0.3706], grad_fn=<SelectBackward>) Actual tensor([-1.5270,  0.7567,  0.3594])\n","Predicted tensor([ 0.3577, -0.2427, -0.3576], grad_fn=<SelectBackward>) Actual tensor([ 0.0565, -0.7582, -0.3306])\n","Predicted tensor([-1.3342,  0.3098,  0.0063], grad_fn=<SelectBackward>) Actual tensor([-2.2052, -0.0722, -0.4240])\n","Predicted tensor([ 0.1324, -0.2377, -0.1463], grad_fn=<SelectBackward>) Actual tensor([ 1.3591, -0.1061, -0.3583])\n","Predicted tensor([-0.6174, -0.4029, -0.1206], grad_fn=<SelectBackward>) Actual tensor([-0.7973, -0.4409, -0.2630])\n","Predicted tensor([-0.6299, -0.4726, -0.0863], grad_fn=<SelectBackward>) Actual tensor([-0.6918, -0.5924, -0.3082])\n","Predicted tensor([ 0.7035, -0.2986, -0.2636], grad_fn=<SelectBackward>) Actual tensor([ 1.0684, -0.4736, -0.3295])\n","Predicted tensor([-0.5795, -0.3388, -0.1012], grad_fn=<SelectBackward>) Actual tensor([1.3367, 5.2522, 1.6973])\n","Batch: 5 completed\n","Predicted tensor([-0.5251, -0.4806, -0.1191], grad_fn=<SelectBackward>) Actual tensor([-0.6937, -0.7716, -0.2916])\n","Predicted tensor([-0.4933, -0.2936, -0.0900], grad_fn=<SelectBackward>) Actual tensor([-0.5834, -0.7680, -0.3293])\n","Predicted tensor([ 0.7023, -0.3696, -0.2615], grad_fn=<SelectBackward>) Actual tensor([ 1.2209, -0.7560, -0.3079])\n","Predicted tensor([-0.0878, -0.2144, -0.1254], grad_fn=<SelectBackward>) Actual tensor([ 0.8238,  0.3706, -0.3309])\n","Predicted tensor([-0.6091, -0.4415, -0.0909], grad_fn=<SelectBackward>) Actual tensor([-0.6920, -0.7523, -0.2891])\n","Predicted tensor([-0.2192,  0.1013, -0.0089], grad_fn=<SelectBackward>) Actual tensor([2.1746, 0.2009, 0.1894])\n","Predicted tensor([-0.6157, -0.3784, -0.1100], grad_fn=<SelectBackward>) Actual tensor([-0.7119, -0.7727, -0.2874])\n","Predicted tensor([-0.5792, -0.2900, -0.0971], grad_fn=<SelectBackward>) Actual tensor([0.9978, 3.5061, 0.4889])\n","Predicted tensor([ 0.6355, -0.2701, -0.1714], grad_fn=<SelectBackward>) Actual tensor([ 1.1087, -0.7835, -0.3312])\n","Predicted tensor([-0.0721,  1.0918,  0.4625], grad_fn=<SelectBackward>) Actual tensor([-0.6619,  2.7716,  1.3124])\n","Predicted tensor([-0.6122, -0.3624, -0.1330], grad_fn=<SelectBackward>) Actual tensor([-0.5812, -0.2542, -0.2321])\n","Predicted tensor([ 0.6118, -0.1984, -0.1998], grad_fn=<SelectBackward>) Actual tensor([ 1.4287, -0.3411, -0.3259])\n","Predicted tensor([-0.6060, -0.3328, -0.1315], grad_fn=<SelectBackward>) Actual tensor([-0.1622, -0.7217, -0.2891])\n","Predicted tensor([-0.6686, -0.4472, -0.1191], grad_fn=<SelectBackward>) Actual tensor([-0.7823, -0.4205, -0.2681])\n","Predicted tensor([-0.7007, -0.5478, -0.0348], grad_fn=<SelectBackward>) Actual tensor([ 1.4701, -0.3988, -0.3325])\n","Predicted tensor([-0.4168, -0.2775, -0.1536], grad_fn=<SelectBackward>) Actual tensor([-0.3913, -0.0652, -0.2304])\n","Predicted tensor([-0.6629, -0.4539, -0.0484], grad_fn=<SelectBackward>) Actual tensor([-0.5598, -0.0853, -0.2560])\n","Predicted tensor([0.1037, 0.3033, 0.2617], grad_fn=<SelectBackward>) Actual tensor([-1.7299,  0.5448, -0.2654])\n","Predicted tensor([ 0.6714, -0.2166, -0.2319], grad_fn=<SelectBackward>) Actual tensor([ 1.1178, -0.7079, -0.3339])\n","Predicted tensor([ 0.1318,  0.0618, -0.1241], grad_fn=<SelectBackward>) Actual tensor([ 0.1605,  2.2005, -0.1933])\n","Predicted tensor([-0.6542, -0.1900, -0.0158], grad_fn=<SelectBackward>) Actual tensor([-1.5654,  0.7949, -0.0227])\n","Predicted tensor([ 0.5689, -0.1577, -0.2222], grad_fn=<SelectBackward>) Actual tensor([-0.7085, -0.6293, -0.3118])\n","Predicted tensor([-0.6444,  0.5740, -0.1768], grad_fn=<SelectBackward>) Actual tensor([-1.6604, -0.0090, -0.3884])\n","Predicted tensor([-0.4652, -0.5103, -0.1165], grad_fn=<SelectBackward>) Actual tensor([ 0.3875, -0.5725, -0.1785])\n","Predicted tensor([-0.7710,  0.2284, -0.0892], grad_fn=<SelectBackward>) Actual tensor([-2.0249,  0.7128, -0.4014])\n","Predicted tensor([-0.5536, -0.2730, -0.1671], grad_fn=<SelectBackward>) Actual tensor([-0.5818, -0.0288, -0.1276])\n","Predicted tensor([ 0.6911, -0.3557, -0.2552], grad_fn=<SelectBackward>) Actual tensor([ 0.2571, -0.7633, -0.2483])\n","Predicted tensor([0.3436, 0.8659, 0.0025], grad_fn=<SelectBackward>) Actual tensor([ 0.5048,  1.1492, -0.2050])\n","Predicted tensor([ 0.6415, -0.1424, -0.2057], grad_fn=<SelectBackward>) Actual tensor([ 1.1074, -0.4842, -0.3388])\n","Predicted tensor([-0.0269, -0.2198, -0.1194], grad_fn=<SelectBackward>) Actual tensor([-0.3741, -0.7719, -0.3089])\n","Predicted tensor([ 0.6489, -0.0771, -0.2030], grad_fn=<SelectBackward>) Actual tensor([-0.3897, -0.7250, -0.3071])\n","Predicted tensor([ 0.0368, -0.1201, -0.1232], grad_fn=<SelectBackward>) Actual tensor([ 0.0447, -0.6982, -0.2325])\n","Predicted tensor([-0.2845,  1.0751,  0.7402], grad_fn=<SelectBackward>) Actual tensor([-0.5675,  1.6959,  0.0487])\n","Predicted tensor([-0.7755, -0.3166,  0.0281], grad_fn=<SelectBackward>) Actual tensor([-1.5914,  0.4555, -0.0674])\n","Predicted tensor([-1.0701,  0.5222, -0.1085], grad_fn=<SelectBackward>) Actual tensor([-1.8667, -0.4396, -0.5173])\n","Predicted tensor([ 0.0606, -0.1677, -0.1374], grad_fn=<SelectBackward>) Actual tensor([ 1.9570, -0.1113, -0.3257])\n","Predicted tensor([ 0.2061, -0.1253, -0.1273], grad_fn=<SelectBackward>) Actual tensor([ 1.1116, -0.7248, -0.3305])\n","Predicted tensor([-0.5638, -0.4422, -0.1014], grad_fn=<SelectBackward>) Actual tensor([-0.7469, -0.5555, -0.2945])\n","Predicted tensor([-0.2599,  0.2926, -0.1219], grad_fn=<SelectBackward>) Actual tensor([-0.8016, -0.5300, -0.3424])\n","Predicted tensor([-0.6513, -0.2438, -0.1170], grad_fn=<SelectBackward>) Actual tensor([-0.2043, -0.3935, -0.3280])\n","Predicted tensor([ 0.1212, -0.2514, -0.1186], grad_fn=<SelectBackward>) Actual tensor([ 1.1187, -0.5938, -0.3363])\n","Predicted tensor([ 0.6559, -0.0957, -0.1237], grad_fn=<SelectBackward>) Actual tensor([ 1.5321,  1.1613, -0.2371])\n","Predicted tensor([ 0.6873, -0.2520, -0.2336], grad_fn=<SelectBackward>) Actual tensor([ 1.1839, -0.4937, -0.3269])\n","Predicted tensor([-0.1508, -0.3542, -0.0736], grad_fn=<SelectBackward>) Actual tensor([-0.5289, -0.7459, -0.2645])\n","Predicted tensor([-0.9756, -0.4757,  4.5225], grad_fn=<SelectBackward>) Actual tensor([-1.0043, -0.6840,  5.1454])\n","Predicted tensor([-0.0954, -0.3258, -0.1280], grad_fn=<SelectBackward>) Actual tensor([-0.7088,  0.5699, -0.1577])\n","Predicted tensor([ 0.0604, -0.0747, -0.1123], grad_fn=<SelectBackward>) Actual tensor([1.4385, 1.4771, 0.2578])\n","Predicted tensor([-0.0665, -0.2331, -0.0779], grad_fn=<SelectBackward>) Actual tensor([ 1.1504, -0.5734, -0.3351])\n","Predicted tensor([-0.9719, -0.4779,  4.5625], grad_fn=<SelectBackward>) Actual tensor([-0.7400, -0.6119,  5.1508])\n","Predicted tensor([ 0.5125, -0.2840, -0.1935], grad_fn=<SelectBackward>) Actual tensor([-0.5683, -0.1656, -0.1612])\n","Predicted tensor([-1.0653, -0.7667,  4.4127], grad_fn=<SelectBackward>) Actual tensor([1.8765, 1.0321, 0.2035])\n","Predicted tensor([-0.9734, -0.4743,  4.5026], grad_fn=<SelectBackward>) Actual tensor([-0.8012, -0.1819,  5.1129])\n","Predicted tensor([-1.0627, -0.5890,  4.7048], grad_fn=<SelectBackward>) Actual tensor([-1.1058,  0.2077,  5.1617])\n","Predicted tensor([-0.7072, -0.0115, -0.1425], grad_fn=<SelectBackward>) Actual tensor([-0.1747, -0.1108, -0.3382])\n","Predicted tensor([-0.5762, -0.4355, -0.1205], grad_fn=<SelectBackward>) Actual tensor([-0.8090, -0.6574, -0.2751])\n","Predicted tensor([-0.0746, -0.3345, -0.1053], grad_fn=<SelectBackward>) Actual tensor([-0.5548, -0.7480, -0.2759])\n","Predicted tensor([ 0.5916,  0.4908, -0.0269], grad_fn=<SelectBackward>) Actual tensor([-0.2717, -0.5344, -0.3044])\n","Predicted tensor([ 0.6913, -0.1317, -0.2344], grad_fn=<SelectBackward>) Actual tensor([-0.6215,  0.0571,  0.3320])\n","Predicted tensor([-0.9956, -0.3027,  4.2410], grad_fn=<SelectBackward>) Actual tensor([-1.7416, -0.6404,  4.7568])\n","Predicted tensor([0.2438, 0.2085, 0.2844], grad_fn=<SelectBackward>) Actual tensor([-0.2255, -0.2615, -0.3334])\n","Predicted tensor([ 0.6187, -0.1817, -0.1826], grad_fn=<SelectBackward>) Actual tensor([-0.4250, -0.6218, -0.2952])\n","Predicted tensor([-0.0779,  0.7987,  1.3803], grad_fn=<SelectBackward>) Actual tensor([0.5582, 3.4372, 1.4498])\n","Predicted tensor([-0.0631, -0.2114, -0.1096], grad_fn=<SelectBackward>) Actual tensor([-0.7651, -0.5364, -0.3089])\n","Predicted tensor([ 0.6691, -0.0214, -0.0680], grad_fn=<SelectBackward>) Actual tensor([ 2.2162, -0.5664, -0.2005])\n","Predicted tensor([ 0.6768, -0.0598, -0.1672], grad_fn=<SelectBackward>) Actual tensor([-0.0756,  0.9104, -0.2304])\n","Predicted tensor([-0.4767, -0.4716, -0.1111], grad_fn=<SelectBackward>) Actual tensor([-0.4194,  0.9042,  0.0048])\n","Predicted tensor([-0.5317, -0.4803, -0.0951], grad_fn=<SelectBackward>) Actual tensor([-0.3640, -0.2810, -0.1741])\n","Predicted tensor([ 0.6864, -0.2746, -0.2368], grad_fn=<SelectBackward>) Actual tensor([-0.6329, -0.7047, -0.2713])\n","Predicted tensor([0.2752, 0.6194, 0.4168], grad_fn=<SelectBackward>) Actual tensor([-0.4669, -0.7718, -0.3005])\n","Predicted tensor([-0.2387,  0.4463,  2.5092], grad_fn=<SelectBackward>) Actual tensor([ 0.1671, -0.3576,  2.8983])\n","Predicted tensor([ 0.0583, -0.2357, -0.1502], grad_fn=<SelectBackward>) Actual tensor([-0.5406, -0.7342, -0.2726])\n","Predicted tensor([-0.6170, -0.5093, -0.0861], grad_fn=<SelectBackward>) Actual tensor([-0.7395, -0.5334, -0.2899])\n","Predicted tensor([ 0.1980,  0.2465, -0.2787], grad_fn=<SelectBackward>) Actual tensor([0.3256, 1.3760, 0.4238])\n","Predicted tensor([ 0.2782, -0.3870, -0.1298], grad_fn=<SelectBackward>) Actual tensor([0.3689, 1.8063, 0.5954])\n","Predicted tensor([ 0.1103, -0.2600, -0.1063], grad_fn=<SelectBackward>) Actual tensor([ 1.0983, -0.2323, -0.2690])\n","Predicted tensor([ 0.7044, -0.3232, -0.2550], grad_fn=<SelectBackward>) Actual tensor([ 1.1503, -0.5446, -0.3126])\n","Predicted tensor([ 0.1750, -0.2081, -0.1254], grad_fn=<SelectBackward>) Actual tensor([ 2.0776, -0.5430, -0.3452])\n","Predicted tensor([ 0.1565, -0.1393, -0.1428], grad_fn=<SelectBackward>) Actual tensor([ 1.2283, -0.6187, -0.3323])\n","Predicted tensor([-0.5932, -0.5023, -0.1023], grad_fn=<SelectBackward>) Actual tensor([-0.8454, -0.6824, -0.2734])\n","Predicted tensor([-0.6186,  0.9300, -0.1951], grad_fn=<SelectBackward>) Actual tensor([-1.6757, -0.2964, -0.5495])\n","Predicted tensor([ 0.6509,  0.4408, -0.0847], grad_fn=<SelectBackward>) Actual tensor([ 1.1700,  0.0922, -0.3518])\n","Predicted tensor([ 0.4738, -0.4389, -0.1687], grad_fn=<SelectBackward>) Actual tensor([ 1.5310,  0.0369, -0.3548])\n","Predicted tensor([-0.9744, -0.5645,  4.4397], grad_fn=<SelectBackward>) Actual tensor([-0.7709, -0.3298,  5.1492])\n","Predicted tensor([ 0.6921, -0.3388, -0.2629], grad_fn=<SelectBackward>) Actual tensor([ 0.2609,  0.3844, -0.2008])\n","Predicted tensor([ 0.1460, -0.2511, -0.1209], grad_fn=<SelectBackward>) Actual tensor([-0.2685, -0.5622, -0.3128])\n","Predicted tensor([ 0.2763, -0.1873, -0.0695], grad_fn=<SelectBackward>) Actual tensor([ 0.2849,  0.2648, -0.1828])\n","Predicted tensor([-0.3862, -0.4395, -0.0907], grad_fn=<SelectBackward>) Actual tensor([-0.5607, -0.7112, -0.2604])\n","Predicted tensor([-0.1087, -0.3143, -0.0657], grad_fn=<SelectBackward>) Actual tensor([-0.5138, -0.4391, -0.2490])\n","Predicted tensor([-0.9394, -0.3986,  4.4843], grad_fn=<SelectBackward>) Actual tensor([-1.0326, -0.7594,  5.1413])\n","Predicted tensor([-0.3704, -0.3402, -0.1343], grad_fn=<SelectBackward>) Actual tensor([-0.7349, -0.7136, -0.3160])\n","Predicted tensor([-0.3653, -0.0132, -0.1753], grad_fn=<SelectBackward>) Actual tensor([ 1.0986, -0.5602, -0.3386])\n","Predicted tensor([ 0.3539,  0.7040, -0.0876], grad_fn=<SelectBackward>) Actual tensor([-0.1624,  2.4126, -0.2988])\n","Predicted tensor([-0.0294, -0.1726, -0.1441], grad_fn=<SelectBackward>) Actual tensor([-0.2312, -0.3827, -0.3277])\n","Predicted tensor([-0.1348, -0.2427, -0.1072], grad_fn=<SelectBackward>) Actual tensor([-0.7212, -0.6211, -0.3157])\n","Predicted tensor([-0.0569, -0.3349, -0.1081], grad_fn=<SelectBackward>) Actual tensor([-0.5749, -0.6378, -0.2592])\n","Predicted tensor([ 0.0647,  0.0418, -0.1263], grad_fn=<SelectBackward>) Actual tensor([-0.1722, -0.1907, -0.3090])\n","Predicted tensor([ 0.4576,  0.3101, -0.1584], grad_fn=<SelectBackward>) Actual tensor([0.9635, 1.4620, 0.2904])\n","Predicted tensor([-0.6479, -0.4605, -0.1181], grad_fn=<SelectBackward>) Actual tensor([-0.5484,  0.2981, -0.1706])\n","Predicted tensor([ 0.6584, -0.2754, -0.2206], grad_fn=<SelectBackward>) Actual tensor([ 0.0208,  0.7269, -0.1669])\n","Predicted tensor([-0.4445,  1.1279, -0.1365], grad_fn=<SelectBackward>) Actual tensor([-0.1042,  2.2000,  0.0517])\n","Predicted tensor([-0.9738, -0.4943,  4.5372], grad_fn=<SelectBackward>) Actual tensor([-1.0333, -0.7816,  5.1429])\n","Predicted tensor([-0.3344,  0.5167,  0.4225], grad_fn=<SelectBackward>) Actual tensor([ 1.5837,  1.5699, -0.3549])\n","Predicted tensor([ 0.1293, -0.2291, -0.1219], grad_fn=<SelectBackward>) Actual tensor([-0.7860,  1.8417,  0.0271])\n","Predicted tensor([ 0.6750, -0.1284, -0.2102], grad_fn=<SelectBackward>) Actual tensor([ 0.9797,  1.2820, -0.2549])\n","Predicted tensor([-0.4127,  0.4313, -0.1309], grad_fn=<SelectBackward>) Actual tensor([-0.1258,  0.5779, -0.3133])\n","Predicted tensor([ 0.6978, -0.3397, -0.2709], grad_fn=<SelectBackward>) Actual tensor([ 1.0877, -0.7353, -0.3376])\n","Predicted tensor([0.4806, 0.9426, 0.0230], grad_fn=<SelectBackward>) Actual tensor([-1.0589,  0.9758, -0.0155])\n","Predicted tensor([-0.6553, -0.3762, -0.1266], grad_fn=<SelectBackward>) Actual tensor([ 0.1927,  0.2816, -0.1011])\n","Predicted tensor([ 0.6709, -0.1113, -0.2202], grad_fn=<SelectBackward>) Actual tensor([ 1.0243, -0.5372, -0.3229])\n","Predicted tensor([ 0.6994, -0.3710, -0.2615], grad_fn=<SelectBackward>) Actual tensor([ 1.1296, -0.7042, -0.3265])\n","Predicted tensor([-0.3474, -0.4344, -0.1253], grad_fn=<SelectBackward>) Actual tensor([ 1.2422, -0.2659, -0.2658])\n","Predicted tensor([-1.0659,  0.6053, -0.1217], grad_fn=<SelectBackward>) Actual tensor([ 0.2219,  1.8216, -0.2877])\n","Predicted tensor([ 0.3328, -0.1176, -0.3699], grad_fn=<SelectBackward>) Actual tensor([-0.3305, -0.7847, -0.3247])\n","Predicted tensor([ 0.6596,  0.0185, -0.1898], grad_fn=<SelectBackward>) Actual tensor([1.9042, 2.0925, 0.0332])\n","Predicted tensor([-0.3307, -0.3183, -0.1311], grad_fn=<SelectBackward>) Actual tensor([1.9277, 3.2863, 0.3826])\n","Predicted tensor([-0.6639, -0.2933, -0.1271], grad_fn=<SelectBackward>) Actual tensor([-0.7935, -0.6244, -0.2856])\n","Predicted tensor([-0.6375, -0.3185, -0.1115], grad_fn=<SelectBackward>) Actual tensor([ 0.0320, -0.6887, -0.3307])\n","Predicted tensor([-0.3008, -0.3365, -0.1034], grad_fn=<SelectBackward>) Actual tensor([-0.5717, -0.7493, -0.3058])\n","Predicted tensor([ 0.7291, -0.2863, -0.1953], grad_fn=<SelectBackward>) Actual tensor([ 1.2356, -0.6524, -0.2636])\n","Predicted tensor([-0.3549,  0.3102, -0.1759], grad_fn=<SelectBackward>) Actual tensor([ 1.0207, -0.5122, -0.2668])\n","Predicted tensor([-0.4039, -0.3505, -0.1220], grad_fn=<SelectBackward>) Actual tensor([-0.3210, -0.3079, -0.1607])\n","Predicted tensor([-0.5871,  0.8062, -0.2326], grad_fn=<SelectBackward>) Actual tensor([-1.3397,  0.8820, -0.4678])\n","Predicted tensor([ 0.4008, -0.2066, -0.2052], grad_fn=<SelectBackward>) Actual tensor([ 1.3138, -0.7923, -0.3035])\n","Predicted tensor([-0.0841, -0.4110, -0.1069], grad_fn=<SelectBackward>) Actual tensor([-0.4768, -0.7744, -0.2430])\n","Predicted tensor([-0.6365, -0.2627, -0.0938], grad_fn=<SelectBackward>) Actual tensor([-0.1765, -0.0566, -0.3480])\n","Predicted tensor([ 0.6597, -0.1698, -0.2161], grad_fn=<SelectBackward>) Actual tensor([-0.4037, -0.7397, -0.3067])\n","Predicted tensor([ 0.0498,  0.0036, -0.1252], grad_fn=<SelectBackward>) Actual tensor([-0.6157, -0.1072, -0.3125])\n","Predicted tensor([ 0.3305,  0.4589, -0.0862], grad_fn=<SelectBackward>) Actual tensor([-0.5828,  1.8470,  0.6677])\n","Predicted tensor([-0.6147, -0.3843, -0.1444], grad_fn=<SelectBackward>) Actual tensor([-2.0216, -0.3639, -0.0227])\n","Predicted tensor([-0.5925, -0.4301, -0.1139], grad_fn=<SelectBackward>) Actual tensor([ 1.7785,  0.5498, -0.3809])\n","Predicted tensor([-0.6499, -0.5082, -0.0881], grad_fn=<SelectBackward>) Actual tensor([-0.4879,  0.0612, -0.1821])\n","Predicted tensor([ 0.1790, -0.3259, -0.1014], grad_fn=<SelectBackward>) Actual tensor([-0.4018, -0.7162, -0.2491])\n","Predicted tensor([-0.3593, -0.4154, -0.0623], grad_fn=<SelectBackward>) Actual tensor([-0.2874, -0.0150, -0.2260])\n","Predicted tensor([-0.9917, -0.4667,  4.5682], grad_fn=<SelectBackward>) Actual tensor([-1.1364, -0.6301,  5.0443])\n","Predicted tensor([-0.9525, -0.4360,  4.5264], grad_fn=<SelectBackward>) Actual tensor([-1.0704, -0.7786,  5.1431])\n","Predicted tensor([0.3963, 0.6973, 0.3081], grad_fn=<SelectBackward>) Actual tensor([1.3572, 3.5540, 0.5896])\n","Predicted tensor([-0.5242, -0.4920, -0.0825], grad_fn=<SelectBackward>) Actual tensor([-0.6688, -0.6778, -0.3111])\n","Predicted tensor([ 0.5896, -0.2198, -0.2846], grad_fn=<SelectBackward>) Actual tensor([ 2.4086, -0.3979, -0.2852])\n","Predicted tensor([-0.6770, -0.3601, -0.1206], grad_fn=<SelectBackward>) Actual tensor([-0.7374, -0.5871, -0.2900])\n","Predicted tensor([-0.0169, -0.0682, -0.1166], grad_fn=<SelectBackward>) Actual tensor([-0.2999,  0.0239, -0.2239])\n","Predicted tensor([0.5015, 0.3807, 0.3680], grad_fn=<SelectBackward>) Actual tensor([ 0.9961,  0.1654, -0.3525])\n","Predicted tensor([ 0.0357, -0.3181, -0.1266], grad_fn=<SelectBackward>) Actual tensor([ 1.7192, -0.4109, -0.3152])\n","Predicted tensor([-0.6547, -0.5286, -0.0844], grad_fn=<SelectBackward>) Actual tensor([-0.7486, -0.5738, -0.2287])\n","Predicted tensor([0.2111, 0.8787, 0.0018], grad_fn=<SelectBackward>) Actual tensor([ 0.5588,  0.7905, -0.2668])\n","Predicted tensor([ 0.1929, -0.2849, -0.1528], grad_fn=<SelectBackward>) Actual tensor([ 1.1280, -0.7352, -0.3336])\n","Predicted tensor([-1.1330,  0.6551, -0.0977], grad_fn=<SelectBackward>) Actual tensor([-1.5463,  0.4598, -0.2856])\n","Predicted tensor([-0.4110,  0.2156, -0.1505], grad_fn=<SelectBackward>) Actual tensor([-0.2009, -0.0879, -0.2828])\n","Predicted tensor([-0.7009, -0.3966, -0.1330], grad_fn=<SelectBackward>) Actual tensor([-0.7687, -0.4054, -0.2555])\n","Predicted tensor([ 0.0017, -0.2138, -0.1226], grad_fn=<SelectBackward>) Actual tensor([ 1.2936, -0.1844, -0.3490])\n","Predicted tensor([-1.1502,  0.5822, -0.1549], grad_fn=<SelectBackward>) Actual tensor([-0.9877,  3.1252, -0.2995])\n","Predicted tensor([ 0.7529, -0.1932, -0.2522], grad_fn=<SelectBackward>) Actual tensor([ 1.4021, -0.6482, -0.3151])\n","Predicted tensor([-0.6256, -0.1652, -0.1300], grad_fn=<SelectBackward>) Actual tensor([-1.7095,  0.2609, -0.0069])\n","Predicted tensor([ 0.2565,  0.4683, -0.0768], grad_fn=<SelectBackward>) Actual tensor([ 0.0356, -0.3325, -0.2753])\n","Predicted tensor([0.3175, 1.0865, 0.0199], grad_fn=<SelectBackward>) Actual tensor([-0.2393, -0.5425, -0.3071])\n","Predicted tensor([-0.1983, -0.1538, -0.1434], grad_fn=<SelectBackward>) Actual tensor([-0.7259, -0.7261, -0.3316])\n","Predicted tensor([-0.6494, -0.5621, -0.0832], grad_fn=<SelectBackward>) Actual tensor([-0.7886, -0.7930, -0.2531])\n","Predicted tensor([0.4094, 1.0253, 0.1480], grad_fn=<SelectBackward>) Actual tensor([-0.2363, -0.5925, -0.2861])\n","Predicted tensor([ 0.6151, -0.3913, -0.2695], grad_fn=<SelectBackward>) Actual tensor([-0.5024, -0.3408, -0.2796])\n","Predicted tensor([-0.2998, -0.4653, -0.0851], grad_fn=<SelectBackward>) Actual tensor([-0.5522, -0.7605, -0.2473])\n","Predicted tensor([ 0.1015, -0.1249, -0.1341], grad_fn=<SelectBackward>) Actual tensor([-0.3037, -0.4280, -0.2960])\n","Predicted tensor([-0.3484,  0.2799, -0.1059], grad_fn=<SelectBackward>) Actual tensor([-0.2528,  0.1390, -0.3437])\n","Predicted tensor([ 0.2003, -0.3411, -0.1365], grad_fn=<SelectBackward>) Actual tensor([ 1.1822, -0.5323, -0.3403])\n","Predicted tensor([ 0.5399, -0.3051, -0.1819], grad_fn=<SelectBackward>) Actual tensor([-0.5993, -0.1713, -0.2684])\n","Predicted tensor([-0.5752,  0.9569,  2.8000], grad_fn=<SelectBackward>) Actual tensor([-1.6904, -0.3428,  4.5733])\n","Predicted tensor([ 0.1685, -0.1535, -0.1385], grad_fn=<SelectBackward>) Actual tensor([ 1.6056, -0.3330, -0.3390])\n","Predicted tensor([ 0.6373, -0.1826, -0.1886], grad_fn=<SelectBackward>) Actual tensor([ 1.1156, -0.7525, -0.3268])\n","Predicted tensor([ 0.6918, -0.2374, -0.2226], grad_fn=<SelectBackward>) Actual tensor([ 1.1478, -0.5215, -0.3224])\n","Predicted tensor([-0.1363, -0.2009, -0.0688], grad_fn=<SelectBackward>) Actual tensor([-0.7077, -0.5694, -0.2629])\n","Predicted tensor([-1.0127, -0.5591,  4.5882], grad_fn=<SelectBackward>) Actual tensor([-1.0204, -0.4745,  5.1230])\n","Predicted tensor([ 0.5258,  0.0519, -0.1672], grad_fn=<SelectBackward>) Actual tensor([ 0.3902,  2.0860, -0.0314])\n","Predicted tensor([-1.0009, -0.5853,  4.4683], grad_fn=<SelectBackward>) Actual tensor([-1.0605, -0.7457,  5.1447])\n","Predicted tensor([-0.6767, -0.5139, -0.1057], grad_fn=<SelectBackward>) Actual tensor([-0.8414, -0.6844, -0.2629])\n","Predicted tensor([ 0.6873, -0.3324, -0.2480], grad_fn=<SelectBackward>) Actual tensor([ 1.1249, -0.6926, -0.3337])\n","Predicted tensor([ 0.0810, -0.2854, -0.0744], grad_fn=<SelectBackward>) Actual tensor([-0.6120,  0.9180,  0.0205])\n","Predicted tensor([-0.4389,  1.3717,  2.4531], grad_fn=<SelectBackward>) Actual tensor([0.2923, 3.0081, 3.0572])\n","Predicted tensor([ 0.5219,  0.2238, -0.1999], grad_fn=<SelectBackward>) Actual tensor([1.5677, 0.5166, 0.4941])\n","Predicted tensor([ 0.6983, -0.3275, -0.2552], grad_fn=<SelectBackward>) Actual tensor([ 0.5477,  1.7155, -0.0914])\n","Predicted tensor([ 0.3948, -0.0821, -0.0987], grad_fn=<SelectBackward>) Actual tensor([ 0.4629,  0.5554, -0.1577])\n","Predicted tensor([-0.2165,  0.6572, -0.1687], grad_fn=<SelectBackward>) Actual tensor([-0.6010,  0.7861, -0.3369])\n","Predicted tensor([-0.6784, -0.3957, -0.1330], grad_fn=<SelectBackward>) Actual tensor([-0.5639, -0.6940, -0.2928])\n","Predicted tensor([ 0.0887, -0.1974, -0.1095], grad_fn=<SelectBackward>) Actual tensor([-1.4385,  1.1091,  0.0312])\n","Predicted tensor([-0.1342, -0.4088, -0.0998], grad_fn=<SelectBackward>) Actual tensor([-0.4763, -0.5420, -0.1830])\n","Predicted tensor([ 0.4498,  0.3202, -0.1506], grad_fn=<SelectBackward>) Actual tensor([ 1.6494,  0.4257, -0.3392])\n","Predicted tensor([ 0.5881,  0.0232, -0.1176], grad_fn=<SelectBackward>) Actual tensor([ 1.0604, -0.5378, -0.3358])\n","Predicted tensor([ 0.6985, -0.3229, -0.2572], grad_fn=<SelectBackward>) Actual tensor([ 0.9648,  0.1716, -0.2779])\n","Predicted tensor([-0.2219, -0.4032, -0.1211], grad_fn=<SelectBackward>) Actual tensor([-0.5147, -0.5648, -0.2356])\n","Predicted tensor([-0.4048, -0.4815, -0.0948], grad_fn=<SelectBackward>) Actual tensor([-0.1602, -0.7787, -0.2100])\n","Predicted tensor([-0.0482,  1.0613,  0.1392], grad_fn=<SelectBackward>) Actual tensor([-0.6724, -0.6310, -0.3094])\n","Predicted tensor([ 0.6970, -0.3268, -0.2573], grad_fn=<SelectBackward>) Actual tensor([ 0.5752,  0.6111, -0.2622])\n","Predicted tensor([-0.1062,  0.0832, -0.1833], grad_fn=<SelectBackward>) Actual tensor([-0.2625, -0.6295, -0.3182])\n","Predicted tensor([-0.7197, -0.3960, -0.0466], grad_fn=<SelectBackward>) Actual tensor([-0.5799, -0.6820, -0.3201])\n","Predicted tensor([-0.9552, -0.4410,  4.5205], grad_fn=<SelectBackward>) Actual tensor([-0.9486, -0.6010,  5.1500])\n","Predicted tensor([ 0.6104,  0.0648, -0.2043], grad_fn=<SelectBackward>) Actual tensor([ 1.0030,  2.5519, -0.0824])\n","Predicted tensor([-0.6174, -0.5101, -0.1015], grad_fn=<SelectBackward>) Actual tensor([-0.7877, -0.3996, -0.2699])\n","Predicted tensor([-0.0302, -0.1954, -0.0866], grad_fn=<SelectBackward>) Actual tensor([ 1.9521, -0.4765, -0.3536])\n","Predicted tensor([0.1533, 0.1181, 0.0650], grad_fn=<SelectBackward>) Actual tensor([-0.8943,  1.8530,  0.2501])\n","Predicted tensor([-0.6444,  0.2735, -0.1497], grad_fn=<SelectBackward>) Actual tensor([-1.8004, -0.2326, -0.3554])\n","Predicted tensor([-0.1834, -0.2835, -0.1217], grad_fn=<SelectBackward>) Actual tensor([-0.5878, -0.7982, -0.3101])\n","Predicted tensor([0.2532, 0.1445, 0.0434], grad_fn=<SelectBackward>) Actual tensor([-2.1260,  0.2888, -0.5719])\n","Predicted tensor([-0.1034, -0.3694, -0.0966], grad_fn=<SelectBackward>) Actual tensor([ 2.1610, -0.3303, -0.1950])\n","Batch: 6 completed\n","Predicted tensor([-0.6199, -0.5009, -0.1210], grad_fn=<SelectBackward>) Actual tensor([-0.8582, -0.7917, -0.2609])\n","Predicted tensor([-0.5432, -0.3328, -0.0963], grad_fn=<SelectBackward>) Actual tensor([-0.3748, -0.6087, -0.3326])\n","Predicted tensor([-0.1301, -0.3704, -0.1122], grad_fn=<SelectBackward>) Actual tensor([ 1.8539, -0.5010, -0.2480])\n","Predicted tensor([-0.3413, -0.4455, -0.0883], grad_fn=<SelectBackward>) Actual tensor([-0.3732,  0.5565, -0.0849])\n","Predicted tensor([ 0.7000, -0.3771, -0.2559], grad_fn=<SelectBackward>) Actual tensor([ 0.3463, -0.5428, -0.2752])\n","Predicted tensor([ 0.0723, -0.1326, -0.1226], grad_fn=<SelectBackward>) Actual tensor([-0.2809, -0.5660, -0.3180])\n","Predicted tensor([-0.2238,  0.8952, -0.2138], grad_fn=<SelectBackward>) Actual tensor([-1.0371,  0.8319, -0.3471])\n","Predicted tensor([ 0.7102, -0.3145, -0.2656], grad_fn=<SelectBackward>) Actual tensor([ 1.7715,  0.4039, -0.2254])\n","Predicted tensor([-0.6048,  0.4845, -0.1368], grad_fn=<SelectBackward>) Actual tensor([-0.2105,  0.2872, -0.3871])\n","Predicted tensor([-0.1193,  0.5328,  0.2729], grad_fn=<SelectBackward>) Actual tensor([ 1.3376,  1.1733, -0.3504])\n","Predicted tensor([0.4747, 1.1771, 0.0780], grad_fn=<SelectBackward>) Actual tensor([2.3202, 1.2576, 0.3014])\n","Predicted tensor([ 0.7093, -0.4142, -0.2779], grad_fn=<SelectBackward>) Actual tensor([ 1.1435, -0.6615, -0.3156])\n","Predicted tensor([ 0.5421,  0.4452, -0.0048], grad_fn=<SelectBackward>) Actual tensor([1.2508, 2.7270, 0.5832])\n","Predicted tensor([ 0.5419,  0.3192, -0.0889], grad_fn=<SelectBackward>) Actual tensor([ 0.3440,  1.1516, -0.1813])\n","Predicted tensor([-0.5512, -0.5534, -0.0960], grad_fn=<SelectBackward>) Actual tensor([-0.8692, -0.6144, -0.2602])\n","Predicted tensor([-0.5355, -0.2410, -0.0900], grad_fn=<SelectBackward>) Actual tensor([-0.5342, -0.7444, -0.3370])\n","Predicted tensor([-0.0431, -0.2537, -0.0914], grad_fn=<SelectBackward>) Actual tensor([-0.3402, -0.7761, -0.3167])\n","Predicted tensor([0.0175, 0.4431, 0.3719], grad_fn=<SelectBackward>) Actual tensor([-1.7075, -0.4915,  0.4468])\n","Predicted tensor([-0.6694, -0.4138, -0.1083], grad_fn=<SelectBackward>) Actual tensor([-0.7774, -0.5109, -0.3059])\n","Predicted tensor([-0.4481,  0.5984, -0.1655], grad_fn=<SelectBackward>) Actual tensor([ 0.1995,  1.2913, -0.3328])\n","Predicted tensor([ 0.6216, -0.3581, -0.1647], grad_fn=<SelectBackward>) Actual tensor([ 1.1095, -0.7395, -0.3308])\n","Predicted tensor([ 0.6454,  0.1250, -0.1520], grad_fn=<SelectBackward>) Actual tensor([-1.4049,  0.7182, -0.3421])\n","Predicted tensor([-0.1005, -0.3606, -0.1297], grad_fn=<SelectBackward>) Actual tensor([-0.6330, -0.7551, -0.2554])\n","Predicted tensor([-0.4975,  0.0313, -0.1240], grad_fn=<SelectBackward>) Actual tensor([-0.5595, -0.0373, -0.3134])\n","Predicted tensor([-0.6394, -0.4753, -0.1129], grad_fn=<SelectBackward>) Actual tensor([-0.8231, -0.3210, -0.2464])\n","Predicted tensor([ 0.4101, -0.1909, -0.1320], grad_fn=<SelectBackward>) Actual tensor([ 0.3883, -0.0182, -0.2944])\n","Predicted tensor([-0.5650, -0.4902, -0.1033], grad_fn=<SelectBackward>) Actual tensor([-1.0564,  1.1823, -0.0042])\n","Predicted tensor([-0.4270, -0.4344, -0.1241], grad_fn=<SelectBackward>) Actual tensor([-0.3675, -0.7758, -0.2805])\n","Predicted tensor([-1.1582, -0.1473,  0.0151], grad_fn=<SelectBackward>) Actual tensor([ 2.3885, -0.5758, -0.2630])\n","Predicted tensor([ 0.1795,  0.7900, -0.0544], grad_fn=<SelectBackward>) Actual tensor([-1.0795,  0.3678, -0.1466])\n","Predicted tensor([ 0.1147, -0.3628, -0.1020], grad_fn=<SelectBackward>) Actual tensor([ 0.1260, -0.4885, -0.2144])\n","Predicted tensor([ 0.0489,  0.0174, -0.1068], grad_fn=<SelectBackward>) Actual tensor([ 2.3681, -0.4669, -0.2166])\n","Predicted tensor([ 0.2197,  0.6008, -0.0657], grad_fn=<SelectBackward>) Actual tensor([ 0.7990,  1.2720, -0.3281])\n","Predicted tensor([-0.0626, -0.0324, -0.1374], grad_fn=<SelectBackward>) Actual tensor([-0.6781, -0.6518, -0.3188])\n","Predicted tensor([ 0.7016, -0.3760, -0.2623], grad_fn=<SelectBackward>) Actual tensor([-0.6850, -0.4498, -0.2534])\n","Predicted tensor([-0.3158, -0.4750, -0.0884], grad_fn=<SelectBackward>) Actual tensor([-1.7983,  0.1746,  0.1200])\n","Predicted tensor([ 0.4954, -0.3716, -0.2209], grad_fn=<SelectBackward>) Actual tensor([ 2.1800,  1.1591, -0.2890])\n","Predicted tensor([-0.3728, -0.2817, -0.1810], grad_fn=<SelectBackward>) Actual tensor([-0.4060, -0.6428, -0.2566])\n","Predicted tensor([-0.8424, -0.1114, -0.0697], grad_fn=<SelectBackward>) Actual tensor([-0.6224, -0.7733, -0.3885])\n","Predicted tensor([ 0.6980, -0.2737, -0.2477], grad_fn=<SelectBackward>) Actual tensor([ 1.1826, -0.5399, -0.3314])\n","Predicted tensor([-0.6635,  0.8745, -0.2072], grad_fn=<SelectBackward>) Actual tensor([-1.7655, -0.7198, -0.4703])\n","Predicted tensor([-0.0634,  0.6342, -0.2001], grad_fn=<SelectBackward>) Actual tensor([ 0.3867,  0.3542, -0.2577])\n","Predicted tensor([ 0.6328, -0.1298, -0.2683], grad_fn=<SelectBackward>) Actual tensor([ 0.9459, -0.4634, -0.3528])\n","Predicted tensor([-0.3506, -0.3639, -0.1483], grad_fn=<SelectBackward>) Actual tensor([-0.3038, -0.0278, -0.1491])\n","Predicted tensor([-0.5767, -0.5649, -0.0825], grad_fn=<SelectBackward>) Actual tensor([-0.7138, -0.7748, -0.2488])\n","Predicted tensor([-0.4943, -0.4547, -0.0839], grad_fn=<SelectBackward>) Actual tensor([-0.7052, -0.7504, -0.2898])\n","Predicted tensor([ 0.7074, -0.2861, -0.2431], grad_fn=<SelectBackward>) Actual tensor([ 1.1618, -0.5265, -0.3231])\n","Predicted tensor([-0.9377,  0.5885, -0.1092], grad_fn=<SelectBackward>) Actual tensor([-0.7336,  1.5766, -0.3837])\n","Predicted tensor([-0.3407,  1.3149,  1.5210], grad_fn=<SelectBackward>) Actual tensor([0.0810, 0.3172, 0.3590])\n","Predicted tensor([-1.0400,  0.5244, -0.1177], grad_fn=<SelectBackward>) Actual tensor([-0.7175,  2.2492, -0.3050])\n","Predicted tensor([-0.5935, -0.3995, -0.1166], grad_fn=<SelectBackward>) Actual tensor([-0.7849, -0.4575, -0.2647])\n","Predicted tensor([ 0.1454, -0.3835, -0.0679], grad_fn=<SelectBackward>) Actual tensor([ 0.1660, -0.7549, -0.2308])\n","Predicted tensor([-0.3865,  1.1630,  2.5954], grad_fn=<SelectBackward>) Actual tensor([-0.0824,  2.7256,  3.6575])\n","Predicted tensor([ 0.3984, -0.2314, -0.1899], grad_fn=<SelectBackward>) Actual tensor([ 0.9634,  0.3529, -0.2749])\n","Predicted tensor([ 0.4981,  0.2522, -0.1317], grad_fn=<SelectBackward>) Actual tensor([ 1.6406,  1.9806, -0.2146])\n","Predicted tensor([ 0.2008, -0.3722, -0.1295], grad_fn=<SelectBackward>) Actual tensor([ 0.0540, -0.7921, -0.2459])\n","Predicted tensor([ 0.1746,  0.0514, -0.0995], grad_fn=<SelectBackward>) Actual tensor([ 1.0562, -0.5026, -0.3426])\n","Predicted tensor([ 0.3908, -0.4118, -0.1734], grad_fn=<SelectBackward>) Actual tensor([-0.0314, -0.7921, -0.2788])\n","Predicted tensor([ 0.6671, -0.1350, -0.2090], grad_fn=<SelectBackward>) Actual tensor([ 0.6463, -0.7337, -0.3162])\n","Predicted tensor([ 0.1512, -0.2377, -0.1360], grad_fn=<SelectBackward>) Actual tensor([-0.2298,  0.1353, -0.2244])\n","Predicted tensor([ 0.3632,  0.3984, -0.1123], grad_fn=<SelectBackward>) Actual tensor([ 1.3968,  0.8113, -0.3723])\n","Predicted tensor([ 0.1404, -0.1736, -0.1485], grad_fn=<SelectBackward>) Actual tensor([ 1.8452,  1.2580, -0.3516])\n","Predicted tensor([-0.6670, -0.5012, -0.0579], grad_fn=<SelectBackward>) Actual tensor([ 0.9760, -0.4632, -0.3460])\n","Predicted tensor([ 0.2446,  0.6276, -0.0389], grad_fn=<SelectBackward>) Actual tensor([ 0.7779,  1.0518, -0.2866])\n","Predicted tensor([ 0.3438, -0.2471,  0.0170], grad_fn=<SelectBackward>) Actual tensor([0.7716, 4.1534, 1.9661])\n","Predicted tensor([-0.4079, -0.3211, -0.1339], grad_fn=<SelectBackward>) Actual tensor([-0.4579, -0.6590, -0.2584])\n","Predicted tensor([ 0.6306,  0.0100, -0.1903], grad_fn=<SelectBackward>) Actual tensor([ 1.9990,  1.5052, -0.1830])\n","Predicted tensor([-0.7132, -0.2611, -0.1468], grad_fn=<SelectBackward>) Actual tensor([ 0.0969, -0.7564, -0.3298])\n","Predicted tensor([-0.5601, -0.2822, -0.1038], grad_fn=<SelectBackward>) Actual tensor([-0.1600, -0.7240, -0.3252])\n","Predicted tensor([ 0.6922, -0.3171, -0.2180], grad_fn=<SelectBackward>) Actual tensor([ 0.9596, -0.1894, -0.2571])\n","Predicted tensor([ 0.3701,  0.5632, -0.0591], grad_fn=<SelectBackward>) Actual tensor([-0.5196, -0.7542, -0.3233])\n","Predicted tensor([-0.7104,  0.0816, -0.1244], grad_fn=<SelectBackward>) Actual tensor([-0.3895,  1.8059,  5.1159])\n","Predicted tensor([ 0.3428, -0.3217, -0.0577], grad_fn=<SelectBackward>) Actual tensor([-2.2738,  0.7645, -0.4326])\n","Predicted tensor([0.4176, 0.7343, 0.0154], grad_fn=<SelectBackward>) Actual tensor([ 1.3272,  0.0765, -0.3564])\n","Predicted tensor([-0.8001,  0.1397, -0.0963], grad_fn=<SelectBackward>) Actual tensor([-0.1667,  0.3440, -0.3495])\n","Predicted tensor([-0.9721, -0.4713,  4.5403], grad_fn=<SelectBackward>) Actual tensor([-1.0920, -0.7753,  5.1437])\n","Predicted tensor([-0.4943, -0.4593, -0.1245], grad_fn=<SelectBackward>) Actual tensor([-0.7419, -0.6086, -0.2876])\n","Predicted tensor([-0.3458, -0.0477, -0.1596], grad_fn=<SelectBackward>) Actual tensor([ 1.1518, -0.1934, -0.2903])\n","Predicted tensor([ 0.6828, -0.2187, -0.2117], grad_fn=<SelectBackward>) Actual tensor([ 1.1451, -0.3362, -0.3379])\n","Predicted tensor([-0.7637, -0.5470, -0.0654], grad_fn=<SelectBackward>) Actual tensor([-0.7598, -0.7327, -0.2573])\n","Predicted tensor([0.5758, 0.6736, 0.1283], grad_fn=<SelectBackward>) Actual tensor([ 2.1914, -0.0909, -0.2804])\n","Predicted tensor([-0.9925, -0.5366,  4.5340], grad_fn=<SelectBackward>) Actual tensor([-1.0940, -0.6582,  5.1524])\n","Predicted tensor([0.7250, 0.5184, 0.0861], grad_fn=<SelectBackward>) Actual tensor([ 0.4489,  0.4265, -0.3182])\n","Predicted tensor([ 0.4931, -0.0714, -0.2292], grad_fn=<SelectBackward>) Actual tensor([ 1.8506,  0.3046, -0.3806])\n","Predicted tensor([ 0.4330,  0.3009, -0.0825], grad_fn=<SelectBackward>) Actual tensor([ 0.9631,  0.6308, -0.3252])\n","Predicted tensor([-0.7648,  0.0183, -0.1066], grad_fn=<SelectBackward>) Actual tensor([ 1.5954, -0.6725, -0.3079])\n","Predicted tensor([ 0.7147, -0.0506, -0.1472], grad_fn=<SelectBackward>) Actual tensor([ 0.4045,  0.2203, -0.1327])\n","Predicted tensor([ 0.6956, -0.3879, -0.2650], grad_fn=<SelectBackward>) Actual tensor([ 1.1123, -0.7643, -0.3294])\n","Predicted tensor([-0.6577, -0.1646, -0.1188], grad_fn=<SelectBackward>) Actual tensor([-0.1545, -0.3604, -0.3276])\n","Predicted tensor([-0.5901, -0.4250, -0.1065], grad_fn=<SelectBackward>) Actual tensor([-0.7098, -0.7919, -0.2845])\n","Predicted tensor([ 0.2186, -0.0703, -0.1037], grad_fn=<SelectBackward>) Actual tensor([ 0.1494, -0.5897, -0.2723])\n","Predicted tensor([ 0.5247,  0.1902, -0.1418], grad_fn=<SelectBackward>) Actual tensor([-1.7535,  0.0194,  0.1803])\n","Predicted tensor([-0.5764, -0.3208, -0.1164], grad_fn=<SelectBackward>) Actual tensor([-0.5391, -0.7547, -0.3260])\n","Predicted tensor([-0.0128, -0.3261, -0.1096], grad_fn=<SelectBackward>) Actual tensor([ 0.0780, -0.7959, -0.2610])\n","Predicted tensor([ 0.1957,  0.3708, -0.0990], grad_fn=<SelectBackward>) Actual tensor([-1.0148,  0.0981, -0.2858])\n","Predicted tensor([-0.3462, -0.4146, -0.1189], grad_fn=<SelectBackward>) Actual tensor([ 1.3793, -0.2397, -0.3449])\n","Predicted tensor([-0.7113, -0.4144, -0.0942], grad_fn=<SelectBackward>) Actual tensor([-0.8152, -0.5421, -0.3076])\n","Predicted tensor([0.4020, 1.5986, 0.0415], grad_fn=<SelectBackward>) Actual tensor([ 0.6507,  2.7584, -0.0233])\n","Predicted tensor([ 0.0139,  0.1864, -0.1349], grad_fn=<SelectBackward>) Actual tensor([-0.3133, -0.7964, -0.3172])\n","Predicted tensor([0.0244, 0.7976, 0.3357], grad_fn=<SelectBackward>) Actual tensor([-0.7179,  2.0472,  0.0792])\n","Predicted tensor([0.5705, 0.7950, 0.0313], grad_fn=<SelectBackward>) Actual tensor([ 1.4418,  2.8337, -0.1068])\n","Predicted tensor([0.7047, 0.4299, 0.1410], grad_fn=<SelectBackward>) Actual tensor([ 2.1325,  0.8009, -0.0173])\n","Predicted tensor([-0.6832, -0.3088, -0.1205], grad_fn=<SelectBackward>) Actual tensor([-0.8175, -0.6332, -0.2947])\n","Predicted tensor([ 0.0991, -0.2923, -0.1004], grad_fn=<SelectBackward>) Actual tensor([-0.5225, -0.7457, -0.2676])\n","Predicted tensor([ 0.2067, -0.3292, -0.1158], grad_fn=<SelectBackward>) Actual tensor([ 0.0303, -0.6282, -0.2722])\n","Predicted tensor([ 0.6678, -0.1697, -0.2320], grad_fn=<SelectBackward>) Actual tensor([ 1.4489, -0.6531, -0.3278])\n","Predicted tensor([-0.0444,  0.2377, -0.1096], grad_fn=<SelectBackward>) Actual tensor([-0.4536, -0.2494, -0.3164])\n","Predicted tensor([ 0.6803, -0.0569,  0.3950], grad_fn=<SelectBackward>) Actual tensor([ 2.1094, -0.5702,  0.2796])\n","Predicted tensor([ 0.2875, -0.4153, -0.1420], grad_fn=<SelectBackward>) Actual tensor([ 0.0591, -0.7790, -0.2662])\n","Predicted tensor([-0.6157, -0.5454, -0.0800], grad_fn=<SelectBackward>) Actual tensor([-0.5874, -0.6545, -0.2058])\n","Predicted tensor([ 0.1552,  0.7721, -0.0408], grad_fn=<SelectBackward>) Actual tensor([ 0.5295,  1.1866, -0.2965])\n","Predicted tensor([ 0.7272, -0.3764, -0.2647], grad_fn=<SelectBackward>) Actual tensor([ 1.2074, -0.1836, -0.3237])\n","Predicted tensor([ 0.0388, -0.1781, -0.1078], grad_fn=<SelectBackward>) Actual tensor([ 0.4849,  0.0080, -0.3129])\n","Predicted tensor([ 0.6965, -0.3710, -0.2597], grad_fn=<SelectBackward>) Actual tensor([ 1.1380, -0.6999, -0.3269])\n","Predicted tensor([ 0.3786,  0.6765, -0.0446], grad_fn=<SelectBackward>) Actual tensor([ 0.4003, -0.5307, -0.2216])\n","Predicted tensor([-0.7161, -0.4338, -0.1056], grad_fn=<SelectBackward>) Actual tensor([-0.8448, -0.4823, -0.2707])\n","Predicted tensor([ 0.4223, -0.0710, -0.2813], grad_fn=<SelectBackward>) Actual tensor([ 1.0716, -0.6473, -0.3357])\n","Predicted tensor([ 0.7149, -0.2142, -0.2027], grad_fn=<SelectBackward>) Actual tensor([ 1.1303, -0.2281, -0.3220])\n","Predicted tensor([ 0.3046,  0.0864, -0.2519], grad_fn=<SelectBackward>) Actual tensor([2.3679, 2.2181, 0.1588])\n","Predicted tensor([ 0.5898,  0.0146, -0.1737], grad_fn=<SelectBackward>) Actual tensor([ 1.2220, -0.4196, -0.2295])\n","Predicted tensor([-0.2150, -0.2846, -0.1256], grad_fn=<SelectBackward>) Actual tensor([ 1.5260,  0.0897, -0.3587])\n","Predicted tensor([-0.3556, -0.2579, -0.1144], grad_fn=<SelectBackward>) Actual tensor([-0.7722, -0.7558, -0.3165])\n","Predicted tensor([-0.6851, -0.3615, -0.1190], grad_fn=<SelectBackward>) Actual tensor([-0.8092, -0.6450, -0.3132])\n","Predicted tensor([-0.6657, -0.4625, -0.0972], grad_fn=<SelectBackward>) Actual tensor([-0.7327, -0.6709, -0.3188])\n","Predicted tensor([ 0.6344, -0.0835, -0.1613], grad_fn=<SelectBackward>) Actual tensor([ 0.0117,  1.6723, -0.0925])\n","Predicted tensor([ 0.0555, -0.2579, -0.1423], grad_fn=<SelectBackward>) Actual tensor([ 1.2624,  0.1098, -0.3593])\n","Predicted tensor([-0.6787, -0.4728, -0.1014], grad_fn=<SelectBackward>) Actual tensor([-0.7039,  0.7422, -0.1346])\n","Predicted tensor([-0.1262,  0.6699, -0.1416], grad_fn=<SelectBackward>) Actual tensor([-0.1086,  1.1016, -0.3313])\n","Predicted tensor([-0.5913, -0.4514, -0.1225], grad_fn=<SelectBackward>) Actual tensor([-0.7752, -0.2089, -0.2292])\n","Predicted tensor([ 0.0509, -0.2484, -0.1114], grad_fn=<SelectBackward>) Actual tensor([ 1.0865,  1.3201, -0.1817])\n","Predicted tensor([0.4516, 0.8485, 0.0339], grad_fn=<SelectBackward>) Actual tensor([ 1.0628,  2.7049, -0.2033])\n","Predicted tensor([ 0.3350, -0.1589, -0.1629], grad_fn=<SelectBackward>) Actual tensor([1.1454, 4.3290, 0.9593])\n","Predicted tensor([ 0.6068,  0.0380, -0.1850], grad_fn=<SelectBackward>) Actual tensor([-0.4412, -0.7842, -0.3009])\n","Predicted tensor([-0.1404, -0.3257, -0.1307], grad_fn=<SelectBackward>) Actual tensor([-0.6236,  0.9440, -0.1295])\n","Predicted tensor([ 0.1677,  0.6613, -0.0847], grad_fn=<SelectBackward>) Actual tensor([1.4193, 1.9218, 1.3827])\n","Predicted tensor([-0.7003, -0.3869, -0.1277], grad_fn=<SelectBackward>) Actual tensor([-0.6284, -0.7403, -0.2661])\n","Predicted tensor([ 0.0842, -0.3290, -0.1083], grad_fn=<SelectBackward>) Actual tensor([ 0.6269, -0.2395, -0.2302])\n","Predicted tensor([ 0.6373, -0.1706, -0.2089], grad_fn=<SelectBackward>) Actual tensor([ 1.5551, -0.5138, -0.2977])\n","Predicted tensor([-0.5193, -0.3737, -0.1420], grad_fn=<SelectBackward>) Actual tensor([-0.6753, -0.0874, -0.1797])\n","Predicted tensor([0.7982, 0.4755, 0.0088], grad_fn=<SelectBackward>) Actual tensor([ 1.0900, -0.4183, -0.3325])\n","Predicted tensor([-0.5860, -0.5608, -0.0945], grad_fn=<SelectBackward>) Actual tensor([-0.7802, -0.5292, -0.2745])\n","Predicted tensor([-0.4233, -0.3396, -0.0939], grad_fn=<SelectBackward>) Actual tensor([-0.7412, -0.7789, -0.2978])\n","Predicted tensor([-0.3746, -0.1803, -0.1467], grad_fn=<SelectBackward>) Actual tensor([-0.6699,  0.7197, -0.0268])\n","Predicted tensor([-0.5565,  0.4769, -0.1484], grad_fn=<SelectBackward>) Actual tensor([-1.1975, -0.7570, -0.3681])\n","Predicted tensor([-0.6128, -0.3915, -0.1287], grad_fn=<SelectBackward>) Actual tensor([-0.7255, -0.6145, -0.2867])\n","Predicted tensor([-0.0785, -0.2104, -0.1009], grad_fn=<SelectBackward>) Actual tensor([-0.8245, -0.6752, -0.3086])\n","Predicted tensor([ 0.2465, -0.3938, -0.1106], grad_fn=<SelectBackward>) Actual tensor([-1.2732, -0.3065, -0.0349])\n","Predicted tensor([0.0779, 0.3473, 0.2301], grad_fn=<SelectBackward>) Actual tensor([-0.5598, -0.6394, -0.3122])\n","Predicted tensor([-1.5227,  0.4389,  0.0405], grad_fn=<SelectBackward>) Actual tensor([-1.8622, -0.2409, -0.3605])\n","Predicted tensor([-0.3434, -0.4225, -0.1367], grad_fn=<SelectBackward>) Actual tensor([ 1.1047, -0.7933, -0.3303])\n","Predicted tensor([-0.6768, -0.4916, -0.0852], grad_fn=<SelectBackward>) Actual tensor([-0.9093,  0.1308, -0.1909])\n","Predicted tensor([ 0.6865, -0.3196, -0.2411], grad_fn=<SelectBackward>) Actual tensor([-0.3230, -0.7100, -0.2850])\n","Predicted tensor([-0.3065,  0.9936,  0.6822], grad_fn=<SelectBackward>) Actual tensor([0.1163, 3.4289, 1.8012])\n","Predicted tensor([-0.3992,  0.3472, -0.1941], grad_fn=<SelectBackward>) Actual tensor([-1.9988, -0.2369, -0.5259])\n","Predicted tensor([ 0.6747, -0.1474, -0.2495], grad_fn=<SelectBackward>) Actual tensor([-0.6462, -0.6567, -0.3016])\n","Predicted tensor([-0.5242, -0.1185, -0.1336], grad_fn=<SelectBackward>) Actual tensor([-0.3997, -0.4833, -0.2603])\n","Predicted tensor([-0.6331, -0.3700, -0.1258], grad_fn=<SelectBackward>) Actual tensor([-0.8134, -0.7901, -0.2783])\n","Predicted tensor([-0.3282, -0.4383, -0.0917], grad_fn=<SelectBackward>) Actual tensor([-1.0482, -0.3560, -0.0655])\n","Predicted tensor([ 0.4138, -0.4264, -0.1602], grad_fn=<SelectBackward>) Actual tensor([-0.5491, -0.0677, -0.2191])\n","Predicted tensor([-0.5249, -0.4777, -0.0910], grad_fn=<SelectBackward>) Actual tensor([ 0.9084,  2.4829, -0.1354])\n","Predicted tensor([-0.0017,  0.0976, -0.0692], grad_fn=<SelectBackward>) Actual tensor([ 1.2221,  0.1901, -0.3508])\n","Predicted tensor([-0.9035, -0.2953,  4.3501], grad_fn=<SelectBackward>) Actual tensor([-0.8382,  0.1098,  4.5460])\n","Predicted tensor([-0.7808, -0.4881, -0.0767], grad_fn=<SelectBackward>) Actual tensor([-0.8273, -0.5512, -0.2535])\n","Predicted tensor([-0.9637, -0.4118,  4.5174], grad_fn=<SelectBackward>) Actual tensor([-1.1059, -0.5293,  5.0648])\n","Predicted tensor([-0.4278,  0.4313,  3.5159], grad_fn=<SelectBackward>) Actual tensor([0.2990, 1.9882, 4.4021])\n","Predicted tensor([ 0.7584,  0.0106, -0.1098], grad_fn=<SelectBackward>) Actual tensor([ 0.2191,  0.5108, -0.2561])\n","Predicted tensor([ 0.7003, -0.3617, -0.2551], grad_fn=<SelectBackward>) Actual tensor([ 0.6014,  0.5289, -0.2620])\n","Predicted tensor([-0.0058,  0.2804, -0.1587], grad_fn=<SelectBackward>) Actual tensor([-0.1289, -0.6567, -0.3125])\n","Predicted tensor([ 0.6677, -0.1741, -0.2390], grad_fn=<SelectBackward>) Actual tensor([ 1.0782, -0.4586, -0.3406])\n","Predicted tensor([ 0.0900, -0.3100, -0.1266], grad_fn=<SelectBackward>) Actual tensor([-0.1052,  0.2182, -0.2086])\n","Predicted tensor([0.7577, 0.4276, 0.0650], grad_fn=<SelectBackward>) Actual tensor([-0.7901, -0.3996, -0.2577])\n","Predicted tensor([-1.1235,  0.4035, -0.0750], grad_fn=<SelectBackward>) Actual tensor([-1.6623, -0.3001, -0.5504])\n","Predicted tensor([0.3972, 1.1650, 0.0710], grad_fn=<SelectBackward>) Actual tensor([-0.2348, -0.7888, -0.3310])\n","Predicted tensor([-0.5416,  0.5606, -0.1854], grad_fn=<SelectBackward>) Actual tensor([-1.3689, -0.0540, -0.3723])\n","Predicted tensor([-0.6489, -0.3105, -0.0729], grad_fn=<SelectBackward>) Actual tensor([0.3720, 1.5134, 3.0663])\n","Predicted tensor([-0.9460, -0.4156,  4.5077], grad_fn=<SelectBackward>) Actual tensor([-1.0719, -0.7903,  5.1426])\n","Predicted tensor([ 0.1543, -0.2310, -0.1321], grad_fn=<SelectBackward>) Actual tensor([ 1.4258,  1.7141, -0.3441])\n","Predicted tensor([ 0.0537,  0.0321, -0.1102], grad_fn=<SelectBackward>) Actual tensor([-0.4760, -0.7604, -0.2999])\n","Predicted tensor([ 0.4595,  0.0944, -0.1438], grad_fn=<SelectBackward>) Actual tensor([-0.0448, -0.2682, -0.2162])\n","Predicted tensor([-0.1736,  0.3854,  2.3397], grad_fn=<SelectBackward>) Actual tensor([-0.4065, -0.7118, -0.3278])\n","Predicted tensor([ 0.2379,  0.6768, -0.0331], grad_fn=<SelectBackward>) Actual tensor([ 0.7400,  1.2280, -0.2657])\n","Predicted tensor([0.2071, 0.2477, 0.4394], grad_fn=<SelectBackward>) Actual tensor([ 0.7598,  0.9583, -0.3596])\n","Predicted tensor([ 0.6926, -0.3729, -0.2565], grad_fn=<SelectBackward>) Actual tensor([ 1.2096, -0.5821, -0.3447])\n","Predicted tensor([ 0.7018, -0.3809, -0.2372], grad_fn=<SelectBackward>) Actual tensor([ 1.1092, -0.7894, -0.3294])\n","Predicted tensor([-0.1442, -0.3960, -0.1042], grad_fn=<SelectBackward>) Actual tensor([ 1.8359,  2.0508, -0.2202])\n","Predicted tensor([ 0.6219,  0.1622, -0.1324], grad_fn=<SelectBackward>) Actual tensor([ 1.4657,  0.3203, -0.2897])\n","Predicted tensor([ 0.1531,  0.0343, -0.1334], grad_fn=<SelectBackward>) Actual tensor([ 1.1187, -0.0044, -0.3489])\n","Predicted tensor([ 0.3332,  0.0664, -0.0781], grad_fn=<SelectBackward>) Actual tensor([ 1.1013, -0.5158, -0.3370])\n","Predicted tensor([1.0268, 0.5612, 0.6782], grad_fn=<SelectBackward>) Actual tensor([-0.7005, -0.6767, -0.3182])\n","Predicted tensor([ 0.0834, -0.2961, -0.1094], grad_fn=<SelectBackward>) Actual tensor([ 1.1225, -0.3574, -0.3432])\n","Predicted tensor([0.9434, 0.7053, 0.7255], grad_fn=<SelectBackward>) Actual tensor([-0.2154,  0.0150,  0.4049])\n","Predicted tensor([ 0.6719, -0.1645, -0.2395], grad_fn=<SelectBackward>) Actual tensor([ 0.1608,  1.6517, -0.1770])\n","Predicted tensor([ 0.7035, -0.3380, -0.2512], grad_fn=<SelectBackward>) Actual tensor([ 1.1510, -0.6422, -0.3263])\n","Predicted tensor([-0.7192, -0.4979, -0.0837], grad_fn=<SelectBackward>) Actual tensor([-0.8066, -0.3616, -0.2724])\n","Predicted tensor([-0.1676,  1.2575,  0.6721], grad_fn=<SelectBackward>) Actual tensor([-0.6085, -0.7138, -0.3246])\n","Predicted tensor([ 0.2069,  0.4479, -0.1050], grad_fn=<SelectBackward>) Actual tensor([-0.3114, -0.5266, -0.3293])\n","Predicted tensor([ 0.4473,  0.1100, -0.1271], grad_fn=<SelectBackward>) Actual tensor([ 0.3415,  1.0263, -0.2531])\n","Predicted tensor([ 0.7188, -0.3298, -0.2669], grad_fn=<SelectBackward>) Actual tensor([ 1.1150, -0.6918, -0.3265])\n","Predicted tensor([-1.0297, -0.6832,  4.4723], grad_fn=<SelectBackward>) Actual tensor([-0.2288,  2.5296,  1.8763])\n","Predicted tensor([ 0.5426,  0.0268, -0.1477], grad_fn=<SelectBackward>) Actual tensor([ 1.0265, -0.0584, -0.2732])\n","Batch: 7 completed\n","Predicted tensor([-0.4787, -0.5371, -0.1030], grad_fn=<SelectBackward>) Actual tensor([-0.6940, -0.7806, -0.2091])\n","Predicted tensor([-0.7897,  0.1697, -0.0673], grad_fn=<SelectBackward>) Actual tensor([-0.2467,  0.9482, -0.3010])\n","Predicted tensor([-0.0623, -0.3615, -0.1247], grad_fn=<SelectBackward>) Actual tensor([-0.4304, -0.7298, -0.2029])\n","Predicted tensor([ 0.6116, -0.2262, -0.1988], grad_fn=<SelectBackward>) Actual tensor([ 1.0796, -0.6658, -0.3392])\n","Predicted tensor([-0.5962, -0.3606, -0.1064], grad_fn=<SelectBackward>) Actual tensor([-0.3823, -0.6465,  0.2813])\n","Predicted tensor([ 0.0258, -0.3526, -0.1028], grad_fn=<SelectBackward>) Actual tensor([ 0.4441, -0.3608, -0.1921])\n","Predicted tensor([ 0.0895, -0.3185, -0.1045], grad_fn=<SelectBackward>) Actual tensor([-0.2219, -0.7890, -0.3106])\n","Predicted tensor([ 0.7849, -0.1925, -0.1651], grad_fn=<SelectBackward>) Actual tensor([ 1.4108, -0.6635, -0.1804])\n","Predicted tensor([-0.5458,  0.8516,  3.0547], grad_fn=<SelectBackward>) Actual tensor([-0.5193,  1.1120,  4.2007])\n","Predicted tensor([ 0.4219,  0.2285, -0.1465], grad_fn=<SelectBackward>) Actual tensor([-0.3822,  1.8898, -0.3734])\n","Predicted tensor([-0.7074, -0.3396, -0.1006], grad_fn=<SelectBackward>) Actual tensor([-0.8556, -0.6325, -0.3054])\n","Predicted tensor([ 0.2260,  0.5167, -0.0642], grad_fn=<SelectBackward>) Actual tensor([ 1.1671,  0.5562, -0.3246])\n","Predicted tensor([-0.3791, -0.1508, -0.1326], grad_fn=<SelectBackward>) Actual tensor([-0.4802, -0.6403, -0.3168])\n","Predicted tensor([ 0.1789, -0.0725, -0.1409], grad_fn=<SelectBackward>) Actual tensor([ 1.1693, -0.5611, -0.3327])\n","Predicted tensor([-0.5371, -0.3016, -0.1022], grad_fn=<SelectBackward>) Actual tensor([-0.1737, -0.1190, -0.3413])\n","Predicted tensor([ 0.6926, -0.4106, -0.3038], grad_fn=<SelectBackward>) Actual tensor([-0.0514, -0.7807, -0.2880])\n","Predicted tensor([ 0.6925, -0.3978, -0.2655], grad_fn=<SelectBackward>) Actual tensor([ 1.1741, -0.7731, -0.3028])\n","Predicted tensor([ 0.2998,  1.7704, -0.0723], grad_fn=<SelectBackward>) Actual tensor([ 9.7636e-01,  4.2621e+00, -1.3609e-03])\n","Predicted tensor([-0.4364, -0.4522, -0.1165], grad_fn=<SelectBackward>) Actual tensor([-0.8488,  0.5369, -0.1278])\n","Predicted tensor([ 0.0506, -0.3972, -0.0823], grad_fn=<SelectBackward>) Actual tensor([ 0.8935,  0.7403, -0.2206])\n","Predicted tensor([ 0.0786, -0.1426, -0.1067], grad_fn=<SelectBackward>) Actual tensor([ 1.2921, -0.5960, -0.3154])\n","Predicted tensor([-0.2598,  1.1261,  0.8399], grad_fn=<SelectBackward>) Actual tensor([-0.1712,  0.5928,  1.2030])\n","Predicted tensor([-0.0249, -0.3486, -0.1282], grad_fn=<SelectBackward>) Actual tensor([-0.2741, -0.0579, -0.1686])\n","Predicted tensor([-0.7803, -0.1621, -0.0814], grad_fn=<SelectBackward>) Actual tensor([ 1.1104, -0.7831, -0.3286])\n","Predicted tensor([-0.0786, -0.3544, -0.1191], grad_fn=<SelectBackward>) Actual tensor([ 1.0243,  1.0849, -0.1642])\n","Predicted tensor([-0.1417, -0.4111, -0.1003], grad_fn=<SelectBackward>) Actual tensor([-0.5582, -0.7349, -0.2950])\n","Predicted tensor([-0.3378, -0.4247, -0.0722], grad_fn=<SelectBackward>) Actual tensor([-0.6423,  0.9877, -0.0593])\n","Predicted tensor([-0.0731,  1.0648,  0.6841], grad_fn=<SelectBackward>) Actual tensor([0.8377, 5.2837, 2.7520])\n","Predicted tensor([ 0.4242,  0.3692, -0.1141], grad_fn=<SelectBackward>) Actual tensor([ 0.9499,  0.1953, -0.3134])\n","Predicted tensor([-0.6836, -0.4798, -0.1144], grad_fn=<SelectBackward>) Actual tensor([-0.6741, -0.6846, -0.2567])\n","Predicted tensor([ 0.1102,  2.0371, -0.2850], grad_fn=<SelectBackward>) Actual tensor([ 0.3245,  2.8300, -0.2074])\n","Predicted tensor([-0.2985, -0.3812, -0.1383], grad_fn=<SelectBackward>) Actual tensor([-0.1375,  0.9421, -0.0996])\n","Predicted tensor([-0.2101,  0.1286, -0.0845], grad_fn=<SelectBackward>) Actual tensor([-0.1892, -0.2014, -0.3469])\n","Predicted tensor([0.2971, 0.2507, 0.0542], grad_fn=<SelectBackward>) Actual tensor([-0.4007, -0.6960, -0.3161])\n","Predicted tensor([ 0.0413, -0.3364, -0.0989], grad_fn=<SelectBackward>) Actual tensor([-0.2638, -0.6489, -0.3222])\n","Predicted tensor([ 0.0624, -0.1297,  0.4207], grad_fn=<SelectBackward>) Actual tensor([-0.4470, -0.7284, -0.3085])\n","Predicted tensor([-0.6116, -0.3299, -0.1075], grad_fn=<SelectBackward>) Actual tensor([-0.4329, -0.5697, -0.3322])\n","Predicted tensor([-0.6663, -0.5310, -0.0920], grad_fn=<SelectBackward>) Actual tensor([-0.8497, -0.6353, -0.2750])\n","Predicted tensor([-0.3127, -0.0574, -0.1700], grad_fn=<SelectBackward>) Actual tensor([-0.1539, -0.5483, -0.3206])\n","Predicted tensor([-0.0400,  0.2700, -0.1050], grad_fn=<SelectBackward>) Actual tensor([-1.2468,  0.6778,  0.2620])\n","Predicted tensor([ 0.1840, -0.2715, -0.1310], grad_fn=<SelectBackward>) Actual tensor([-0.6042, -0.7130, -0.2913])\n","Predicted tensor([ 0.1431, -0.2103, -0.1106], grad_fn=<SelectBackward>) Actual tensor([-1.6410, -0.4198,  0.2970])\n","Predicted tensor([-0.3505, -0.0128, -0.1051], grad_fn=<SelectBackward>) Actual tensor([-0.6763, -0.7096, -0.3229])\n","Predicted tensor([ 0.6975, -0.3844, -0.2627], grad_fn=<SelectBackward>) Actual tensor([ 1.1105, -0.7837, -0.3296])\n","Predicted tensor([-0.6051, -0.3675, -0.1236], grad_fn=<SelectBackward>) Actual tensor([-0.5882, -0.7955, -0.3271])\n","Predicted tensor([-1.0045,  0.6459, -0.1316], grad_fn=<SelectBackward>) Actual tensor([-2.0241, -0.4345, -0.4053])\n","Predicted tensor([-0.4321, -0.2643, -0.1048], grad_fn=<SelectBackward>) Actual tensor([-1.0578,  1.6321,  1.2008])\n","Predicted tensor([0.9495, 0.3515, 0.6075], grad_fn=<SelectBackward>) Actual tensor([-0.7097, -0.5503, -0.2624])\n","Predicted tensor([-0.4187,  1.1988,  2.3998], grad_fn=<SelectBackward>) Actual tensor([0.3173, 3.0249, 2.6849])\n","Predicted tensor([ 0.6240, -0.3430, -0.2911], grad_fn=<SelectBackward>) Actual tensor([ 1.1170, -0.6636, -0.3282])\n","Predicted tensor([-0.4246, -0.4218, -0.1123], grad_fn=<SelectBackward>) Actual tensor([ 1.8210,  0.3677, -0.3741])\n","Predicted tensor([-0.6818, -0.3844, -0.1178], grad_fn=<SelectBackward>) Actual tensor([-0.3701, -0.7346, -0.2212])\n","Predicted tensor([ 0.2272,  1.0422, -0.0564], grad_fn=<SelectBackward>) Actual tensor([ 1.0013,  1.4279, -0.3079])\n","Predicted tensor([-0.4748, -0.2633, -0.1408], grad_fn=<SelectBackward>) Actual tensor([ 0.5479,  1.1352, -0.1500])\n","Predicted tensor([-0.5894,  0.1169, -0.1047], grad_fn=<SelectBackward>) Actual tensor([-0.6499, -0.0319, -0.3330])\n","Predicted tensor([ 0.6899, -0.3444, -0.1988], grad_fn=<SelectBackward>) Actual tensor([ 1.0808, -0.4628, -0.3311])\n","Predicted tensor([0.7052, 0.4486, 0.0285], grad_fn=<SelectBackward>) Actual tensor([ 1.7688,  1.8313, -0.2074])\n","Predicted tensor([-0.4566, -0.4806, -0.1226], grad_fn=<SelectBackward>) Actual tensor([-0.8282, -0.1312, -0.2269])\n","Predicted tensor([-0.5724, -0.3454, -0.0874], grad_fn=<SelectBackward>) Actual tensor([-1.3072,  0.3537,  1.9732])\n","Predicted tensor([ 0.1278,  0.1331, -0.1071], grad_fn=<SelectBackward>) Actual tensor([ 0.3339, -0.1397, -0.3231])\n","Predicted tensor([-0.3727, -0.1441, -0.1587], grad_fn=<SelectBackward>) Actual tensor([-0.5952, -0.7374, -0.2790])\n","Predicted tensor([-0.7212, -0.3843, -0.0953], grad_fn=<SelectBackward>) Actual tensor([-0.7886, -0.5216, -0.2741])\n","Predicted tensor([ 0.1530, -0.2872, -0.1167], grad_fn=<SelectBackward>) Actual tensor([ 0.0865, -0.2075, -0.2433])\n","Predicted tensor([ 0.0284,  0.1097, -0.0954], grad_fn=<SelectBackward>) Actual tensor([-0.2473, -0.1110, -0.3379])\n","Predicted tensor([-0.1192,  1.0968,  0.8645], grad_fn=<SelectBackward>) Actual tensor([0.5454, 4.6964, 3.4379])\n","Predicted tensor([-0.0030,  0.2472, -0.1094], grad_fn=<SelectBackward>) Actual tensor([-0.5659,  0.1040, -0.3026])\n","Predicted tensor([ 0.6643, -0.2968, -0.2006], grad_fn=<SelectBackward>) Actual tensor([ 1.1027, -0.7205, -0.3340])\n","Predicted tensor([-0.5439, -0.4100, -0.1478], grad_fn=<SelectBackward>) Actual tensor([-0.5211, -0.1882, -0.2515])\n","Predicted tensor([-0.7086, -0.4906, -0.0827], grad_fn=<SelectBackward>) Actual tensor([-0.7775, -0.7775, -0.2630])\n","Predicted tensor([ 0.2568, -0.3823,  0.0033], grad_fn=<SelectBackward>) Actual tensor([-0.9566, -0.6814, -0.1230])\n","Predicted tensor([-0.4686, -0.4242, -0.1045], grad_fn=<SelectBackward>) Actual tensor([-0.3245, -0.1684, -0.3410])\n","Predicted tensor([-0.7125, -0.4060, -0.1035], grad_fn=<SelectBackward>) Actual tensor([-0.8557, -0.4353, -0.2715])\n","Predicted tensor([ 0.2221, -0.1480, -0.1308], grad_fn=<SelectBackward>) Actual tensor([ 1.2090, -0.3131, -0.3409])\n","Predicted tensor([-0.6841, -0.3495, -0.1306], grad_fn=<SelectBackward>) Actual tensor([-0.8713, -0.5653, -0.2779])\n","Predicted tensor([-0.5713, -0.5093, -0.0936], grad_fn=<SelectBackward>) Actual tensor([-0.9271, -0.4096, -0.2461])\n","Predicted tensor([-0.0498, -0.2236, -0.1126], grad_fn=<SelectBackward>) Actual tensor([ 1.1025, -0.6409, -0.3349])\n","Predicted tensor([0.7286, 0.2901, 0.0026], grad_fn=<SelectBackward>) Actual tensor([ 1.8046,  0.4435, -0.1585])\n","Predicted tensor([-0.6848, -0.3052, -0.1235], grad_fn=<SelectBackward>) Actual tensor([-0.8415, -0.6342, -0.2828])\n","Predicted tensor([ 0.5985,  0.0340, -0.1162], grad_fn=<SelectBackward>) Actual tensor([-0.3750, -0.5690, -0.2588])\n","Predicted tensor([0.1582, 0.9585, 0.5983], grad_fn=<SelectBackward>) Actual tensor([-0.6783,  0.4692,  1.0900])\n","Predicted tensor([ 0.2410,  0.5135, -0.1797], grad_fn=<SelectBackward>) Actual tensor([-0.3544, -0.6276, -0.3219])\n","Predicted tensor([ 0.7333, -0.2714, -0.2347], grad_fn=<SelectBackward>) Actual tensor([ 1.1214, -0.5796, -0.3273])\n","Predicted tensor([-0.8386, -0.3424,  4.1367], grad_fn=<SelectBackward>) Actual tensor([-0.1108,  0.4087,  5.0121])\n","Predicted tensor([-0.6535, -0.3402, -0.1358], grad_fn=<SelectBackward>) Actual tensor([-0.8055, -0.5569, -0.2416])\n","Predicted tensor([ 0.6945, -0.2905, -0.2430], grad_fn=<SelectBackward>) Actual tensor([ 1.1948, -0.5784, -0.3265])\n","Predicted tensor([-0.0149,  0.4812, -0.0650], grad_fn=<SelectBackward>) Actual tensor([-0.2516,  1.0959, -0.2865])\n","Predicted tensor([-0.9734, -0.4874,  4.5258], grad_fn=<SelectBackward>) Actual tensor([-1.0646, -0.7659,  5.1429])\n","Predicted tensor([-0.6227, -0.3525, -0.1237], grad_fn=<SelectBackward>) Actual tensor([ 0.1403, -0.7376, -0.3301])\n","Predicted tensor([-0.1199, -0.3285, -0.1069], grad_fn=<SelectBackward>) Actual tensor([-0.5824, -0.7553, -0.3007])\n","Predicted tensor([ 0.5829,  0.1187, -0.1666], grad_fn=<SelectBackward>) Actual tensor([-0.4478, -0.6936, -0.2939])\n","Predicted tensor([ 0.6663, -0.2692, -0.2111], grad_fn=<SelectBackward>) Actual tensor([-0.4081, -0.5466, -0.3358])\n","Predicted tensor([ 0.7358, -0.0752, -0.1796], grad_fn=<SelectBackward>) Actual tensor([ 1.1103, -0.7608, -0.3297])\n","Predicted tensor([ 0.6092, -0.0807, -0.2284], grad_fn=<SelectBackward>) Actual tensor([2.3198, 1.4516, 0.0066])\n","Predicted tensor([-0.6514, -0.5801, -0.0677], grad_fn=<SelectBackward>) Actual tensor([-0.8050, -0.5897, -0.2658])\n","Predicted tensor([-0.6501, -0.1466, -0.1060], grad_fn=<SelectBackward>) Actual tensor([-0.6530, -0.7640, -0.3442])\n","Predicted tensor([-1.0474,  0.4881, -0.1069], grad_fn=<SelectBackward>) Actual tensor([-0.5684,  1.8817, -0.3843])\n","Predicted tensor([ 0.2488,  0.6837, -0.0741], grad_fn=<SelectBackward>) Actual tensor([ 1.2817,  0.0532, -0.3574])\n","Predicted tensor([ 0.6951, -0.2288, -0.2422], grad_fn=<SelectBackward>) Actual tensor([ 1.1158, -0.5322, -0.3235])\n","Predicted tensor([-0.1834, -0.1892, -0.1318], grad_fn=<SelectBackward>) Actual tensor([-0.3756, -0.5994, -0.3279])\n","Predicted tensor([-1.1429,  0.6831, -0.0843], grad_fn=<SelectBackward>) Actual tensor([ 1.0384,  0.8627, -0.3215])\n","Predicted tensor([ 0.1742, -0.0814, -0.1680], grad_fn=<SelectBackward>) Actual tensor([ 1.1133, -0.7543, -0.3282])\n","Predicted tensor([-0.0557, -0.3988, -0.1027], grad_fn=<SelectBackward>) Actual tensor([-0.4489, -0.7395, -0.1996])\n","Predicted tensor([-0.5038, -0.3215, -0.0865], grad_fn=<SelectBackward>) Actual tensor([-0.6176, -0.7524, -0.3247])\n","Predicted tensor([ 0.7607, -0.4385, -0.2824], grad_fn=<SelectBackward>) Actual tensor([ 1.2813, -0.5081, -0.3054])\n","Predicted tensor([-0.3128,  0.7741, -0.2340], grad_fn=<SelectBackward>) Actual tensor([ 0.0043,  1.5528, -0.3239])\n","Predicted tensor([-0.5340, -0.4952, -0.1112], grad_fn=<SelectBackward>) Actual tensor([-0.8541, -0.7815, -0.2811])\n","Predicted tensor([ 0.1781, -0.1268, -0.1157], grad_fn=<SelectBackward>) Actual tensor([-0.2953,  1.1658, -0.1970])\n","Predicted tensor([-0.1974, -0.3832, -0.1071], grad_fn=<SelectBackward>) Actual tensor([-0.2179, -0.7900, -0.2584])\n","Predicted tensor([ 0.1899, -0.2238, -0.1159], grad_fn=<SelectBackward>) Actual tensor([-0.7534, -0.5858, -0.3107])\n","Predicted tensor([ 0.5369,  0.1773, -0.1730], grad_fn=<SelectBackward>) Actual tensor([ 1.5685,  0.0044, -0.3614])\n","Predicted tensor([ 0.1157, -0.1779, -0.1477], grad_fn=<SelectBackward>) Actual tensor([-2.2449,  0.1326,  0.1142])\n","Predicted tensor([-0.7261, -0.4572, -0.0761], grad_fn=<SelectBackward>) Actual tensor([-0.7370, -0.5255, -0.2979])\n","Predicted tensor([0.1854, 0.3276, 0.2398], grad_fn=<SelectBackward>) Actual tensor([1.8187, 3.0181, 0.1522])\n","Predicted tensor([ 0.6598, -0.2979, -0.2031], grad_fn=<SelectBackward>) Actual tensor([ 0.1943, -0.6696, -0.3101])\n","Predicted tensor([-0.1682,  0.3498, -0.2288], grad_fn=<SelectBackward>) Actual tensor([ 0.0853, -0.2597, -0.3108])\n","Predicted tensor([-0.6663, -0.5464, -0.0797], grad_fn=<SelectBackward>) Actual tensor([-0.8235, -0.7240, -0.2819])\n","Predicted tensor([ 0.6538, -0.2121, -0.2142], grad_fn=<SelectBackward>) Actual tensor([ 1.1102, -0.6840, -0.3321])\n","Predicted tensor([ 0.6753, -0.1805, -0.2252], grad_fn=<SelectBackward>) Actual tensor([ 0.3625,  0.8217, -0.2444])\n","Predicted tensor([-0.8920,  0.5106, -0.1195], grad_fn=<SelectBackward>) Actual tensor([-1.2669,  1.2490, -0.3164])\n","Predicted tensor([-0.2944, -0.4761, -0.1082], grad_fn=<SelectBackward>) Actual tensor([-0.8475, -0.3423, -0.2507])\n","Predicted tensor([-0.4539, -0.3602, -0.1035], grad_fn=<SelectBackward>) Actual tensor([-0.5021, -0.7630, -0.3172])\n","Predicted tensor([-0.8436,  0.3036, -0.1150], grad_fn=<SelectBackward>) Actual tensor([-1.2288, -0.4198, -0.3662])\n","Predicted tensor([-0.6748, -0.1617, -0.1285], grad_fn=<SelectBackward>) Actual tensor([-0.3818, -0.1891, -0.3413])\n","Predicted tensor([-0.6287, -0.3715, -0.1301], grad_fn=<SelectBackward>) Actual tensor([-0.8237, -0.7867, -0.2770])\n","Predicted tensor([-0.4976, -0.2562, -0.0936], grad_fn=<SelectBackward>) Actual tensor([-0.7299, -0.7525, -0.3272])\n","Predicted tensor([ 0.1483, -0.1865, -0.1170], grad_fn=<SelectBackward>) Actual tensor([-0.2727, -0.4503, -0.3303])\n","Predicted tensor([ 0.7072, -0.3306, -0.2505], grad_fn=<SelectBackward>) Actual tensor([ 1.1229, -0.6515, -0.3279])\n","Predicted tensor([-0.7846, -0.4518, -0.0958], grad_fn=<SelectBackward>) Actual tensor([-0.7538, -0.7397, -0.2703])\n","Predicted tensor([-0.6187, -0.4434, -0.0981], grad_fn=<SelectBackward>) Actual tensor([-0.9814, -0.5586, -0.0703])\n","Predicted tensor([ 0.6233, -0.2283, -0.1895], grad_fn=<SelectBackward>) Actual tensor([ 1.2150, -0.5760, -0.3285])\n","Predicted tensor([ 0.2172, -0.3494, -0.1209], grad_fn=<SelectBackward>) Actual tensor([-0.6508, -0.7804, -0.2999])\n","Predicted tensor([ 0.7229, -0.3431, -0.2609], grad_fn=<SelectBackward>) Actual tensor([ 1.1065, -0.7863, -0.3286])\n","Predicted tensor([ 0.6809, -0.2665, -0.2448], grad_fn=<SelectBackward>) Actual tensor([-0.1748, -0.6690, -0.2699])\n","Predicted tensor([ 0.2971,  0.4274, -0.0990], grad_fn=<SelectBackward>) Actual tensor([ 1.1162, -0.5746, -0.3369])\n","Predicted tensor([-0.4027, -0.2556, -0.1344], grad_fn=<SelectBackward>) Actual tensor([ 0.8698, -0.2883, -0.3588])\n","Predicted tensor([ 0.0376, -0.2369, -0.1110], grad_fn=<SelectBackward>) Actual tensor([-0.4631, -0.7370, -0.3191])\n","Predicted tensor([ 0.1344, -0.1830, -0.1413], grad_fn=<SelectBackward>) Actual tensor([ 1.1753, -0.5474, -0.3363])\n","Predicted tensor([-0.6453, -0.1663, -0.0785], grad_fn=<SelectBackward>) Actual tensor([-0.5295, -0.6650, -0.2872])\n","Predicted tensor([-0.4229,  1.3249,  1.2645], grad_fn=<SelectBackward>) Actual tensor([0.2647, 2.0458, 1.0498])\n","Predicted tensor([-0.4433, -0.2036, -0.1462], grad_fn=<SelectBackward>) Actual tensor([-0.8821, -0.6788, -0.3491])\n","Predicted tensor([-0.4191, -0.5035, -0.0869], grad_fn=<SelectBackward>) Actual tensor([-0.3078, -0.0018, -0.2058])\n","Predicted tensor([ 0.3933,  0.3063, -0.1515], grad_fn=<SelectBackward>) Actual tensor([ 1.9195,  0.9417, -0.3591])\n","Predicted tensor([-0.0735, -0.2121, -0.1666], grad_fn=<SelectBackward>) Actual tensor([-0.4383, -0.5199, -0.2449])\n","Predicted tensor([ 0.1452, -0.1737, -0.1194], grad_fn=<SelectBackward>) Actual tensor([ 0.7399, -0.4765, -0.3574])\n","Predicted tensor([-1.8553, -0.0927,  0.5881], grad_fn=<SelectBackward>) Actual tensor([-2.7163,  2.5758, -0.0824])\n","Predicted tensor([-0.3877,  0.7127, -0.2144], grad_fn=<SelectBackward>) Actual tensor([-1.4563,  0.3495, -0.3711])\n","Predicted tensor([ 0.2191, -0.2770, -0.1550], grad_fn=<SelectBackward>) Actual tensor([ 0.1671, -0.0079, -0.2494])\n","Predicted tensor([ 0.6851, -0.3129, -0.2495], grad_fn=<SelectBackward>) Actual tensor([-0.4352, -0.6788, -0.2664])\n","Predicted tensor([ 0.6014,  0.8738, -0.0365], grad_fn=<SelectBackward>) Actual tensor([-2.2421, -0.7216,  0.1727])\n","Predicted tensor([-0.2726, -0.3558, -0.1189], grad_fn=<SelectBackward>) Actual tensor([-0.6093, -0.7827, -0.3135])\n","Predicted tensor([-0.6373, -0.5445, -0.0821], grad_fn=<SelectBackward>) Actual tensor([-0.8370, -0.7237, -0.2678])\n","Predicted tensor([0.6993, 0.3397, 0.0493], grad_fn=<SelectBackward>) Actual tensor([-0.4204, -0.7460, -0.3129])\n","Predicted tensor([ 0.7089, -0.3067, -0.2247], grad_fn=<SelectBackward>) Actual tensor([ 1.1858, -0.4712, -0.2995])\n","Predicted tensor([-1.1754,  0.3903, -0.0873], grad_fn=<SelectBackward>) Actual tensor([-1.9404, -0.0548, -0.5390])\n","Predicted tensor([-0.8798,  0.7378, -0.1947], grad_fn=<SelectBackward>) Actual tensor([-1.1597,  0.7528, -0.3498])\n","Predicted tensor([ 0.6329, -0.3362, -0.1678], grad_fn=<SelectBackward>) Actual tensor([ 1.5242, -0.2708, -0.3513])\n","Predicted tensor([-0.9706, -0.0097,  0.2526], grad_fn=<SelectBackward>) Actual tensor([-1.5439,  0.6669,  0.0221])\n","Predicted tensor([-0.6904,  0.0579, -0.1194], grad_fn=<SelectBackward>) Actual tensor([-0.6576, -0.1276, -0.3401])\n","Predicted tensor([-0.6295, -0.4276, -0.1313], grad_fn=<SelectBackward>) Actual tensor([-0.8332, -0.4278, -0.2746])\n","Predicted tensor([-0.5308, -0.4316, -0.1234], grad_fn=<SelectBackward>) Actual tensor([-0.7468,  1.1552, -0.0942])\n","Predicted tensor([-0.5445, -0.4421, -0.1302], grad_fn=<SelectBackward>) Actual tensor([-0.2854, -0.6093, -0.2251])\n","Predicted tensor([-0.6490, -0.5366, -0.0717], grad_fn=<SelectBackward>) Actual tensor([-0.8280, -0.7369, -0.2803])\n","Predicted tensor([-0.8463,  0.2458,  0.5033], grad_fn=<SelectBackward>) Actual tensor([-1.8697, -0.2884, -0.0875])\n","Predicted tensor([-0.6800, -0.0592,  4.0590], grad_fn=<SelectBackward>) Actual tensor([-0.7367, -0.6915,  5.1513])\n","Predicted tensor([-0.0776,  0.5855, -0.1461], grad_fn=<SelectBackward>) Actual tensor([ 0.6244, -0.7653, -0.2822])\n","Predicted tensor([ 0.1028, -0.2474, -0.1381], grad_fn=<SelectBackward>) Actual tensor([ 1.2167, -0.3135, -0.3479])\n","Predicted tensor([-0.4616,  0.5389, -0.1531], grad_fn=<SelectBackward>) Actual tensor([ 0.0695,  1.3722, -0.2765])\n","Predicted tensor([ 0.6297,  0.0129, -0.1972], grad_fn=<SelectBackward>) Actual tensor([ 2.0452, -0.5598, -0.2727])\n","Predicted tensor([ 0.1289, -0.2427, -0.1257], grad_fn=<SelectBackward>) Actual tensor([-0.3797, -0.7818, -0.3163])\n","Predicted tensor([ 0.6790, -0.3277, -0.2307], grad_fn=<SelectBackward>) Actual tensor([-0.3071, -0.6260, -0.2715])\n","Predicted tensor([ 0.5645, -0.2629, -0.2628], grad_fn=<SelectBackward>) Actual tensor([0.9591, 3.7902, 1.0108])\n","Predicted tensor([ 0.2384, -0.4824, -0.4662], grad_fn=<SelectBackward>) Actual tensor([-0.9376, -0.5295, -0.0899])\n","Predicted tensor([ 0.7083, -0.3646, -0.2610], grad_fn=<SelectBackward>) Actual tensor([ 1.2067, -0.7619, -0.3011])\n","Predicted tensor([-0.3949, -0.4460, -0.1244], grad_fn=<SelectBackward>) Actual tensor([-0.5936, -0.7597, -0.2995])\n","Predicted tensor([-0.6987, -0.4154, -0.1168], grad_fn=<SelectBackward>) Actual tensor([-0.7819, -0.4101, -0.2680])\n","Predicted tensor([-0.6689, -0.4991, -0.1054], grad_fn=<SelectBackward>) Actual tensor([-0.5968, -0.7945, -0.2573])\n","Predicted tensor([-0.9934,  0.5286, -0.0976], grad_fn=<SelectBackward>) Actual tensor([-0.0966,  1.1202, -0.3268])\n","Predicted tensor([-0.2323, -0.4568, -0.0713], grad_fn=<SelectBackward>) Actual tensor([-0.7673, -0.3911, -0.2180])\n","Predicted tensor([-0.0940,  0.2969,  0.6656], grad_fn=<SelectBackward>) Actual tensor([-1.9278,  0.8794,  0.7680])\n","Predicted tensor([0.3042, 1.3056, 0.0945], grad_fn=<SelectBackward>) Actual tensor([-0.4280, -0.6857, -0.3268])\n","Predicted tensor([-0.1752,  1.1445,  0.9444], grad_fn=<SelectBackward>) Actual tensor([0.0378, 2.8842, 1.9494])\n","Predicted tensor([ 0.2769,  0.7439, -0.0339], grad_fn=<SelectBackward>) Actual tensor([ 1.0646,  0.1496, -0.3585])\n","Predicted tensor([ 0.0785,  0.0110, -0.1319], grad_fn=<SelectBackward>) Actual tensor([ 0.0483, -0.1651, -0.3018])\n","Predicted tensor([-0.1442, -0.2053, -0.1160], grad_fn=<SelectBackward>) Actual tensor([-0.4806, -0.6928, -0.3246])\n","Predicted tensor([ 0.5512, -0.2310, -0.2047], grad_fn=<SelectBackward>) Actual tensor([ 1.6074, -0.2937, -0.3388])\n","Predicted tensor([-0.3129, -0.0445, -0.1188], grad_fn=<SelectBackward>) Actual tensor([-0.7431, -0.7248, -0.3319])\n","Predicted tensor([ 0.2979, -0.3506, -0.1260], grad_fn=<SelectBackward>) Actual tensor([-0.2958, -0.7617, -0.2775])\n","Predicted tensor([ 0.6932, -0.3446, -0.2428], grad_fn=<SelectBackward>) Actual tensor([ 1.1121, -0.7373, -0.3302])\n","Predicted tensor([0.2639, 0.2901, 0.1806], grad_fn=<SelectBackward>) Actual tensor([-0.5761,  0.4926,  0.5180])\n","Predicted tensor([ 0.0063,  0.0120, -0.0854], grad_fn=<SelectBackward>) Actual tensor([ 1.2539,  1.1537, -0.3693])\n","Predicted tensor([0.3992, 0.1003, 0.1372], grad_fn=<SelectBackward>) Actual tensor([-0.5367, -0.5609, -0.2958])\n","Predicted tensor([ 0.2365, -0.4906, -0.4490], grad_fn=<SelectBackward>) Actual tensor([-2.3267, -0.2754,  0.0562])\n","Predicted tensor([-0.6160,  0.7704,  1.9291], grad_fn=<SelectBackward>) Actual tensor([-1.0548, -0.6532,  2.7401])\n","Predicted tensor([-0.6894, -0.4466, -0.0298], grad_fn=<SelectBackward>) Actual tensor([-0.7349, -0.4746, -0.2286])\n","Predicted tensor([ 0.6859, -0.3153, -0.2417], grad_fn=<SelectBackward>) Actual tensor([ 1.1400, -0.6469, -0.3332])\n","Predicted tensor([ 0.2432, -0.1827, -0.1192], grad_fn=<SelectBackward>) Actual tensor([ 1.1315, -0.5427, -0.3339])\n","Predicted tensor([-0.1672,  0.0919, -0.1648], grad_fn=<SelectBackward>) Actual tensor([-0.4767, -0.7235, -0.2620])\n","Predicted tensor([-0.8368, -0.5227, -0.0370], grad_fn=<SelectBackward>) Actual tensor([-0.1271, -0.1984, -0.0176])\n","Predicted tensor([ 0.7574, -0.3180, -0.2622], grad_fn=<SelectBackward>) Actual tensor([ 1.0200, -0.2057, -0.2748])\n","Predicted tensor([0.7439, 0.4267, 0.0485], grad_fn=<SelectBackward>) Actual tensor([2.0611, 2.5954, 0.0582])\n","Batch: 8 completed\n","Predicted tensor([-0.4903,  1.0869,  2.0237], grad_fn=<SelectBackward>) Actual tensor([-0.6271, -0.7350, -0.3304])\n","Predicted tensor([-0.4040, -0.5148, -0.0926], grad_fn=<SelectBackward>) Actual tensor([-0.5253, -0.7710, -0.2889])\n","Predicted tensor([-0.0231, -0.2430, -0.1117], grad_fn=<SelectBackward>) Actual tensor([ 2.0568,  1.0851, -0.2478])\n","Predicted tensor([-0.3636,  0.1149, -0.1419], grad_fn=<SelectBackward>) Actual tensor([-0.2122, -0.3853, -0.3288])\n","Predicted tensor([-0.4308, -0.4475, -0.1108], grad_fn=<SelectBackward>) Actual tensor([-0.1700,  0.2764, -0.1646])\n","Predicted tensor([ 0.2581, -0.4193, -0.4524], grad_fn=<SelectBackward>) Actual tensor([ 1.5545,  0.7667, -0.3661])\n","Predicted tensor([-0.5314, -0.1860, -0.1323], grad_fn=<SelectBackward>) Actual tensor([-0.6318, -0.2446, -0.3355])\n","Predicted tensor([ 0.6896, -0.2821, -0.2656], grad_fn=<SelectBackward>) Actual tensor([ 1.6598,  0.1308, -0.3601])\n","Predicted tensor([-0.3637,  0.6950, -0.2068], grad_fn=<SelectBackward>) Actual tensor([-0.9731,  0.8831, -0.3685])\n","Predicted tensor([-0.1970,  0.6064, -0.1893], grad_fn=<SelectBackward>) Actual tensor([-0.3683,  0.9497, -0.3430])\n","Predicted tensor([-0.5947, -0.2958, -0.1139], grad_fn=<SelectBackward>) Actual tensor([-0.7119, -0.7230, -0.3232])\n","Predicted tensor([-0.2898,  0.5194,  1.5366], grad_fn=<SelectBackward>) Actual tensor([-0.4971,  0.2903,  3.6083])\n","Predicted tensor([ 0.0208, -0.1830, -0.1166], grad_fn=<SelectBackward>) Actual tensor([-0.4269,  1.4825,  0.8590])\n","Predicted tensor([ 0.6997, -0.3900, -0.2627], grad_fn=<SelectBackward>) Actual tensor([ 1.1101, -0.7790, -0.3290])\n","Predicted tensor([-0.3661, -0.3961, -0.1167], grad_fn=<SelectBackward>) Actual tensor([-0.5863, -0.7613, -0.2983])\n","Predicted tensor([-0.6483, -0.4339, -0.0868], grad_fn=<SelectBackward>) Actual tensor([-0.6253, -0.7345, -0.3189])\n","Predicted tensor([ 0.6860, -0.3693, -0.2062], grad_fn=<SelectBackward>) Actual tensor([ 1.3727, -0.6192, -0.3199])\n","Predicted tensor([-0.5148, -0.3233, -0.0955], grad_fn=<SelectBackward>) Actual tensor([-0.5659, -0.7967, -0.3066])\n","Predicted tensor([ 0.7032, -0.3006, -0.2523], grad_fn=<SelectBackward>) Actual tensor([ 1.2223, -0.5711, -0.3195])\n","Predicted tensor([-0.6730, -0.4101, -0.1117], grad_fn=<SelectBackward>) Actual tensor([-0.6428, -0.7185, -0.2810])\n","Predicted tensor([ 0.4233, -0.3555, -0.1865], grad_fn=<SelectBackward>) Actual tensor([ 1.1207, -0.7474, -0.3273])\n","Predicted tensor([0.1843, 0.3908, 0.5262], grad_fn=<SelectBackward>) Actual tensor([-0.2855, -0.4867, -0.3285])\n","Predicted tensor([ 0.6908, -0.3692, -0.2586], grad_fn=<SelectBackward>) Actual tensor([ 1.3041, -0.5796, -0.3170])\n","Predicted tensor([ 0.6875, -0.2658, -0.2435], grad_fn=<SelectBackward>) Actual tensor([ 1.1204, -0.6040, -0.3325])\n","Predicted tensor([-0.9132,  0.5156, -0.1341], grad_fn=<SelectBackward>) Actual tensor([-1.3126, -0.4654, -0.4829])\n","Predicted tensor([-0.6509,  0.4665, -0.1529], grad_fn=<SelectBackward>) Actual tensor([-0.8818,  0.4669, -0.3433])\n","Predicted tensor([-0.0376,  0.0708, -0.1563], grad_fn=<SelectBackward>) Actual tensor([ 1.5425, -0.1572, -0.3504])\n","Predicted tensor([ 0.0594, -0.2318, -0.1410], grad_fn=<SelectBackward>) Actual tensor([-0.1457,  0.1401, -0.2103])\n","Predicted tensor([-0.6694, -0.3648, -0.1075], grad_fn=<SelectBackward>) Actual tensor([-0.7787, -0.6684, -0.2698])\n","Predicted tensor([ 0.6844, -0.2936, -0.2437], grad_fn=<SelectBackward>) Actual tensor([ 1.1205, -0.6372, -0.3332])\n","Predicted tensor([ 0.4609,  0.2241, -0.0468], grad_fn=<SelectBackward>) Actual tensor([-2.4099, -0.3562, -0.5572])\n","Predicted tensor([ 0.7531, -0.3019, -0.2606], grad_fn=<SelectBackward>) Actual tensor([ 1.0529, -0.2308, -0.2795])\n","Predicted tensor([ 0.7885,  0.1763, -0.1048], grad_fn=<SelectBackward>) Actual tensor([-0.4868, -0.7917, -0.3046])\n","Predicted tensor([ 0.0699,  2.0919, -0.1449], grad_fn=<SelectBackward>) Actual tensor([-1.6779,  0.7169, -0.3069])\n","Predicted tensor([ 0.7006, -0.2339, -0.1543], grad_fn=<SelectBackward>) Actual tensor([ 1.4411, -0.3797, -0.2775])\n","Predicted tensor([ 0.6855,  0.1182, -0.1275], grad_fn=<SelectBackward>) Actual tensor([ 1.1312, -0.6470, -0.3368])\n","Predicted tensor([ 0.7336, -0.2326, -0.2421], grad_fn=<SelectBackward>) Actual tensor([ 1.1121, -0.5916, -0.3314])\n","Predicted tensor([ 0.6204, -0.0211, -0.2008], grad_fn=<SelectBackward>) Actual tensor([ 1.0705, -0.1759, -0.3498])\n","Predicted tensor([-0.2671, -0.3349, -0.1135], grad_fn=<SelectBackward>) Actual tensor([-0.6121, -0.7889, -0.3081])\n","Predicted tensor([ 0.6977, -0.3666, -0.2593], grad_fn=<SelectBackward>) Actual tensor([ 1.4764, -0.6143, -0.3090])\n","Predicted tensor([-0.2907, -0.4243, -0.1009], grad_fn=<SelectBackward>) Actual tensor([ 2.0068,  0.4384, -0.3694])\n","Predicted tensor([-0.0199,  0.1396, -0.1057], grad_fn=<SelectBackward>) Actual tensor([-0.4912, -0.2790, -0.3379])\n","Predicted tensor([ 0.5217,  0.2254, -0.1549], grad_fn=<SelectBackward>) Actual tensor([-1.9964,  0.0851,  0.1073])\n","Predicted tensor([-0.6268,  0.4839, -0.1779], grad_fn=<SelectBackward>) Actual tensor([-1.3594, -0.6796, -0.3628])\n","Predicted tensor([-0.7436, -0.1376, -0.1238], grad_fn=<SelectBackward>) Actual tensor([-0.3101,  0.1073, -0.3486])\n","Predicted tensor([-0.9298, -0.4545,  0.0111], grad_fn=<SelectBackward>) Actual tensor([ 0.5783,  0.2536, -0.2684])\n","Predicted tensor([ 0.7513, -0.2894, -0.2299], grad_fn=<SelectBackward>) Actual tensor([-2.1337,  0.2560, -0.0552])\n","Predicted tensor([ 0.5747, -0.1503, -0.2383], grad_fn=<SelectBackward>) Actual tensor([-2.2095, -0.7816,  0.1843])\n","Predicted tensor([-0.1114, -0.3149, -0.1006], grad_fn=<SelectBackward>) Actual tensor([ 1.1120, -0.7218, -0.3300])\n","Predicted tensor([-0.1201,  1.1188,  1.0337], grad_fn=<SelectBackward>) Actual tensor([-2.1267,  0.8342, -0.2057])\n","Predicted tensor([ 0.7082, -0.3356, -0.2246], grad_fn=<SelectBackward>) Actual tensor([ 1.1987, -0.4880, -0.2997])\n","Predicted tensor([ 0.0930, -0.3251, -0.1085], grad_fn=<SelectBackward>) Actual tensor([-0.3054, -0.5880, -0.2526])\n","Predicted tensor([ 0.4402, -0.1063, -0.0554], grad_fn=<SelectBackward>) Actual tensor([ 1.2171, -0.5590, -0.3280])\n","Predicted tensor([-0.8616, -0.3450,  4.2729], grad_fn=<SelectBackward>) Actual tensor([-0.8069, -0.6134,  5.1434])\n","Predicted tensor([-0.7502,  0.3062, -0.1461], grad_fn=<SelectBackward>) Actual tensor([-1.1025, -0.7790, -0.3618])\n","Predicted tensor([-0.6429, -0.4297, -0.1209], grad_fn=<SelectBackward>) Actual tensor([-0.5564, -0.4773, -0.2069])\n","Predicted tensor([0.5356, 0.6056, 0.0274], grad_fn=<SelectBackward>) Actual tensor([ 1.7046,  2.0453, -0.2438])\n","Predicted tensor([-0.3821, -0.4958, -0.1041], grad_fn=<SelectBackward>) Actual tensor([-0.6022, -0.7283, -0.2037])\n","Predicted tensor([ 0.4678,  0.0047, -0.2028], grad_fn=<SelectBackward>) Actual tensor([ 1.8232,  1.3541, -0.2585])\n","Predicted tensor([ 0.2019, -0.2937, -0.1477], grad_fn=<SelectBackward>) Actual tensor([-0.1273, -0.7471, -0.3147])\n","Predicted tensor([-0.6382, -0.3255, -0.0914], grad_fn=<SelectBackward>) Actual tensor([-0.6822, -0.6518, -0.3254])\n","Predicted tensor([ 0.3643, -0.0182, -0.2620], grad_fn=<SelectBackward>) Actual tensor([2.4620, 0.3307, 0.2553])\n","Predicted tensor([-0.6708, -0.5089, -0.1118], grad_fn=<SelectBackward>) Actual tensor([-0.7599, -0.4235, -0.2690])\n","Predicted tensor([-0.3871, -0.2414, -0.1619], grad_fn=<SelectBackward>) Actual tensor([ 1.1104, -0.7713, -0.3300])\n","Predicted tensor([-0.4341, -0.3739, -0.1148], grad_fn=<SelectBackward>) Actual tensor([-0.7203, -0.6520, -0.3191])\n","Predicted tensor([-0.4309, -0.4779, -0.1005], grad_fn=<SelectBackward>) Actual tensor([-0.4349,  0.0411, -0.1771])\n","Predicted tensor([-0.6035, -0.2562, -0.1092], grad_fn=<SelectBackward>) Actual tensor([-0.4711, -0.3245, -0.3346])\n","Predicted tensor([-0.2884, -0.5098, -0.0498], grad_fn=<SelectBackward>) Actual tensor([-0.7826, -0.4024, -0.2539])\n","Predicted tensor([ 0.1938, -0.2559, -0.1221], grad_fn=<SelectBackward>) Actual tensor([-0.6910, -0.6818, -0.2920])\n","Predicted tensor([-1.5262,  0.0718,  0.0321], grad_fn=<SelectBackward>) Actual tensor([ 1.2222,  0.0564, -0.3081])\n","Predicted tensor([ 0.6921, -0.2926, -0.2486], grad_fn=<SelectBackward>) Actual tensor([ 0.0114, -0.6354, -0.2680])\n","Predicted tensor([ 0.6636, -0.2698, -0.1640], grad_fn=<SelectBackward>) Actual tensor([ 1.6336,  0.5291, -0.2698])\n","Predicted tensor([-0.1533, -0.3787, -0.1053], grad_fn=<SelectBackward>) Actual tensor([-0.6922, -0.7421, -0.2758])\n","Predicted tensor([-0.3080, -0.3444, -0.1046], grad_fn=<SelectBackward>) Actual tensor([ 1.3266,  0.3951, -0.3544])\n","Predicted tensor([-0.1505,  0.1308, -0.1142], grad_fn=<SelectBackward>) Actual tensor([-0.7498, -0.7890, -0.3452])\n","Predicted tensor([-0.2159, -0.3686, -0.1250], grad_fn=<SelectBackward>) Actual tensor([-0.4766, -0.6112, -0.1636])\n","Predicted tensor([-0.3453, -0.1977,  0.0684], grad_fn=<SelectBackward>) Actual tensor([-1.2796e+00,  1.1876e+00,  1.4180e-04])\n","Predicted tensor([ 0.7198, -0.4358, -0.2583], grad_fn=<SelectBackward>) Actual tensor([ 1.1071, -0.7776, -0.3289])\n","Predicted tensor([ 0.6975, -0.3212, -0.2527], grad_fn=<SelectBackward>) Actual tensor([ 1.1180, -0.5915, -0.3284])\n","Predicted tensor([-0.4290, -0.4859, -0.1052], grad_fn=<SelectBackward>) Actual tensor([-0.5435, -0.2242, -0.1926])\n","Predicted tensor([-0.5783, -0.2364, -0.1110], grad_fn=<SelectBackward>) Actual tensor([ 1.9069,  2.2670, -0.1582])\n","Predicted tensor([-0.3229,  0.6376, -0.1612], grad_fn=<SelectBackward>) Actual tensor([-1.2125, -0.2483, -0.4924])\n","Predicted tensor([ 0.2068, -0.2790, -0.1455], grad_fn=<SelectBackward>) Actual tensor([ 0.1136,  1.2364, -0.0371])\n","Predicted tensor([ 0.2581,  0.1161, -0.0924], grad_fn=<SelectBackward>) Actual tensor([-0.2525, -0.5710, -0.2631])\n","Predicted tensor([ 0.5658,  0.0946, -0.1815], grad_fn=<SelectBackward>) Actual tensor([-0.5091,  1.8130,  0.0260])\n","Predicted tensor([-0.0671, -0.1673, -0.1232], grad_fn=<SelectBackward>) Actual tensor([-0.6854, -0.6120, -0.2929])\n","Predicted tensor([ 0.6781, -0.3244, -0.2107], grad_fn=<SelectBackward>) Actual tensor([0.2813, 0.8855, 1.6708])\n","Predicted tensor([ 0.1152,  0.3538, -0.0940], grad_fn=<SelectBackward>) Actual tensor([ 1.1161, -0.7133, -0.3266])\n","Predicted tensor([-0.3571, -0.1055, -0.1953], grad_fn=<SelectBackward>) Actual tensor([-0.6729, -0.5600, -0.2601])\n","Predicted tensor([ 0.5613, -0.2454, -0.2041], grad_fn=<SelectBackward>) Actual tensor([ 0.0471, -0.7952, -0.3314])\n","Predicted tensor([0.7283, 0.3658, 0.0420], grad_fn=<SelectBackward>) Actual tensor([-1.0695, -0.7882,  5.1428])\n","Predicted tensor([ 0.6728, -0.0537, -0.1579], grad_fn=<SelectBackward>) Actual tensor([-0.5514, -0.7730, -0.3255])\n","Predicted tensor([-0.0333, -0.3209, -0.1090], grad_fn=<SelectBackward>) Actual tensor([-0.9500,  0.4869,  0.0687])\n","Predicted tensor([ 0.5043, -0.2895, -0.2374], grad_fn=<SelectBackward>) Actual tensor([-0.5232, -0.3692, -0.3039])\n","Predicted tensor([ 0.2201, -0.2595, -0.1458], grad_fn=<SelectBackward>) Actual tensor([-0.0399, -0.2580, -0.2470])\n","Predicted tensor([-1.4951,  0.0862,  0.0566], grad_fn=<SelectBackward>) Actual tensor([-2.4112, -0.3491, -0.5050])\n","Predicted tensor([-0.6830,  0.1583, -0.1147], grad_fn=<SelectBackward>) Actual tensor([-0.7011, -0.5783, -0.3102])\n","Predicted tensor([ 0.2437,  0.0882, -0.1273], grad_fn=<SelectBackward>) Actual tensor([-1.8332, -0.1759, -0.4758])\n","Predicted tensor([-0.5878,  0.3497, -0.1458], grad_fn=<SelectBackward>) Actual tensor([-0.2463, -0.2957, -0.3646])\n","Predicted tensor([ 0.4778, -0.3599, -0.2063], grad_fn=<SelectBackward>) Actual tensor([-0.5571, -0.6512, -0.2052])\n","Predicted tensor([-0.0115, -0.1494, -0.0668], grad_fn=<SelectBackward>) Actual tensor([ 1.3543,  1.1342, -0.3730])\n","Predicted tensor([-0.3174,  0.7489,  3.0920], grad_fn=<SelectBackward>) Actual tensor([-0.9438,  2.0922,  5.0488])\n","Predicted tensor([ 0.2751, -0.3359, -0.1576], grad_fn=<SelectBackward>) Actual tensor([ 0.4296, -0.5120, -0.2433])\n","Predicted tensor([-0.5878, -0.2957, -0.1263], grad_fn=<SelectBackward>) Actual tensor([-1.5683, -0.2794, -0.2032])\n","Predicted tensor([-0.5341, -0.4559, -0.1226], grad_fn=<SelectBackward>) Actual tensor([ 1.1587, -0.3071, -0.3412])\n","Predicted tensor([-0.6632, -0.5377, -0.0341], grad_fn=<SelectBackward>) Actual tensor([-0.7838, -0.4807, -0.2787])\n","Predicted tensor([-0.9706, -0.4465,  4.5466], grad_fn=<SelectBackward>) Actual tensor([ 1.6301,  2.1252, -0.0799])\n","Predicted tensor([0.1423, 0.2785, 0.2971], grad_fn=<SelectBackward>) Actual tensor([-1.6676,  0.3829,  0.2887])\n","Predicted tensor([ 0.4047,  0.1660, -0.2314], grad_fn=<SelectBackward>) Actual tensor([ 1.1658,  0.6453, -0.3647])\n","Predicted tensor([ 0.7117, -0.2471, -0.2481], grad_fn=<SelectBackward>) Actual tensor([ 1.0993, -0.6040, -0.3272])\n","Predicted tensor([-0.6011, -0.5113, -0.1118], grad_fn=<SelectBackward>) Actual tensor([-0.7870, -0.6580, -0.2591])\n","Predicted tensor([-0.5035, -0.4066, -0.0911], grad_fn=<SelectBackward>) Actual tensor([-0.7023, -0.7802, -0.2368])\n","Predicted tensor([-0.0206, -0.1633, -0.1100], grad_fn=<SelectBackward>) Actual tensor([-0.0834, -0.6261, -0.3288])\n","Predicted tensor([-0.1947, -0.3906, -0.0607], grad_fn=<SelectBackward>) Actual tensor([ 1.1090, -0.7937, -0.3307])\n","Predicted tensor([-0.4790,  1.2396,  2.8925], grad_fn=<SelectBackward>) Actual tensor([-1.1005,  0.6965,  4.2811])\n","Predicted tensor([-0.5761, -0.4993, -0.1038], grad_fn=<SelectBackward>) Actual tensor([-0.8409, -0.5728, -0.3066])\n","Predicted tensor([ 0.6770, -0.2279, -0.2207], grad_fn=<SelectBackward>) Actual tensor([0.3051, 0.0536, 0.0799])\n","Predicted tensor([-0.2754,  0.0237, -0.0860], grad_fn=<SelectBackward>) Actual tensor([-0.7111, -0.6974, -0.2780])\n","Predicted tensor([-0.2495,  0.0651, -0.1851], grad_fn=<SelectBackward>) Actual tensor([-0.1789, -0.1402, -0.2503])\n","Predicted tensor([-0.6105, -0.4578, -0.1056], grad_fn=<SelectBackward>) Actual tensor([-0.7106, -0.6605, -0.2976])\n","Predicted tensor([-0.6303, -0.2263, -0.1293], grad_fn=<SelectBackward>) Actual tensor([ 1.6847, -0.6646, -0.3301])\n","Predicted tensor([-0.6151, -0.5395, -0.0721], grad_fn=<SelectBackward>) Actual tensor([-0.5272, -0.1301, -0.2373])\n","Predicted tensor([ 0.1038, -0.2527, -0.1183], grad_fn=<SelectBackward>) Actual tensor([-0.1318, -0.6199, -0.2926])\n","Predicted tensor([-0.1133, -0.3661, -0.1194], grad_fn=<SelectBackward>) Actual tensor([-0.3449, -0.3104, -0.1619])\n","Predicted tensor([-1.3305,  0.1807,  0.0690], grad_fn=<SelectBackward>) Actual tensor([-1.7209,  0.2562, -0.1794])\n","Predicted tensor([0.3758, 0.1694, 0.0236], grad_fn=<SelectBackward>) Actual tensor([ 1.2814,  0.1672, -0.3519])\n","Predicted tensor([-0.1993, -0.4026, -0.0973], grad_fn=<SelectBackward>) Actual tensor([-0.3244, -0.4988, -0.2161])\n","Predicted tensor([ 0.4535,  0.1962, -0.0513], grad_fn=<SelectBackward>) Actual tensor([ 0.8494,  0.9194, -0.1159])\n","Predicted tensor([ 0.0019, -0.1782, -0.1579], grad_fn=<SelectBackward>) Actual tensor([-0.2917, -0.2966, -0.2405])\n","Predicted tensor([-1.0103, -0.1706, -0.0651], grad_fn=<SelectBackward>) Actual tensor([-1.5641,  1.8289, -0.3158])\n","Predicted tensor([-0.2453,  0.0560, -0.0460], grad_fn=<SelectBackward>) Actual tensor([ 1.5563,  0.0310, -0.3663])\n","Predicted tensor([ 0.6501, -0.3950, -0.1847], grad_fn=<SelectBackward>) Actual tensor([-0.4322,  1.0075, -0.0082])\n","Predicted tensor([-0.6039, -0.5655, -0.0516], grad_fn=<SelectBackward>) Actual tensor([-0.6538,  0.8391, -0.1296])\n","Predicted tensor([-0.6718, -0.4309, -0.0695], grad_fn=<SelectBackward>) Actual tensor([-0.2177, -0.7832, -0.2349])\n","Predicted tensor([-0.0294, -0.2311, -0.0595], grad_fn=<SelectBackward>) Actual tensor([ 1.2474, -0.0489, -0.3498])\n","Predicted tensor([-0.9678, -0.4658,  4.5399], grad_fn=<SelectBackward>) Actual tensor([-1.0648, -0.6757,  5.1521])\n","Predicted tensor([ 0.2152, -0.3669, -0.1368], grad_fn=<SelectBackward>) Actual tensor([ 0.0854, -0.7884, -0.2406])\n","Predicted tensor([-0.4727, -0.3753, -0.0952], grad_fn=<SelectBackward>) Actual tensor([-0.7152, -0.7462, -0.2809])\n","Predicted tensor([-0.2673, -0.2559, -0.1126], grad_fn=<SelectBackward>) Actual tensor([2.0242, 0.2073, 0.4834])\n","Predicted tensor([ 0.0075, -0.2159, -0.1161], grad_fn=<SelectBackward>) Actual tensor([ 1.0415, -0.3256, -0.3324])\n","Predicted tensor([-0.5195, -0.1394, -0.0806], grad_fn=<SelectBackward>) Actual tensor([-0.5825, -0.7186, -0.2769])\n","Predicted tensor([0.0270, 0.4708, 0.2986], grad_fn=<SelectBackward>) Actual tensor([ 0.9230, -0.5311, -0.3420])\n","Predicted tensor([-0.3551, -0.0967, -0.0299], grad_fn=<SelectBackward>) Actual tensor([-1.0141,  1.3009,  0.0714])\n","Predicted tensor([-0.4997, -0.3968, -0.1348], grad_fn=<SelectBackward>) Actual tensor([-0.5325,  0.5450, -0.1667])\n","Predicted tensor([-0.5624, -0.1765, -0.1096], grad_fn=<SelectBackward>) Actual tensor([-0.4899, -0.2147, -0.3083])\n","Predicted tensor([ 0.0269,  0.7111, -0.0352], grad_fn=<SelectBackward>) Actual tensor([ 0.2696,  0.5644, -0.2982])\n","Predicted tensor([-1.0169, -0.4510,  4.5785], grad_fn=<SelectBackward>) Actual tensor([-1.0098,  0.4416,  5.1521])\n","Predicted tensor([-0.6828, -0.4093, -0.1443], grad_fn=<SelectBackward>) Actual tensor([-0.6392, -0.7983, -0.2418])\n","Predicted tensor([-0.3640, -0.3150, -0.0943], grad_fn=<SelectBackward>) Actual tensor([-0.6671, -0.7460, -0.2896])\n","Predicted tensor([ 0.5439,  0.3368, -0.0691], grad_fn=<SelectBackward>) Actual tensor([ 0.8235,  2.9135, -0.0770])\n","Predicted tensor([-0.6147, -0.1083, -0.1300], grad_fn=<SelectBackward>) Actual tensor([-0.4450, -0.2405, -0.3206])\n","Predicted tensor([-0.4197, -0.2881, -0.1107], grad_fn=<SelectBackward>) Actual tensor([-0.6823, -0.7179, -0.3223])\n","Predicted tensor([ 0.5984,  0.4018, -0.0337], grad_fn=<SelectBackward>) Actual tensor([1.7217, 1.7421, 0.1229])\n","Predicted tensor([-0.6603, -0.5955, -0.0688], grad_fn=<SelectBackward>) Actual tensor([-0.7949, -0.6443, -0.2558])\n","Predicted tensor([-0.3070, -0.3914, -0.1109], grad_fn=<SelectBackward>) Actual tensor([ 1.1399, -0.5345, -0.3343])\n","Predicted tensor([-0.8166, -0.4848, -0.0514], grad_fn=<SelectBackward>) Actual tensor([-0.8762, -0.5507, -0.2781])\n","Predicted tensor([-0.9407, -0.4070,  4.4815], grad_fn=<SelectBackward>) Actual tensor([-1.0192, -0.7740,  5.1414])\n","Predicted tensor([ 0.3413,  0.5409, -0.1289], grad_fn=<SelectBackward>) Actual tensor([-0.4849, -0.6663, -0.3084])\n","Predicted tensor([ 0.0627, -0.0006, -0.1319], grad_fn=<SelectBackward>) Actual tensor([ 1.5004,  1.6247, -0.3675])\n","Predicted tensor([-0.5359, -0.5543, -0.0839], grad_fn=<SelectBackward>) Actual tensor([-0.7493, -0.5323, -0.2964])\n","Predicted tensor([-0.6415, -0.3975, -0.1116], grad_fn=<SelectBackward>) Actual tensor([-0.9708, -0.3046, -0.1517])\n","Predicted tensor([ 0.0082, -0.0469, -0.1479], grad_fn=<SelectBackward>) Actual tensor([-0.2473, -0.2741, -0.2419])\n","Predicted tensor([-0.5998, -0.4868, -0.0590], grad_fn=<SelectBackward>) Actual tensor([-0.6887,  0.0684, -0.1034])\n","Predicted tensor([ 0.6966, -0.3721, -0.2700], grad_fn=<SelectBackward>) Actual tensor([ 1.0805, -0.6870, -0.3355])\n","Predicted tensor([-0.7499, -0.5355, -0.0556], grad_fn=<SelectBackward>) Actual tensor([-0.4747, -0.4865, -0.1819])\n","Predicted tensor([-0.4638,  1.3372,  2.0151], grad_fn=<SelectBackward>) Actual tensor([-0.0282,  0.6831,  1.0097])\n","Predicted tensor([-0.6234, -0.5073, -0.0976], grad_fn=<SelectBackward>) Actual tensor([-0.7693, -0.5329, -0.2820])\n","Predicted tensor([ 0.6681, -0.1174, -0.2129], grad_fn=<SelectBackward>) Actual tensor([ 1.0038, -0.0363, -0.2396])\n","Predicted tensor([ 0.7317,  0.1835, -0.0987], grad_fn=<SelectBackward>) Actual tensor([-2.3243,  0.2145, -0.4421])\n","Predicted tensor([-0.6408, -0.3377, -0.1056], grad_fn=<SelectBackward>) Actual tensor([-0.6454, -0.7760, -0.3278])\n","Predicted tensor([ 0.1267, -0.1393, -0.1518], grad_fn=<SelectBackward>) Actual tensor([ 1.2934, -0.1254, -0.3496])\n","Predicted tensor([-0.6812, -0.3082, -0.1337], grad_fn=<SelectBackward>) Actual tensor([-0.7950, -0.7832, -0.2761])\n","Predicted tensor([-1.1976,  0.2904, -0.0236], grad_fn=<SelectBackward>) Actual tensor([-0.8589,  1.7821, -0.3625])\n","Predicted tensor([-0.1110, -0.3547, -0.1334], grad_fn=<SelectBackward>) Actual tensor([-0.7041, -0.5587, -0.2572])\n","Predicted tensor([-0.2865, -0.2506, -0.0954], grad_fn=<SelectBackward>) Actual tensor([-0.5251, -0.7234, -0.3184])\n","Predicted tensor([0.4838, 0.9108, 0.1781], grad_fn=<SelectBackward>) Actual tensor([-0.2663, -0.2068, -0.1081])\n","Predicted tensor([-0.3593,  0.6133,  3.3271], grad_fn=<SelectBackward>) Actual tensor([-0.1850, -0.3429, -0.2361])\n","Predicted tensor([-0.5654,  0.3305, -0.1373], grad_fn=<SelectBackward>) Actual tensor([-0.3144,  0.2316, -0.3477])\n","Predicted tensor([ 0.6222,  0.5351, -0.0384], grad_fn=<SelectBackward>) Actual tensor([1.7944, 2.5139, 0.1210])\n","Predicted tensor([0.2241, 0.2542, 0.1270], grad_fn=<SelectBackward>) Actual tensor([-0.4945, -0.7718, -0.2943])\n","Predicted tensor([-0.2350,  1.0542,  1.8899], grad_fn=<SelectBackward>) Actual tensor([ 1.1516,  0.7567, -0.1539])\n","Predicted tensor([ 0.3256, -0.0011, -0.1510], grad_fn=<SelectBackward>) Actual tensor([1.7271, 2.1246, 0.1192])\n","Predicted tensor([0.8081, 0.5137, 0.1568], grad_fn=<SelectBackward>) Actual tensor([-0.4322, -0.6887, -0.2894])\n","Predicted tensor([0.1260, 0.3723, 0.2138], grad_fn=<SelectBackward>) Actual tensor([-0.4591, -0.6987, -0.3279])\n","Predicted tensor([-0.8724, -0.4579,  0.0033], grad_fn=<SelectBackward>) Actual tensor([-0.7121, -0.6312, -0.2767])\n","Predicted tensor([ 0.4230, -0.2229, -0.1455], grad_fn=<SelectBackward>) Actual tensor([ 1.1699, -0.6169, -0.3282])\n","Predicted tensor([0.7110, 0.0937, 0.0193], grad_fn=<SelectBackward>) Actual tensor([-1.2780,  0.8327, -0.2231])\n","Predicted tensor([-0.3301,  1.1713,  0.9446], grad_fn=<SelectBackward>) Actual tensor([0.6323, 2.2463, 2.0122])\n","Predicted tensor([-0.3296, -0.0607, -0.1924], grad_fn=<SelectBackward>) Actual tensor([-0.3559, -0.7970, -0.3122])\n","Predicted tensor([-0.6108,  0.1000, -0.1149], grad_fn=<SelectBackward>) Actual tensor([-0.6754, -0.4060, -0.3237])\n","Predicted tensor([-1.0167, -0.1879, -0.0684], grad_fn=<SelectBackward>) Actual tensor([-1.8974, -0.0617, -0.4250])\n","Predicted tensor([ 0.2096,  0.0628, -0.1111], grad_fn=<SelectBackward>) Actual tensor([ 1.1433, -0.5740, -0.3307])\n","Predicted tensor([ 0.7428, -0.2395, -0.2457], grad_fn=<SelectBackward>) Actual tensor([ 1.2265, -0.6302, -0.3128])\n","Predicted tensor([-0.3363, -0.4902, -0.0822], grad_fn=<SelectBackward>) Actual tensor([-0.5621, -0.6961, -0.1938])\n","Predicted tensor([ 0.0442,  0.0206, -0.1194], grad_fn=<SelectBackward>) Actual tensor([-0.5291, -0.6266, -0.3265])\n","Predicted tensor([-0.5341, -0.3380, -0.0999], grad_fn=<SelectBackward>) Actual tensor([-0.7832, -0.5361, -0.2798])\n","Predicted tensor([ 0.1214, -0.3090, -0.1112], grad_fn=<SelectBackward>) Actual tensor([-0.2811, -0.5268, -0.3211])\n","Predicted tensor([ 0.7426, -0.3908, -0.2992], grad_fn=<SelectBackward>) Actual tensor([ 0.8970, -0.4521, -0.2877])\n","Predicted tensor([0.0324, 0.5924, 0.2319], grad_fn=<SelectBackward>) Actual tensor([-0.4909, -0.7436, -0.3137])\n","Predicted tensor([-0.4549, -0.4265, -0.0956], grad_fn=<SelectBackward>) Actual tensor([ 0.2226, -0.7771, -0.2213])\n","Batch: 9 completed\n","Predicted tensor([ 0.6954, -0.2712, -0.2492], grad_fn=<SelectBackward>) Actual tensor([-0.6034, -0.1956, -0.3201])\n","Predicted tensor([-0.7462,  0.5763, -0.1513], grad_fn=<SelectBackward>) Actual tensor([-0.9519, -0.1970, -0.4261])\n","Predicted tensor([ 0.0967, -0.3096, -0.1510], grad_fn=<SelectBackward>) Actual tensor([-0.4235, -0.7489, -0.2506])\n","Predicted tensor([-0.7685,  0.1049, -0.0838], grad_fn=<SelectBackward>) Actual tensor([-0.5314,  0.0386, -0.3850])\n","Predicted tensor([ 0.2053, -0.2898, -0.1363], grad_fn=<SelectBackward>) Actual tensor([-0.4311, -0.6589, -0.2949])\n","Predicted tensor([ 0.4074, -0.0652, -0.1002], grad_fn=<SelectBackward>) Actual tensor([-0.6867, -0.7102, -0.3218])\n","Predicted tensor([-0.2040,  0.3798, -0.1171], grad_fn=<SelectBackward>) Actual tensor([-0.2161, -0.3524, -0.3449])\n","Predicted tensor([ 0.0768,  0.1079, -0.1401], grad_fn=<SelectBackward>) Actual tensor([ 2.0982,  1.6703, -0.1866])\n","Predicted tensor([ 0.5122,  0.1091, -0.1872], grad_fn=<SelectBackward>) Actual tensor([ 1.6691,  0.7316, -0.2874])\n","Predicted tensor([ 0.4663,  0.4534, -0.0962], grad_fn=<SelectBackward>) Actual tensor([-0.4417, -0.7374, -0.3146])\n","Predicted tensor([-0.0254,  0.4385, -0.2149], grad_fn=<SelectBackward>) Actual tensor([-1.1953, -0.0416, -0.3111])\n","Predicted tensor([-0.5944, -0.4825, -0.0922], grad_fn=<SelectBackward>) Actual tensor([-0.6146, -0.7436, -0.3077])\n","Predicted tensor([0.1072, 0.2035, 0.3998], grad_fn=<SelectBackward>) Actual tensor([2.0227, 1.9763, 0.0623])\n","Predicted tensor([-0.0170, -0.3089, -0.1166], grad_fn=<SelectBackward>) Actual tensor([ 1.2943, -0.3155, -0.3426])\n","Predicted tensor([ 0.6101, -0.2629, -0.1908], grad_fn=<SelectBackward>) Actual tensor([-0.2505,  0.0742, -0.2537])\n","Predicted tensor([ 0.3402,  0.1484, -0.0862], grad_fn=<SelectBackward>) Actual tensor([-0.1354,  0.8616, -0.3224])\n","Predicted tensor([0.3767, 1.3077, 0.0280], grad_fn=<SelectBackward>) Actual tensor([-2.4100, -0.1046,  0.0906])\n","Predicted tensor([-1.2839,  0.4791,  0.0862], grad_fn=<SelectBackward>) Actual tensor([-1.5836, -0.1717, -0.1798])\n","Predicted tensor([ 0.7643, -0.3063, -0.2598], grad_fn=<SelectBackward>) Actual tensor([ 1.2380, -0.6956, -0.3056])\n","Predicted tensor([ 0.2257, -0.0061, -0.3385], grad_fn=<SelectBackward>) Actual tensor([ 1.5808,  1.7312, -0.3332])\n","Predicted tensor([ 0.6980, -0.1805, -0.2353], grad_fn=<SelectBackward>) Actual tensor([-0.0025,  0.1474,  0.2273])\n","Predicted tensor([ 0.1161, -0.2904, -0.1171], grad_fn=<SelectBackward>) Actual tensor([ 1.7757,  1.2414, -0.2225])\n","Predicted tensor([ 0.7115, -0.3177, -0.2216], grad_fn=<SelectBackward>) Actual tensor([ 1.0313, -0.5605, -0.3012])\n","Predicted tensor([-0.2942,  0.4746,  0.2420], grad_fn=<SelectBackward>) Actual tensor([-0.5529, -0.7594, -0.3286])\n","Predicted tensor([ 0.7021, -0.3672, -0.2605], grad_fn=<SelectBackward>) Actual tensor([ 0.1114,  0.8837, -0.1499])\n","Predicted tensor([ 0.2078, -0.3743, -0.1156], grad_fn=<SelectBackward>) Actual tensor([ 0.0664, -0.7848, -0.2559])\n","Predicted tensor([ 0.0269, -0.2433, -0.1152], grad_fn=<SelectBackward>) Actual tensor([-0.4296, -0.7328, -0.2856])\n","Predicted tensor([-0.2963, -0.3713, -0.0977], grad_fn=<SelectBackward>) Actual tensor([-0.5311, -0.7607, -0.3090])\n","Predicted tensor([ 0.4906,  0.0687, -0.1013], grad_fn=<SelectBackward>) Actual tensor([ 0.7041,  0.6955, -0.3097])\n","Predicted tensor([ 0.0303,  0.1864, -0.1294], grad_fn=<SelectBackward>) Actual tensor([-0.2885,  0.3138, -0.3027])\n","Predicted tensor([0.0154, 0.8002, 0.2941], grad_fn=<SelectBackward>) Actual tensor([-0.6726, -0.7686, -0.3279])\n","Predicted tensor([0.5293, 0.9947, 0.0335], grad_fn=<SelectBackward>) Actual tensor([ 1.2817,  2.2953, -0.2620])\n","Predicted tensor([ 0.7617, -0.1890, -0.1753], grad_fn=<SelectBackward>) Actual tensor([ 1.1161, -0.1404, -0.2321])\n","Predicted tensor([ 0.6794, -0.2895, -0.2406], grad_fn=<SelectBackward>) Actual tensor([-0.4154, -0.7497, -0.2980])\n","Predicted tensor([ 0.7043, -0.3657, -0.2659], grad_fn=<SelectBackward>) Actual tensor([ 1.0878, -0.7672, -0.3270])\n","Predicted tensor([-0.5341,  0.4789, -0.1501], grad_fn=<SelectBackward>) Actual tensor([-0.1312, -0.2256, -0.2352])\n","Predicted tensor([3.0594e-01, 5.0417e-01, 3.9500e-04], grad_fn=<SelectBackward>) Actual tensor([2.2822, 0.3282, 0.0494])\n","Predicted tensor([-0.0926,  0.3370, -0.0999], grad_fn=<SelectBackward>) Actual tensor([-0.7951, -0.4743, -0.3184])\n","Predicted tensor([-0.6074,  0.8189, -0.2070], grad_fn=<SelectBackward>) Actual tensor([-0.6080,  2.8221, -0.2755])\n","Predicted tensor([-0.3773,  0.4611, -0.1491], grad_fn=<SelectBackward>) Actual tensor([-0.2597,  0.1305, -0.3390])\n","Predicted tensor([ 0.7676, -0.0073, -0.1939], grad_fn=<SelectBackward>) Actual tensor([ 1.2155,  0.3231, -0.2692])\n","Predicted tensor([-0.0819, -0.4098, -0.0977], grad_fn=<SelectBackward>) Actual tensor([-0.4635, -0.7503, -0.1987])\n","Predicted tensor([0.7672, 0.4206, 0.0579], grad_fn=<SelectBackward>) Actual tensor([ 0.9130,  0.1691, -0.0705])\n","Predicted tensor([ 0.7052, -0.4448, -0.2523], grad_fn=<SelectBackward>) Actual tensor([ 1.2544, -0.6909, -0.3135])\n","Predicted tensor([ 0.6521, -0.2664, -0.2126], grad_fn=<SelectBackward>) Actual tensor([ 1.2336, -0.5548, -0.3470])\n","Predicted tensor([ 0.6955, -0.3688, -0.2593], grad_fn=<SelectBackward>) Actual tensor([ 0.2509, -0.0612, -0.1964])\n","Predicted tensor([-0.8406,  0.5794, -0.1323], grad_fn=<SelectBackward>) Actual tensor([-0.6250, -0.0743, -0.4439])\n","Predicted tensor([ 0.1205, -0.3724, -0.0888], grad_fn=<SelectBackward>) Actual tensor([-0.3506, -0.4896, -0.2203])\n","Predicted tensor([-0.3162,  0.9817,  2.9021], grad_fn=<SelectBackward>) Actual tensor([ 0.0923, -0.2743,  2.4626])\n","Predicted tensor([-0.6663, -0.4856, -0.1103], grad_fn=<SelectBackward>) Actual tensor([-0.7271, -0.7867, -0.2866])\n","Predicted tensor([ 0.6993, -0.3604, -0.2590], grad_fn=<SelectBackward>) Actual tensor([ 1.1410, -0.6795, -0.3295])\n","Predicted tensor([-0.6695, -0.4861, -0.1062], grad_fn=<SelectBackward>) Actual tensor([-0.6981, -0.6692, -0.2309])\n","Predicted tensor([-0.5183, -0.0098, -0.1081], grad_fn=<SelectBackward>) Actual tensor([-0.6791, -0.4317, -0.3226])\n","Predicted tensor([ 0.7058, -0.3470, -0.2611], grad_fn=<SelectBackward>) Actual tensor([ 1.1096, -0.7457, -0.3284])\n","Predicted tensor([-0.5723, -0.3447, -0.1163], grad_fn=<SelectBackward>) Actual tensor([-1.7780,  0.2820,  0.8713])\n","Predicted tensor([-0.6113, -0.5268, -0.0855], grad_fn=<SelectBackward>) Actual tensor([-0.7622, -0.7306, -0.2736])\n","Predicted tensor([ 0.6735, -0.0243, -0.1860], grad_fn=<SelectBackward>) Actual tensor([ 1.1316, -0.2647, -0.3156])\n","Predicted tensor([-0.0853, -0.2577, -0.1180], grad_fn=<SelectBackward>) Actual tensor([-0.7395, -0.5634, -0.3109])\n","Predicted tensor([ 0.6992, -0.3752, -0.2601], grad_fn=<SelectBackward>) Actual tensor([ 0.0587, -0.7119, -0.2716])\n","Predicted tensor([-0.5694,  0.8029, -0.2453], grad_fn=<SelectBackward>) Actual tensor([-0.9452, -0.2916, -0.4941])\n","Predicted tensor([-0.4537, -0.4996, -0.1050], grad_fn=<SelectBackward>) Actual tensor([-0.8359, -0.5494, -0.2637])\n","Predicted tensor([ 0.4649,  1.5364, -0.5522], grad_fn=<SelectBackward>) Actual tensor([ 1.3787,  2.7169, -0.2161])\n","Predicted tensor([0.8012, 0.4807, 0.4948], grad_fn=<SelectBackward>) Actual tensor([-1.8461,  1.4929, -0.2923])\n","Predicted tensor([-0.7710, -0.4075, -0.1108], grad_fn=<SelectBackward>) Actual tensor([-0.7572, -0.6758, -0.2680])\n","Predicted tensor([ 0.0905, -0.3050, -0.1080], grad_fn=<SelectBackward>) Actual tensor([-0.3219, -0.6909, -0.2852])\n","Predicted tensor([ 0.6730, -0.2218, -0.2361], grad_fn=<SelectBackward>) Actual tensor([-0.0790, -0.6741, -0.3075])\n","Predicted tensor([ 0.6526,  0.0389, -0.1510], grad_fn=<SelectBackward>) Actual tensor([ 1.0609,  0.0348, -0.3270])\n","Predicted tensor([-1.0799, -0.7066,  4.6128], grad_fn=<SelectBackward>) Actual tensor([-1.1722, -0.3088,  5.1106])\n","Predicted tensor([ 0.5522,  0.3756, -0.1056], grad_fn=<SelectBackward>) Actual tensor([-1.4703,  1.6973, -0.3372])\n","Predicted tensor([ 0.3516,  1.8886, -0.2618], grad_fn=<SelectBackward>) Actual tensor([ 1.3344,  3.7741, -0.2744])\n","Predicted tensor([-0.5481,  0.0277,  0.0748], grad_fn=<SelectBackward>) Actual tensor([1.2784, 2.2241, 0.0876])\n","Predicted tensor([-0.6002, -0.4936, -0.1082], grad_fn=<SelectBackward>) Actual tensor([-0.0500,  0.2713, -0.1248])\n","Predicted tensor([-0.5913, -0.2764, -0.1151], grad_fn=<SelectBackward>) Actual tensor([ 0.0083, -0.3448,  0.8633])\n","Predicted tensor([-0.7091, -0.4750, -0.0963], grad_fn=<SelectBackward>) Actual tensor([-0.6523, -0.6607, -0.2182])\n","Predicted tensor([ 0.5725, -0.0678, -0.1388], grad_fn=<SelectBackward>) Actual tensor([ 0.8850, -0.3402, -0.2563])\n","Predicted tensor([ 0.1954, -0.3323, -0.1271], grad_fn=<SelectBackward>) Actual tensor([ 1.1105, -0.7775, -0.3300])\n","Predicted tensor([-0.4906, -0.2554, -0.1212], grad_fn=<SelectBackward>) Actual tensor([-0.7309,  0.8760, -0.0805])\n","Predicted tensor([ 0.1787, -0.2934, -0.1042], grad_fn=<SelectBackward>) Actual tensor([ 0.3559, -0.2391, -0.2322])\n","Predicted tensor([0.1144, 0.3891, 1.8171], grad_fn=<SelectBackward>) Actual tensor([ 0.1025, -0.1561,  4.5042])\n","Predicted tensor([ 0.3593,  0.3489, -0.1012], grad_fn=<SelectBackward>) Actual tensor([0.7018, 4.2966, 1.4263])\n","Predicted tensor([-0.8754, -0.0021, -0.1494], grad_fn=<SelectBackward>) Actual tensor([-1.8787,  0.0537, -0.3910])\n","Predicted tensor([-1.3094,  0.1964, -0.0763], grad_fn=<SelectBackward>) Actual tensor([ 1.4648, -0.7239, -0.2849])\n","Predicted tensor([ 0.6978, -0.3209, -0.2548], grad_fn=<SelectBackward>) Actual tensor([ 1.2235, -0.3331, -0.2667])\n","Predicted tensor([ 0.7764, -0.4242, -0.2758], grad_fn=<SelectBackward>) Actual tensor([ 1.1467,  0.1419, -0.2080])\n","Predicted tensor([ 0.0002, -0.1132, -0.1076], grad_fn=<SelectBackward>) Actual tensor([-1.9883, -0.3428,  0.4631])\n","Predicted tensor([ 0.6471, -0.2093, -0.2038], grad_fn=<SelectBackward>) Actual tensor([-0.0722,  1.1036, -0.1481])\n","Predicted tensor([-0.7121, -0.3569, -0.1343], grad_fn=<SelectBackward>) Actual tensor([-0.5658, -0.7634, -0.2339])\n","Predicted tensor([-0.0713, -0.3702, -0.0965], grad_fn=<SelectBackward>) Actual tensor([-0.5842, -0.7210, -0.2636])\n","Predicted tensor([-0.2894, -0.2265, -0.0937], grad_fn=<SelectBackward>) Actual tensor([-0.3364, -0.5606, -0.3323])\n","Predicted tensor([0.6709, 0.6202, 0.1990], grad_fn=<SelectBackward>) Actual tensor([-0.0271,  0.6438,  0.1914])\n","Predicted tensor([-0.4924, -0.3206, -0.1143], grad_fn=<SelectBackward>) Actual tensor([-0.7248, -0.7433, -0.3196])\n","Predicted tensor([-0.0354, -0.1851, -0.1259], grad_fn=<SelectBackward>) Actual tensor([-1.5316, -0.5856,  0.0231])\n","Predicted tensor([-0.6421, -0.4293, -0.1297], grad_fn=<SelectBackward>) Actual tensor([-0.8517, -0.6774, -0.2734])\n","Predicted tensor([-0.4407, -0.3807, -0.0917], grad_fn=<SelectBackward>) Actual tensor([-0.6229, -0.7819, -0.3044])\n","Predicted tensor([0.4336, 1.2279, 0.0978], grad_fn=<SelectBackward>) Actual tensor([ 1.2422,  2.9879, -0.2150])\n","Predicted tensor([-0.1887, -0.4381, -0.1040], grad_fn=<SelectBackward>) Actual tensor([-0.5311, -0.7265, -0.3123])\n","Predicted tensor([ 0.7223, -0.3347, -0.2382], grad_fn=<SelectBackward>) Actual tensor([ 1.0757, -0.6685, -0.3249])\n","Predicted tensor([-0.6502, -0.3706, -0.1081], grad_fn=<SelectBackward>) Actual tensor([-0.7679, -0.7681, -0.2649])\n","Predicted tensor([ 0.7024, -0.3822, -0.2664], grad_fn=<SelectBackward>) Actual tensor([-0.1255,  0.0740, -0.2089])\n","Predicted tensor([-1.2578,  0.6708, -0.1139], grad_fn=<SelectBackward>) Actual tensor([ 0.6422,  0.8222, -0.0503])\n","Predicted tensor([ 0.0482, -0.2760, -0.1512], grad_fn=<SelectBackward>) Actual tensor([ 1.1132, -0.7485, -0.3314])\n","Predicted tensor([-0.4636, -0.4428, -0.1178], grad_fn=<SelectBackward>) Actual tensor([ 0.0930,  0.4618, -0.1663])\n","Predicted tensor([-0.4824, -0.4037, -0.1057], grad_fn=<SelectBackward>) Actual tensor([-0.7870, -0.4739, -0.2760])\n","Predicted tensor([-0.9015,  0.4956, -0.1192], grad_fn=<SelectBackward>) Actual tensor([-0.5226,  0.0521, -0.3881])\n","Predicted tensor([-1.2235,  0.6506,  0.1831], grad_fn=<SelectBackward>) Actual tensor([ 1.8616,  0.9596, -0.2092])\n","Predicted tensor([0.0726, 0.3138, 0.2947], grad_fn=<SelectBackward>) Actual tensor([1.1837, 4.9788, 1.6275])\n","Predicted tensor([0.4086, 0.8743, 0.0701], grad_fn=<SelectBackward>) Actual tensor([-2.0366,  0.1398,  0.2025])\n","Predicted tensor([-0.0086, -0.4063, -0.0854], grad_fn=<SelectBackward>) Actual tensor([-0.4499, -0.7611, -0.2108])\n","Predicted tensor([ 0.1204,  0.1214, -0.0994], grad_fn=<SelectBackward>) Actual tensor([-1.6047,  0.4372,  1.7550])\n","Predicted tensor([ 0.7042, -0.3105, -0.2638], grad_fn=<SelectBackward>) Actual tensor([ 1.0749, -0.7602, -0.3260])\n","Predicted tensor([0.7333, 0.4630, 0.0846], grad_fn=<SelectBackward>) Actual tensor([ 1.9908,  2.0358, -0.1603])\n","Predicted tensor([-0.4512,  1.0920,  0.8033], grad_fn=<SelectBackward>) Actual tensor([-1.3885,  1.2970,  0.7466])\n","Predicted tensor([-1.4311,  0.5207, -0.0553], grad_fn=<SelectBackward>) Actual tensor([-1.9510,  0.5235, -0.5714])\n","Predicted tensor([-0.5848, -0.5130, -0.1072], grad_fn=<SelectBackward>) Actual tensor([-0.5828, -0.7630, -0.3105])\n","Predicted tensor([ 0.6283, -0.0860, -0.1800], grad_fn=<SelectBackward>) Actual tensor([-0.0852, -0.6269, -0.2958])\n","Predicted tensor([-0.1689,  0.3714,  0.6869], grad_fn=<SelectBackward>) Actual tensor([-1.8769,  0.4048,  0.8063])\n","Predicted tensor([0.3880, 0.1350, 0.4025], grad_fn=<SelectBackward>) Actual tensor([-0.9733, -0.0803,  0.4030])\n","Predicted tensor([-0.5000,  0.9204,  3.1114], grad_fn=<SelectBackward>) Actual tensor([-0.7085,  0.1535,  4.2337])\n","Predicted tensor([-0.3335, -0.4589, -0.1089], grad_fn=<SelectBackward>) Actual tensor([-0.5335, -0.7130, -0.3113])\n","Predicted tensor([ 0.3667, -0.1444,  0.0753], grad_fn=<SelectBackward>) Actual tensor([-0.7768,  0.0404, -0.0984])\n","Predicted tensor([-0.6669, -0.1592, -0.0923], grad_fn=<SelectBackward>) Actual tensor([-0.3157, -0.1704, -0.3408])\n","Predicted tensor([ 0.6196,  0.5269, -0.0131], grad_fn=<SelectBackward>) Actual tensor([-0.6933, -0.5342, -0.3093])\n","Predicted tensor([-0.6969,  0.3768, -0.1352], grad_fn=<SelectBackward>) Actual tensor([-0.0613,  0.4063, -0.3358])\n","Predicted tensor([-0.5591, -0.4496, -0.1184], grad_fn=<SelectBackward>) Actual tensor([ 1.0961, -0.7365, -0.3330])\n","Predicted tensor([-0.0990, -0.4044, -0.0852], grad_fn=<SelectBackward>) Actual tensor([-0.3992, -0.4587, -0.1905])\n","Predicted tensor([-0.2362,  0.0412,  0.0157], grad_fn=<SelectBackward>) Actual tensor([-1.4238, -0.0619,  0.0385])\n","Predicted tensor([0.1979, 1.3522, 0.0519], grad_fn=<SelectBackward>) Actual tensor([-0.0271, -0.1613, -0.2814])\n","Predicted tensor([ 0.7160, -0.3210, -0.2775], grad_fn=<SelectBackward>) Actual tensor([ 1.3041, -0.3727, -0.2758])\n","Predicted tensor([-0.4479,  1.1365,  2.1493], grad_fn=<SelectBackward>) Actual tensor([-0.8121,  1.9955,  3.0507])\n","Predicted tensor([ 0.7045, -0.3035, -0.2506], grad_fn=<SelectBackward>) Actual tensor([ 0.5058,  0.5647, -0.3271])\n","Predicted tensor([ 0.6889, -0.3663, -0.2456], grad_fn=<SelectBackward>) Actual tensor([ 0.5522, -0.7270, -0.2558])\n","Predicted tensor([ 0.6729, -0.1797, -0.2239], grad_fn=<SelectBackward>) Actual tensor([-0.4057, -0.7858, -0.3017])\n","Predicted tensor([ 0.0638, -0.1361, -0.1235], grad_fn=<SelectBackward>) Actual tensor([-0.3213, -0.6811, -0.3044])\n","Predicted tensor([ 0.6903, -0.3289, -0.2436], grad_fn=<SelectBackward>) Actual tensor([-0.3158, -0.6807, -0.2767])\n","Predicted tensor([ 0.1465, -0.1469, -0.1399], grad_fn=<SelectBackward>) Actual tensor([ 1.1093, -0.7608, -0.3306])\n","Predicted tensor([-0.3227, -0.4956, -0.0696], grad_fn=<SelectBackward>) Actual tensor([-0.7786, -0.4919, -0.2552])\n","Predicted tensor([-0.0653, -0.1828, -0.0977], grad_fn=<SelectBackward>) Actual tensor([-0.3271, -0.7946, -0.3249])\n","Predicted tensor([ 0.0826, -0.2631, -0.0701], grad_fn=<SelectBackward>) Actual tensor([-0.7217, -0.7610, -0.2985])\n","Predicted tensor([-1.0204, -0.5502,  4.5948], grad_fn=<SelectBackward>) Actual tensor([-1.0058, -0.4719,  4.9153])\n","Predicted tensor([-0.5838, -0.4828, -0.1249], grad_fn=<SelectBackward>) Actual tensor([-0.5786, -0.2732, -0.1516])\n","Predicted tensor([-0.4626, -0.3979, -0.0934], grad_fn=<SelectBackward>) Actual tensor([-0.3665, -0.4535, -0.3498])\n","Predicted tensor([0.2852, 1.3196, 0.0936], grad_fn=<SelectBackward>) Actual tensor([-1.1290, -0.7668,  5.1437])\n","Predicted tensor([0.4838, 1.0836, 0.0816], grad_fn=<SelectBackward>) Actual tensor([ 1.3249,  1.5326, -0.2425])\n","Predicted tensor([-0.7359, -0.4499, -0.0539], grad_fn=<SelectBackward>) Actual tensor([ 0.4701,  4.2248, -0.0923])\n","Predicted tensor([ 0.7547, -0.3980, -0.2966], grad_fn=<SelectBackward>) Actual tensor([ 0.8882, -0.2488, -0.2860])\n","Predicted tensor([-0.0045, -0.3408, -0.1055], grad_fn=<SelectBackward>) Actual tensor([-0.4702, -0.6920, -0.2637])\n","Predicted tensor([0.4503, 1.6831, 0.0463], grad_fn=<SelectBackward>) Actual tensor([ 0.9982,  2.4616, -0.1218])\n","Predicted tensor([ 0.1877, -0.2232, -0.1493], grad_fn=<SelectBackward>) Actual tensor([ 0.2372,  0.3916, -0.2491])\n","Predicted tensor([-0.0175,  0.2457, -0.1093], grad_fn=<SelectBackward>) Actual tensor([ 1.3903, -0.0117, -0.3614])\n","Predicted tensor([ 0.6967, -0.3552, -0.2628], grad_fn=<SelectBackward>) Actual tensor([ 1.1221, -0.5924, -0.3334])\n","Predicted tensor([-0.6555, -0.4767, -0.1024], grad_fn=<SelectBackward>) Actual tensor([-0.7805, -0.6495, -0.2740])\n","Predicted tensor([ 0.4467,  0.1742, -0.2134], grad_fn=<SelectBackward>) Actual tensor([-0.3896, -0.7597, -0.3175])\n","Predicted tensor([ 0.6866, -0.1661, -0.2108], grad_fn=<SelectBackward>) Actual tensor([ 1.1596, -0.3553, -0.3385])\n","Predicted tensor([-0.5463, -0.4562, -0.0999], grad_fn=<SelectBackward>) Actual tensor([ 1.7499,  0.3653, -0.3753])\n","Predicted tensor([ 0.0935, -0.1910, -0.1291], grad_fn=<SelectBackward>) Actual tensor([ 1.0369, -0.3249, -0.2817])\n","Predicted tensor([ 0.0463, -0.2803, -0.0644], grad_fn=<SelectBackward>) Actual tensor([ 1.1128, -0.3447, -0.3441])\n","Predicted tensor([-1.0124, -0.5326,  4.5979], grad_fn=<SelectBackward>) Actual tensor([-1.0938, -0.4092,  5.1631])\n","Predicted tensor([-0.0323, -0.1816, -0.1473], grad_fn=<SelectBackward>) Actual tensor([-2.2536e+00, -3.9798e-01,  5.2901e-04])\n","Predicted tensor([-0.6549, -0.4497, -0.1091], grad_fn=<SelectBackward>) Actual tensor([-0.5811, -0.7463, -0.2418])\n","Predicted tensor([ 0.6622, -0.2217, -0.2111], grad_fn=<SelectBackward>) Actual tensor([-0.1563,  1.8131, -0.1433])\n","Predicted tensor([-0.6178, -0.1210, -0.1660], grad_fn=<SelectBackward>) Actual tensor([-1.9834,  0.7540, -0.5496])\n","Predicted tensor([ 0.7030,  0.2485, -0.0668], grad_fn=<SelectBackward>) Actual tensor([ 0.8945, -0.6681, -0.0480])\n","Predicted tensor([-0.3296, -0.2346, -0.1300], grad_fn=<SelectBackward>) Actual tensor([1.3384, 5.2999, 2.2260])\n","Predicted tensor([-0.5601, -0.4482, -0.1176], grad_fn=<SelectBackward>) Actual tensor([-1.2324,  0.2588, -0.1500])\n","Predicted tensor([-0.5360, -0.2374, -0.1364], grad_fn=<SelectBackward>) Actual tensor([ 0.3732, -0.7164, -0.3161])\n","Predicted tensor([ 0.3060, -0.2085, -0.1274], grad_fn=<SelectBackward>) Actual tensor([ 1.1271, -0.6576, -0.3308])\n","Predicted tensor([-0.3262, -0.5030, -0.0709], grad_fn=<SelectBackward>) Actual tensor([-0.4897, -0.7610, -0.2792])\n","Predicted tensor([-0.9597,  0.7996, -0.0604], grad_fn=<SelectBackward>) Actual tensor([-1.5905,  2.0691, -0.3253])\n","Predicted tensor([ 0.5403,  0.1846, -0.2065], grad_fn=<SelectBackward>) Actual tensor([0.1543, 2.1871, 0.1641])\n","Predicted tensor([ 0.1739, -0.3811, -0.1200], grad_fn=<SelectBackward>) Actual tensor([ 0.0412, -0.6724, -0.2228])\n","Predicted tensor([ 0.1431, -0.2103, -0.1120], grad_fn=<SelectBackward>) Actual tensor([-0.2270, -0.4086, -0.3254])\n","Predicted tensor([ 0.6959, -0.3726, -0.2568], grad_fn=<SelectBackward>) Actual tensor([-0.3605,  1.0948, -0.1158])\n","Predicted tensor([ 0.3174, -0.4425, -0.1303], grad_fn=<SelectBackward>) Actual tensor([-0.7670, -0.6654, -0.2800])\n","Predicted tensor([ 0.6941, -0.2904, -0.2565], grad_fn=<SelectBackward>) Actual tensor([-0.7098, -0.6247, -0.3008])\n","Predicted tensor([-0.5495, -0.4696, -0.1041], grad_fn=<SelectBackward>) Actual tensor([-0.7480, -0.6639, -0.2803])\n","Predicted tensor([-0.3743, -0.3537, -0.0975], grad_fn=<SelectBackward>) Actual tensor([-0.6635, -0.3798,  0.3310])\n","Predicted tensor([0.0503, 0.0161, 0.4867], grad_fn=<SelectBackward>) Actual tensor([-0.4579, -0.7480, -0.3065])\n","Predicted tensor([-0.7916, -0.2528,  4.2193], grad_fn=<SelectBackward>) Actual tensor([-0.6086, -0.1322,  4.8994])\n","Predicted tensor([ 0.1615, -0.2683, -0.1328], grad_fn=<SelectBackward>) Actual tensor([-0.0343, -0.7770, -0.3014])\n","Predicted tensor([ 0.1627,  0.4416, -0.0714], grad_fn=<SelectBackward>) Actual tensor([ 0.7206,  0.3673, -0.2590])\n","Predicted tensor([ 0.6992, -0.2457, -0.2367], grad_fn=<SelectBackward>) Actual tensor([ 1.1293, -0.5409, -0.3275])\n","Predicted tensor([-0.5766, -0.4794, -0.1263], grad_fn=<SelectBackward>) Actual tensor([-0.7108, -0.5464, -0.2448])\n","Predicted tensor([-0.6819, -0.5442, -0.0625], grad_fn=<SelectBackward>) Actual tensor([-0.7350, -0.6008, -0.2561])\n","Predicted tensor([0.3390, 0.0964, 0.0142], grad_fn=<SelectBackward>) Actual tensor([ 1.3143, -0.1645, -0.3488])\n","Predicted tensor([-0.5805, -0.5319, -0.0770], grad_fn=<SelectBackward>) Actual tensor([-0.7216, -0.2166, -0.2361])\n","Predicted tensor([ 0.7314, -0.4442, -0.2593], grad_fn=<SelectBackward>) Actual tensor([ 1.2183, -0.5575, -0.2829])\n","Predicted tensor([0.5894, 0.9218, 0.0370], grad_fn=<SelectBackward>) Actual tensor([ 0.9208, -0.7239, -0.3345])\n","Predicted tensor([ 0.8173,  0.0272, -0.1952], grad_fn=<SelectBackward>) Actual tensor([ 1.1210, -0.6388, -0.3337])\n","Predicted tensor([-1.3267,  0.2287, -0.0820], grad_fn=<SelectBackward>) Actual tensor([-2.2046, -0.2184, -0.5736])\n","Predicted tensor([-0.6645, -0.4696, -0.1211], grad_fn=<SelectBackward>) Actual tensor([-0.7750, -0.6805, -0.2761])\n","Predicted tensor([-0.3891, -0.4176, -0.1286], grad_fn=<SelectBackward>) Actual tensor([-0.5081, -0.3793, -0.2283])\n","Predicted tensor([-0.6406, -0.5103, -0.0903], grad_fn=<SelectBackward>) Actual tensor([-0.7839, -0.7588, -0.2828])\n","Predicted tensor([0.3852, 0.4383, 0.1606], grad_fn=<SelectBackward>) Actual tensor([0.9687, 2.1700, 0.6473])\n","Predicted tensor([ 0.1022, -0.0393, -0.1227], grad_fn=<SelectBackward>) Actual tensor([-1.3851, -0.0372,  0.2679])\n","Predicted tensor([ 0.7010, -0.3453, -0.2599], grad_fn=<SelectBackward>) Actual tensor([ 1.1105, -0.7628, -0.3282])\n","Predicted tensor([-0.6346, -0.4736, -0.0991], grad_fn=<SelectBackward>) Actual tensor([-0.7288, -0.7919, -0.2843])\n","Predicted tensor([-0.1643, -0.4307, -0.0920], grad_fn=<SelectBackward>) Actual tensor([ 1.1708,  0.5787, -0.3516])\n","Predicted tensor([ 0.0965,  0.6521, -0.0654], grad_fn=<SelectBackward>) Actual tensor([ 0.4248, -0.4073, -0.2445])\n","Predicted tensor([ 0.2848,  0.6374, -0.0672], grad_fn=<SelectBackward>) Actual tensor([0.8984, 2.7553, 0.0691])\n","Predicted tensor([-0.2597, -0.0211, -0.1107], grad_fn=<SelectBackward>) Actual tensor([-0.5884, -0.3743, -0.2986])\n","Batch: 10 completed\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"kTWVIApknABA","colab_type":"code","colab":{}},"source":["outputs=sc_Y.inverse_transform(outputs.detach().numpy())\n","y=sc_Y.inverse_transform(y.detach().numpy())"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"FczNRsIIqVBz","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":3484},"outputId":"ee7966e4-3fc5-4026-a28e-ad6b4902ea16","executionInfo":{"status":"ok","timestamp":1559454970840,"user_tz":240,"elapsed":538,"user":{"displayName":"Gautham Bekal","photoUrl":"","userId":"01650273333839084339"}}},"source":["#VELOCITY IN ACTUAL FORMAT AFTER INVERSE TRANSFORMATION FOR THE LAST BATCH ie for 200 observations\n","for i,j in zip(outputs,y):\n","  print(\"Predicted \"+str(i)+\" Actual \"+str(j))"],"execution_count":52,"outputs":[{"output_type":"stream","text":["Predicted [0.80949694 0.08633223 0.17030495] Actual [0.21220477 0.09871712 0.01944595]\n","Predicted [0.14654349 0.22513364 0.3787018 ] Actual [ 0.05192093  0.09849536 -0.20631582]\n","Predicted [0.5341523  0.08004943 0.37939703] Actual [0.2949092  0.00810157 0.1672526 ]\n","Predicted [0.13626869 0.14793602 0.5223967 ] Actual [ 0.24533394  0.137076   -0.11882836]\n","Predicted [0.5840819  0.08329201 0.410675  ] Actual [0.29143423 0.0228524  0.0730285 ]\n","Predicted [0.6770322  0.12007566 0.48750973] Actual [0.173878   0.01444838 0.01581042]\n","Predicted [0.39587352 0.19294605 0.45150322] Actual [ 0.39031273  0.07303512 -0.03339923]\n","Predicted [0.5249918 0.1484207 0.4024269] Actual [1.4545763  0.40429106 0.30345342]\n","Predicted [0.72522336 0.1486159  0.30218923] Actual [1.25727    0.2505553  0.08909374]\n","Predicted [0.7041166  0.20499873 0.49601766] Actual [0.2865521  0.00998913 0.03110104]\n","Predicted [0.4779874  0.20255388 0.2433021 ] Actual [-0.05998774  0.12393064  0.03849726]\n","Predicted [0.216334   0.05174291 0.50444037] Actual [0.20704831 0.00898395 0.04582214]\n","Predicted [0.53896946 0.16408116 1.5516332 ] Actual [1.4198432  0.4543949  0.83327305]\n","Predicted [0.4818482  0.08016898 0.45243216] Actual [ 1.0848849   0.07908547 -0.02855337]\n","Predicted [0.7702475  0.08770503 0.2947029 ] Actual [0.3744846  0.14290231 0.16071796]\n","Predicted [0.6461182 0.1550461 0.517238 ] Actual [0.42740932 0.2718477  0.0144751 ]\n","Predicted [0.6629047  0.34489894 0.7603314 ] Actual [-0.61859864  0.11361339  0.89349276]\n","Predicted [-0.10075369  0.20920771  0.8841703 ] Actual [-0.23858072  0.10263007  0.31806332]\n","Predicted [0.8411682  0.08058933 0.14771247] Actual [1.0589951  0.01682927 0.05019789]\n","Predicted [ 0.593484    0.12975383 -0.01981682] Actual [ 1.2166519   0.41425055 -0.00840986]\n","Predicted [0.81066513 0.10119351 0.19997448] Actual [0.48854396 0.15489393 1.1844223 ]\n","Predicted [0.54305965 0.08318862 0.45150828] Actual [1.3062912  0.3340494  0.22715962]\n","Predicted [0.81689984 0.07872776 0.22900838] Actual [0.9639562  0.03896633 0.05952888]\n","Predicted [0.35436967 0.2084693  1.2157886 ] Actual [0.23540424 0.00639607 0.00121176]\n","Predicted [0.81257933 0.07061543 0.14625591] Actual [0.5409025  0.275472   0.38164324]\n","Predicted [0.5852417  0.06945061 0.45456332] Actual [0.52023506 0.00222497 0.155976  ]\n","Predicted [0.5020591  0.09091056 0.45543012] Actual [0.29213542 0.0107487  0.09285318]\n","Predicted [0.35342193 0.06993893 0.49266168] Actual [0.24543595 0.00616832 0.04307174]\n","Predicted [0.7152907  0.14200607 0.4851445 ] Actual [0.81345975 0.24463928 0.04162513]\n","Predicted [0.5036179  0.1612782  0.42521888] Actual [0.35700554 0.18214245 0.0563957 ]\n","Predicted [0.4967745 0.2617861 1.326657 ] Actual [0.18037273 0.00487503 0.00278395]\n","Predicted [0.73309785 0.29365015 0.7720234 ] Actual [1.0791026  0.50664157 0.14294678]\n","Predicted [0.83996546 0.09979969 0.32758677] Actual [1.002922   0.10775741 0.20670477]\n","Predicted [0.80211765 0.08334401 0.1886115 ] Actual [0.29865307 0.00797987 0.06634276]\n","Predicted [0.81355375 0.07085668 0.13472247] Actual [0.9899068  0.00510852 0.0047388 ]\n","Predicted [0.2440489  0.20917831 0.38120666] Actual [0.42935756 0.09380095 0.20006603]\n","Predicted [0.6303774  0.21331401 0.70155245] Actual [1.5391849  0.184501   0.80582184]\n","Predicted [0.44708377 0.18593638 0.4880686 ] Actual [0.12404657 0.0530832  0.02305549]\n","Predicted [0.21035333 0.2648588  0.26008022] Actual [0.21010534 0.59290504 0.1142553 ]\n","Predicted [0.3161749  0.20626396 0.38342   ] Actual [ 0.37023526  0.15212733 -0.02076573]\n","Predicted [0.84268606 0.12955602 0.28795666] Actual [1.0486732  0.18365574 0.12773019]\n","Predicted [0.4520249  0.06363972 0.49281138] Actual [0.2765389  0.00787464 0.27777672]\n","Predicted [0.8424893  0.19962808 0.82399905] Actual [0.9095499  0.15844685 0.55070823]\n","Predicted [0.81399673 0.05791217 0.16361684] Actual [1.0665553  0.01761008 0.03336566]\n","Predicted [0.78957546 0.0871162  0.24816   ] Actual [ 1.0569897   0.03989772 -0.03794069]\n","Predicted [0.8095348  0.07035996 0.14875168] Actual [0.605053   0.12073296 0.2826628 ]\n","Predicted [0.10310952 0.22562945 0.41904566] Actual [ 0.20224826  0.11858722 -0.2441687 ]\n","Predicted [0.5451063  0.06975891 0.51167583] Actual [0.3284675  0.0505704  0.23173481]\n","Predicted [0.3442885  0.29152265 6.877718  ] Actual [0.5321504  0.08583802 5.942363  ]\n","Predicted [0.18326344 0.0512287  0.4658681 ] Actual [0.15531792 0.00191608 0.09079581]\n","Predicted [0.81126803 0.07172462 0.14954293] Actual [ 1.0143906e+00  1.9469058e-02 -5.2476622e-04]\n","Predicted [0.18182124 0.05115086 0.47465816] Actual [0.16864015 0.02116506 0.20923826]\n","Predicted [0.25131592 0.12915239 0.47069332] Actual [0.17737664 0.06004758 0.01397424]\n","Predicted [0.8142416  0.07391881 0.14486706] Actual [0.99996614 0.00863611 0.00162452]\n","Predicted [0.22648533 0.07429349 0.45321795] Actual [-0.3279467  0.1769345  2.5553367]\n","Predicted [0.20855625 0.04447442 0.5186723 ] Actual [0.13916464 0.01111327 0.11831164]\n","Predicted [0.7994022  0.12676424 0.30486053] Actual [1.0100542  0.08740815 0.02889263]\n","Predicted [0.4504637  0.08854646 0.4495751 ] Actual [0.14960362 0.03849084 0.03888243]\n","Predicted [0.8112428  0.06930862 0.14707726] Actual [0.5166686  0.01417211 0.12259894]\n","Predicted [0.22785379 0.26223835 0.17855012] Actual [ 0.05501164  0.0829966  -0.35099304]\n","Predicted [0.2810413  0.04892977 0.47722974] Actual [0.10526765 0.04077938 0.13950443]\n","Predicted [ 0.7034656   0.38235632 -0.47472668] Actual [1.1236817  0.57568175 0.24077538]\n","Predicted [0.8581214  0.20946452 1.7538885 ] Actual [-0.35928062  0.37523666  0.07860111]\n","Predicted [0.13514908 0.06401684 0.46498305] Actual [0.14147471 0.0200815  0.13030207]\n","Predicted [0.5312999  0.08080267 0.47086436] Actual [0.34164652 0.01760794 0.09369462]\n","Predicted [0.7991934  0.09443142 0.19808555] Actual [0.45336533 0.02035079 0.04611378]\n","Predicted [0.78980845 0.13711344 0.3793272 ] Actual [0.9775657  0.13644582 0.00477272]\n","Predicted [-6.9298348e-03  1.5043436e-02  1.0518987e+01] Actual [-0.04938706  0.08017511 11.57845   ]\n","Predicted [0.74361724 0.19225918 0.47598082] Actual [-0.18646975  0.40870923 -0.01691104]\n","Predicted [0.6513921  0.44003385 0.14352477] Actual [1.1033226  0.7488068  0.11662071]\n","Predicted [0.23761983 0.13528825 0.86000144] Actual [1.0775636  0.49496937 0.88723135]\n","Predicted [0.21367984 0.04991697 0.47049314] Actual [0.46669617 0.17517754 0.43507594]\n","Predicted [0.21778427 0.0854785  0.4557152 ] Actual [0.49349278 0.07428404 2.5382738 ]\n","Predicted [0.16358413 0.05296431 0.49565816] Actual [0.18970264 0.02255555 0.23625794]\n","Predicted [0.7529394  0.11965352 0.4052599 ] Actual [0.8966482  0.07503206 0.1551404 ]\n","Predicted [0.5795631  0.07632608 0.43012872] Actual [ 1.0003756   0.00341901 -0.00158132]\n","Predicted [0.26405182 0.08893074 0.44277176] Actual [0.1535498  0.27421206 0.5293403 ]\n","Predicted [0.57186747 0.08270853 0.4789611 ] Actual [0.6533635  0.09159456 0.20638198]\n","Predicted [0.5422932 0.1944761 4.5683846] Actual [ 0.5368111   0.10518127 10.287843  ]\n","Predicted [0.6549354  0.18789409 0.4853954 ] Actual [0.81242937 0.83436894 3.7364435 ]\n","Predicted [0.08711616 0.13040234 0.38281357] Actual [-0.37425748  0.13954479 -0.13157594]\n","Predicted [-0.11246511  0.16290972  0.5383706 ] Actual [1.1632776  0.01220463 0.09429806]\n","Predicted [0.8105737  0.0781962  0.15828049] Actual [1.0523306  0.0762044  0.13294733]\n","Predicted [0.8467383  0.06128249 0.11363929] Actual [1.017031   0.1539878  0.25798538]\n","Predicted [0.48979813 0.1122135  0.47163063] Actual [-0.42468843  0.07461132  1.6864309 ]\n","Predicted [0.7872504  0.09647962 0.26696274] Actual [0.4564941  0.31147972 0.38558406]\n","Predicted [0.16223101 0.07230926 0.41493618] Actual [0.2294975  0.0057361  0.20286071]\n","Predicted [0.45689276 0.07011854 0.49522617] Actual [0.22102104 0.01267508 0.13965875]\n","Predicted [0.3565918  0.09365061 0.50117815] Actual [ 0.33498654  0.038945   -0.00666178]\n","Predicted [0.7981912  0.23231916 1.1243783 ] Actual [0.4772248  0.23618239 1.1080313 ]\n","Predicted [0.26323825 0.07824417 0.45752773] Actual [0.15638767 0.00902059 0.02034818]\n","Predicted [0.47338778 0.10043669 0.43265426] Actual [-0.21465941  0.03485774  0.749984  ]\n","Predicted [0.19440316 0.06045377 0.42473143] Actual [0.0980076  0.01981497 0.11889308]\n","Predicted [0.28700182 0.06840234 0.505496  ] Actual [0.20321633 0.00270922 0.05271172]\n","Predicted [0.68909883 0.33183765 0.90883774] Actual [1.0609361  0.62006205 0.2430453 ]\n","Predicted [0.40288526 0.05899869 0.47932914] Actual [0.24542779 0.01177676 0.03596949]\n","Predicted [0.8218561  0.07593221 0.1937517 ] Actual [0.9843429  0.02127315 0.00908666]\n","Predicted [0.1906978  0.0700528  0.47068065] Actual [0.13653038 0.00496478 0.1367889 ]\n","Predicted [0.8126792  0.06816306 0.13375187] Actual [0.43197748 0.14286935 0.25609213]\n","Predicted [-0.08873215  0.24060373  0.4583058 ] Actual [0.7850331  0.2653966  0.59374976]\n","Predicted [0.5118656  0.08554403 0.37895986] Actual [ 1.0016277   0.00817271 -0.00460011]\n","Predicted [0.2765014  0.05824401 0.45001382] Actual [0.5324591  0.20637847 0.34683675]\n","Predicted [0.26784933 0.06463767 0.47582394] Actual [0.12778877 0.05314697 0.11334818]\n","Predicted [0.07512871 0.21191083 0.44691497] Actual [ 0.24936287  0.13927968 -0.12537819]\n","Predicted [-0.07296111  0.2372975   1.090438  ] Actual [1.345778   0.2878973  0.25534397]\n","Predicted [0.52309096 0.18213144 1.3278669 ] Actual [1.0340464  0.94609475 4.1648283 ]\n","Predicted [0.67758304 0.2739278  0.84982413] Actual [-0.44685987  0.15364036  1.131714  ]\n","Predicted [0.48571098 0.06421216 0.51893604] Actual [0.28277063 0.00611298 0.25204283]\n","Predicted [0.54506975 0.15062791 0.4892009 ] Actual [-0.2482666   0.20234048  4.4361305 ]\n","Predicted [0.8135348  0.07990117 0.13924819] Actual [0.98400784 0.00625715 0.00687014]\n","Predicted [0.8269058  0.20657541 0.88079476] Actual [1.4051754  0.46413523 0.3596025 ]\n","Predicted [0.28218034 0.30958077 2.4105897 ] Actual [-0.14886226  0.3431542   2.2897596 ]\n","Predicted [-0.16841711  0.21602806  0.58302766] Actual [-0.40749368  0.21647863 -0.51556313]\n","Predicted [0.2207744  0.0467417  0.47251284] Actual [0.22166191 0.00579312 0.03972023]\n","Predicted [0.77862287 0.1166684  0.31766742] Actual [0.4504976  0.02808539 0.07101654]\n","Predicted [0.41199967 0.19156955 2.1627603 ] Actual [-0.37343678  0.19703649  2.4168146 ]\n","Predicted [0.6680974  0.15285085 1.5575113 ] Actual [0.04211478 0.11759726 1.5584726 ]\n","Predicted [0.25976533 0.28148115 7.323185  ] Actual [0.16384636 0.15589237 9.712108  ]\n","Predicted [0.33631855 0.05559848 0.46899447] Actual [0.24435967 0.01398554 0.03821742]\n","Predicted [0.65831    0.10710316 0.86097574] Actual [0.13246985 0.13736096 0.49131972]\n","Predicted [0.18300606 0.10467258 0.5043097 ] Actual [ 0.34451684  0.10284839 -0.02477134]\n","Predicted [0.77463615 0.21703498 0.67291176] Actual [0.17084466 0.04326157 0.04231881]\n","Predicted [0.16919501 0.1924571  0.4130081 ] Actual [ 0.46148375  0.19729067 -0.01399351]\n","Predicted [0.23256178 0.05712874 0.44875062] Actual [ 0.9937574   0.01014699 -0.00802297]\n","Predicted [0.44415796 0.06451935 0.5192931 ] Actual [0.3061182 0.05564   0.2952715]\n","Predicted [0.38106215 0.13750485 0.73414385] Actual [-0.16505189  0.1206095   0.78266007]\n","Predicted [0.58067334 0.35218245 0.8111349 ] Actual [0.4772301  0.10433643 0.10170417]\n","Predicted [0.8189711  0.07818856 0.10999059] Actual [1.0893923  0.06970805 0.11371367]\n","Predicted [0.28369087 0.31687465 5.2753925 ] Actual [0.11622832 0.45753172 7.1940007 ]\n","Predicted [0.813679   0.08104976 0.16736758] Actual [0.72230315 0.22322503 0.00455057]\n","Predicted [0.8064943 0.0707707 0.1779623] Actual [0.7436172  0.01169187 0.15625906]\n","Predicted [0.7991281  0.10132357 0.22424969] Actual [0.30313352 0.00206321 0.05850982]\n","Predicted [0.5190055  0.10846054 0.43783563] Actual [0.34194654 0.01921439 0.0527082 ]\n","Predicted [0.8071396  0.07688728 0.18226016] Actual [0.34445825 0.01927417 0.11185055]\n","Predicted [0.55703753 0.10669884 0.40284175] Actual [ 0.99983394  0.00616773 -0.00292749]\n","Predicted [0.34126976 0.04958601 0.5526193 ] Actual [0.13164403 0.05019814 0.15744233]\n","Predicted [0.45963717 0.10080801 0.49279794] Actual [0.3392425  0.00062381 0.00915562]\n","Predicted [0.5276754  0.08765949 0.55146956] Actual [0.15780072 0.00612379 0.06527548]\n","Predicted [ 0.02043677  0.04064118 10.480559  ] Actual [ 0.02717043  0.0534746  11.162685  ]\n","Predicted [0.22119899 0.05168873 0.43496034] Actual [0.22361998 0.08600771 0.37799   ]\n","Predicted [0.27696404 0.06558748 0.5019937 ] Actual [ 0.32112667  0.05649012 -0.04381824]\n","Predicted [0.6208526  0.34685126 0.8999902 ] Actual [-2.9525539e-02  5.1790611e-03  1.1649012e+01]\n","Predicted [0.712162   0.30820778 0.87430555] Actual [1.09898    0.38173428 0.18462586]\n","Predicted [0.15124802 0.05708113 0.58606356] Actual [0.70587647 0.8226155  0.504348  ]\n","Predicted [0.8367453  0.06556711 0.06935244] Actual [0.8981369  0.0900064  0.09198778]\n","Predicted [0.48759562 0.07494159 0.47607678] Actual [0.27345017 0.01743173 0.13948101]\n","Predicted [0.69677305 0.4063763  0.79917634] Actual [0.94873816 0.5338696  0.44154647]\n","Predicted [0.5760023  0.09419721 0.38296568] Actual [0.5987464  0.19487266 0.17049778]\n","Predicted [0.48164338 0.17099191 0.46809256] Actual [ 1.1290307   0.12883699 -0.06849504]\n","Predicted [0.8100756  0.07257474 0.14124662] Actual [ 1.0057194   0.03374206 -0.00887341]\n","Predicted [0.18823893 0.05269187 0.48281544] Actual [0.13076966 0.02438894 0.11756688]\n","Predicted [0.69512904 0.1592842  0.24641255] Actual [0.31050208 0.00634202 0.02485257]\n","Predicted [0.8054403  0.10355181 0.2519246 ] Actual [ 1.0229533   0.07256154 -0.01976842]\n","Predicted [0.23846231 0.05604748 0.4880275 ] Actual [ 1.2943854   0.19057347 -0.0980813 ]\n","Predicted [0.5326921  0.09947546 0.42599973] Actual [0.9665427  0.07755025 0.10122638]\n","Predicted [0.5109694  0.08485498 0.5637344 ] Actual [ 1.0014027   0.07429969 -0.03161151]\n","Predicted [ 0.02413232  0.04353275 10.487169  ] Actual [-0.01332422  0.06373668 11.690138  ]\n","Predicted [0.47483534 0.10100377 0.38711333] Actual [-0.5466555   0.06557623  0.7018377 ]\n","Predicted [0.18853958 0.05711213 0.4684507 ] Actual [0.22244422 0.00853082 0.18608564]\n","Predicted [0.79421663 0.09444844 0.25143063] Actual [0.41779485 0.4276718  0.39566132]\n","Predicted [0.20559348 0.11093789 0.34728685] Actual [-0.42242107  0.25423113 -0.46899915]\n","Predicted [0.81298804 0.17144305 0.5584452 ] Actual [0.9010361  0.02133236 0.5986421 ]\n","Predicted [0.3381273  0.09232403 0.42394626] Actual [1.1051657  0.99867433 5.438772  ]\n","Predicted [0.23210298 0.05734991 0.45043564] Actual [-0.07705405  0.1731393   0.38134938]\n","Predicted [0.24320635 0.09187213 0.41035834] Actual [0.66129446 0.01342737 0.02786302]\n","Predicted [0.6303837  0.09660864 0.4294779 ] Actual [ 1.0079811   0.02306771 -0.0034175 ]\n","Predicted [0.33966956 0.0483718  0.54973656] Actual [0.26447433 0.00612123 0.10651129]\n","Predicted [0.04835526 0.26170012 0.572122  ] Actual [-0.24172457  0.469591    0.00822567]\n","Predicted [0.7381377  0.16098322 0.26109838] Actual [0.5606563 0.4889198 1.050042 ]\n","Predicted [0.56964207 0.06833736 0.44534627] Actual [0.50864214 0.02062965 0.22656706]\n","Predicted [0.5555048  0.09630743 0.46234828] Actual [0.38529134 0.06383564 0.00815659]\n","Predicted [0.8097206  0.06973342 0.15406471] Actual [0.3239198  0.3100397  0.45422813]\n","Predicted [0.635651   0.05829342 0.42339537] Actual [0.13698311 0.02178609 0.10477351]\n","Predicted [0.8088811  0.08319966 0.15470761] Actual [0.16327585 0.02845198 0.06042712]\n","Predicted [0.23699965 0.05385099 0.47915596] Actual [0.14568494 0.02202308 0.10407429]\n","Predicted [0.31755733 0.07283486 0.49308935] Actual [0.18457599 0.06854713 1.4051851 ]\n","Predicted [0.5128042 0.1333938 1.7367212] Actual [0.27911618 0.00824962 0.04837226]\n","Predicted [0.12566994 0.0893474  9.681292  ] Actual [ 0.20979793  0.10909893 11.129022  ]\n","Predicted [0.563941   0.08682089 0.41801095] Actual [0.47392157 0.00349893 0.05910694]\n","Predicted [0.56450516 0.20306729 0.548812  ] Actual [0.8210595  0.19090153 0.14950728]\n","Predicted [0.81123304 0.09051285 0.19696385] Actual [1.0090169  0.04216497 0.00359976]\n","Predicted [0.22451322 0.05224498 0.4318597 ] Actual [0.16281901 0.0412657  0.17956364]\n","Predicted [0.17610513 0.04163134 0.5677268 ] Actual [0.15169735 0.03236336 0.15562034]\n","Predicted [0.64557046 0.14653505 0.7308823 ] Actual [ 1.094096    0.10380386 -0.04165203]\n","Predicted [0.22272678 0.04365158 0.53691643] Actual [0.15783744 0.09527459 0.19811189]\n","Predicted [0.82603484 0.05800987 0.14883655] Actual [1.049947   0.03945468 0.09847539]\n","Predicted [0.76072955 0.2817062  0.77956116] Actual [ 0.9131112   0.01219646 -0.01122642]\n","Predicted [0.86551654 0.13520691 0.28529474] Actual [ 1.0051903   0.02613886 -0.00947756]\n","Predicted [-0.12041046  0.16819929  0.5261371 ] Actual [-0.5241423   0.09498177 -0.520188  ]\n","Predicted [0.18411519 0.05384316 0.4429627 ] Actual [0.13331042 0.01930717 0.11295032]\n","Predicted [0.3107486  0.06235647 0.42701986] Actual [0.2560327  0.06862815 0.21473274]\n","Predicted [0.19511025 0.04717422 0.5085299 ] Actual [0.12920593 0.00648843 0.09872495]\n","Predicted [0.6668298  0.20253265 1.0425885 ] Actual [0.93517196 0.48611885 2.0785644 ]\n","Predicted [0.53670067 0.12432042 0.43944684] Actual [-0.14727636  0.12465991  1.271018  ]\n","Predicted [0.812068   0.07420416 0.14757854] Actual [1.0003796  0.00583285 0.00223779]\n","Predicted [0.19784029 0.05318592 0.48988357] Actual [0.1545325  0.00107044 0.09551399]\n","Predicted [0.41412786 0.06021445 0.504806  ] Actual [ 1.0280954   0.22552241 -0.04768748]\n","Predicted [0.5340449  0.23753524 0.56157225] Actual [0.6850425  0.06404985 0.18032706]\n","Predicted [0.62063414 0.23513925 0.5576569 ] Actual [0.902836   0.5819718  0.84775823]\n","Predicted [0.37027302 0.1273004  0.46511462] Actual [0.2190973  0.06945227 0.0650711 ]\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"8sljnsWiyGl8","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":1751},"outputId":"121dc499-b7ad-4c2e-e0fd-9bcc1f2941c9","executionInfo":{"status":"ok","timestamp":1559456222182,"user_tz":240,"elapsed":618,"user":{"displayName":"Gautham Bekal","photoUrl":"","userId":"01650273333839084339"}}},"source":["#R-SQUARED METRIC\n","R_residual=((outputs[:,1]-y[:,1])**2).sum()\n","R_total=((outputs[:,1]-np.average(y[:,1]))**2).sum()\n","print(R_residual)\n","print(R_total)"],"execution_count":63,"outputs":[{"output_type":"stream","text":["[3.56757969e-01 8.95342696e-03 5.72372712e-02 1.18952291e-02\n"," 8.56426507e-02 2.53164113e-01 3.09223360e-05 8.64127219e-01\n"," 2.83073604e-01 1.74360096e-01 2.89417237e-01 8.62240122e-05\n"," 7.75938570e-01 3.63653183e-01 1.56628296e-01 4.78335842e-02\n"," 1.64225078e+00 1.89962927e-02 4.74485606e-02 3.88338268e-01\n"," 1.03762053e-01 5.82522452e-01 2.16255672e-02 1.41527737e-02\n"," 7.38083050e-02 4.22585988e-03 4.40679528e-02 1.16609707e-02\n"," 9.63715836e-03 2.14951802e-02 1.00110084e-01 1.19719312e-01\n"," 2.65548527e-02 2.53476590e-01 3.11003942e-02 3.43393013e-02\n"," 8.25931072e-01 1.04353040e-01 6.14966211e-08 2.92252353e-03\n"," 4.24306840e-02 3.07953358e-02 4.49712249e-03 6.37858137e-02\n"," 7.15103596e-02 4.18127999e-02 9.82849021e-03 4.69323695e-02\n"," 3.52920890e-02 7.80951988e-04 4.12587747e-02 1.73741137e-04\n"," 5.46701672e-03 3.44936103e-02 3.07394892e-01 4.81519522e-03\n"," 4.43742871e-02 9.05168056e-02 8.67739618e-02 2.98744068e-02\n"," 3.08963768e-02 1.76581562e-01 1.48206758e+00 4.00136232e-05\n"," 3.59684005e-02 1.19597048e-01 3.52527872e-02 1.80261582e-03\n"," 8.65061760e-01 2.04241201e-01 7.05505610e-01 6.40172735e-02\n"," 7.60151744e-02 6.82176906e-04 2.06522271e-02 1.77083194e-01\n"," 1.22106960e-02 6.64160773e-03 3.00531756e-05 2.48043444e-02\n"," 2.12865621e-01 1.62751961e+00 5.84464073e-02 2.89995950e-02\n"," 8.36285591e-01 1.09399736e-01 4.52478137e-03 5.56354672e-02\n"," 4.66786965e-04 1.03019424e-01 1.14170462e-02 4.73408908e-01\n"," 9.29210428e-03 7.02000828e-03 1.38262942e-01 2.47928556e-02\n"," 2.64019575e-02 2.93410942e-03 1.44933775e-01 7.63465703e-01\n"," 2.39866883e-01 6.55143410e-02 1.96169596e-02 3.03575397e-02\n"," 2.01282048e+00 2.61075467e-01 1.26437187e+00 4.11847830e-02\n"," 6.29382551e-01 2.90610567e-02 3.34395796e-01 1.85797736e-01\n"," 5.71576059e-02 7.87679596e-07 1.07666194e-01 6.16910398e-01\n"," 3.91854197e-01 9.20044817e-03 8.45643599e-03 2.76507884e-01\n"," 2.60857325e-02 3.64564151e-01 8.54326934e-02 5.79418838e-01\n"," 1.90549772e-02 2.98240542e-01 1.07005034e-02 7.31276274e-02\n"," 2.80437078e-02 8.34954157e-03 3.95353185e-03 2.46010646e-01\n"," 3.13498676e-02 2.14074001e-01 1.96068659e-01 4.39429507e-02\n"," 1.44948782e-02 1.36807263e-01 4.53421235e-05 5.86120041e-06\n"," 1.95033802e-03 4.22991693e-01 1.49628118e-01 3.07612687e-01\n"," 3.76892765e-03 4.58582751e-02 6.34864122e-02 5.17294975e-04\n"," 4.19110358e-01 3.82765122e-02 3.30271805e-03 1.47937894e-01\n"," 4.73118909e-02 1.11497355e+00 1.88226387e-01 2.40524858e-01\n"," 1.40299252e-03 1.04344344e+00 1.14952470e-03 1.41693354e-01\n"," 3.94402295e-01 7.75245763e-03 5.88348031e-01 9.55780596e-02\n"," 1.74797669e-01 1.42579794e-01 5.65432152e-03 8.41463059e-02\n"," 3.14996503e-02 3.72099155e-03 2.89726220e-02 2.36002386e-01\n"," 2.48669669e-01 4.16806161e-01 8.33837502e-03 1.76840387e-02\n"," 5.46100922e-02 7.07751932e-03 8.10349826e-03 6.58201426e-02\n"," 3.91184427e-02 3.80617497e-03 5.95739461e-04 2.01175109e-01\n"," 4.21062671e-03 5.01366630e-02 2.32201703e-02 1.95087455e-02\n"," 1.62999406e-01 2.58112396e-03 2.99382978e-03 4.34337929e-03\n"," 7.20074996e-02 4.67824548e-01 3.54612507e-02 1.87556387e-03\n"," 3.76956135e-01 2.28002686e-02 7.96379074e-02 2.28540991e-02]\n","[1.16069891e-01 1.03853516e-01 4.27006092e-03 1.10581487e-01\n"," 1.32883862e-02 4.33578789e-02 5.31923817e-03 3.15677514e-03\n"," 6.57495409e-02 5.53707778e-02 8.42867958e-05 6.37424365e-02\n"," 4.92282305e-03 1.70082960e-04 9.08666104e-02 3.14394049e-02\n"," 3.76740545e-02 3.24398935e-01 1.38653159e-01 1.55444443e-02\n"," 1.16867237e-01 5.51351160e-03 1.21168882e-01 1.30958166e-02\n"," 1.18179679e-01 1.35571212e-02 1.10572728e-03 1.33136287e-02\n"," 6.07544109e-02 1.21182366e-03 7.82201765e-04 6.98498562e-02\n"," 1.37758881e-01 1.11096241e-01 1.18850581e-01 5.05160391e-02\n"," 2.61051189e-02 4.71882347e-04 6.67981133e-02 2.32964456e-02\n"," 1.39785826e-01 2.81626038e-04 1.39638737e-01 1.19156212e-01\n"," 1.02892645e-01 1.16095684e-01 1.33734375e-01 5.82163921e-03\n"," 1.55047635e-02 8.15349221e-02 1.17279813e-01 8.23606178e-02\n"," 4.73022051e-02 1.19325317e-01 5.87196127e-02 6.77302629e-02\n"," 1.09293416e-01 3.36462428e-04 1.17262550e-01 5.80582693e-02\n"," 3.52558196e-02 5.50648272e-02 1.51565984e-01 1.11327372e-01\n"," 3.90540808e-03 1.09155409e-01 1.03042170e-01 2.26325184e-01\n"," 7.55208731e-02 3.33374552e-02 5.34473322e-02 6.50896728e-02\n"," 6.30122125e-02 9.31607783e-02 8.07314366e-02 1.22669926e-02\n"," 4.19245288e-02 1.06215375e-02 5.40027535e-03 3.46439295e-02\n"," 1.45687610e-01 3.37876797e-01 1.16804734e-01 1.42832339e-01\n"," 4.40643256e-04 1.01406440e-01 9.39885974e-02 1.41940196e-04\n"," 1.25921685e-02 1.08494192e-01 4.22583558e-02 2.09869668e-05\n"," 7.52972513e-02 3.30529884e-02 4.85286564e-02 4.34562657e-03\n"," 1.24643922e-01 7.73445219e-02 1.18248329e-01 3.10849458e-01\n"," 1.85407675e-03 3.69813032e-02 4.03838344e-02 1.54982299e-01\n"," 2.93512255e-01 2.94678891e-03 4.35875915e-02 2.85757182e-04\n"," 5.81606477e-03 1.18837513e-01 1.28235012e-01 3.48293707e-02\n"," 4.06054080e-01 6.15199842e-02 9.59861055e-02 3.22702969e-03\n"," 3.97168025e-02 4.36982624e-02 1.75530892e-02 3.59115265e-02\n"," 8.16819668e-02 9.35316980e-02 8.97671282e-02 5.58116250e-02\n"," 6.07556780e-04 7.69909285e-03 1.25141609e-02 1.22615159e-01\n"," 3.42678428e-02 1.18936941e-01 1.14032961e-01 1.09112285e-01\n"," 2.51992489e-03 1.14469185e-01 7.78469304e-03 1.62656512e-02\n"," 8.40789871e-05 3.46553163e-03 2.01035529e-01 6.13095388e-02\n"," 3.68035771e-02 2.31179763e-02 5.92218488e-02 1.00843459e-01\n"," 1.35378882e-01 3.53026262e-04 5.19686937e-02 1.14909131e-02\n"," 1.64782265e-04 1.16464503e-01 7.87182376e-02 5.12218326e-02\n"," 1.13322236e-01 5.30585013e-02 4.08135075e-03 1.77769968e-03\n"," 1.97735250e-01 3.63453655e-05 7.85496235e-02 1.05891675e-01\n"," 6.92811683e-02 1.18460849e-01 1.70770902e-02 5.60286157e-02\n"," 5.08954823e-02 2.61071417e-02 1.66763831e-02 1.76779360e-01\n"," 7.25392401e-02 1.01677869e-02 7.51657365e-03 1.16222322e-01\n"," 2.78370436e-02 1.15650654e-01 5.37344739e-02 2.28763483e-02\n"," 1.93578750e-03 1.17742769e-01 9.05054994e-03 9.15820990e-03\n"," 1.17255852e-01 5.96792698e-02 8.56741592e-02 3.12454533e-02\n"," 6.05552904e-02 1.27611995e-01 8.52189958e-02 1.57378763e-01\n"," 3.47176760e-01 8.10492262e-02 2.49823369e-02 7.49097019e-02\n"," 3.92131880e-02 4.60960111e-03 1.17828362e-01 7.34227598e-02\n"," 2.98976758e-03 4.25603520e-03 2.30515935e-02 9.70887020e-03]\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"qqwlL4-2z9zp","colab_type":"code","colab":{}},"source":["R_squared=1-(R_residual/R_total)\n","print(R_squared)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"P2cCiI9Nq6SD","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":156},"outputId":"2dee416f-de52-419c-af27-d24f01738b91","executionInfo":{"status":"ok","timestamp":1559454970845,"user_tz":240,"elapsed":171,"user":{"displayName":"Gautham Bekal","photoUrl":"","userId":"01650273333839084339"}}},"source":["df.iloc[150,:]"],"execution_count":54,"outputs":[{"output_type":"execute_result","data":{"text/plain":["ccx        -3.525993\n","ccy        -1.176824\n","ccz         0.833231\n","U1          0.210105\n","U2          0.592905\n","U3          0.114255\n","distance    3.809438\n","Name: 276269, dtype: float64"]},"metadata":{"tags":[]},"execution_count":54}]},{"cell_type":"code","metadata":{"id":"A2NzNZprpZYl","colab_type":"code","colab":{}},"source":["O = np.array([\n","[[1,2,3], [4,5,6]],\n","[[3,8,9], [2,9,4]],\n","[[7,1,3], [1,3,6]],\n","[[5,4,2], [6,9,8]]\n","])"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"x742T1gDpk5i","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":208},"outputId":"aad47f9e-67a4-465b-c4b3-f74b767625fb","executionInfo":{"status":"ok","timestamp":1559454970874,"user_tz":240,"elapsed":115,"user":{"displayName":"Gautham Bekal","photoUrl":"","userId":"01650273333839084339"}}},"source":["O"],"execution_count":56,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([[[1, 2, 3],\n","        [4, 5, 6]],\n","\n","       [[3, 8, 9],\n","        [2, 9, 4]],\n","\n","       [[7, 1, 3],\n","        [1, 3, 6]],\n","\n","       [[5, 4, 2],\n","        [6, 9, 8]]])"]},"metadata":{"tags":[]},"execution_count":56}]},{"cell_type":"code","metadata":{"id":"CNsv3C8OpmLz","colab_type":"code","colab":{}},"source":["O=np.delete(O,1,2)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"qIgIxVAcpuBZ","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":208},"outputId":"92218e1d-8819-4409-ac55-74350c57f59f","executionInfo":{"status":"ok","timestamp":1559454970896,"user_tz":240,"elapsed":88,"user":{"displayName":"Gautham Bekal","photoUrl":"","userId":"01650273333839084339"}}},"source":["O"],"execution_count":58,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([[[1, 3],\n","        [4, 6]],\n","\n","       [[3, 9],\n","        [2, 4]],\n","\n","       [[7, 3],\n","        [1, 6]],\n","\n","       [[5, 2],\n","        [6, 8]]])"]},"metadata":{"tags":[]},"execution_count":58}]}]}